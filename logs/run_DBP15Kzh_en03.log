Script started on 2025-12-17 16:06:02+08:00 [TERM="xterm-256color" TTY="/dev/pts/0" COLUMNS="165" LINES="40"]
2025-12-17 16:06:04.032484: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-12-17 16:06:04.032529: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-12-17 16:06:04.033565: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-12-17 16:06:04.040807: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-12-17 16:06:04.915082: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO - 12/17/25 16:06:06 - 0:00:00 - ============ Initialized logger ============
INFO - 12/17/25 16:06:06 - 0:00:00 - The experiment will be stored in /root/data/mmkg/dump/1217-IJCAI_MEAformer_sf_0_500-Norm/MEAformer_DBP15K_zh_en_v1_zh_en_0.3
                                     
INFO - 12/17/25 16:06:06 - 0:00:00 - Running command: python main.py --gpu 0 --eval_epoch 1 --only_test 0 --model_name MEAformer --data_choice DBP15K --data_split zh_en --data_rate '0.3' --epoch 500 --lr '5e-4' --hidden_units '300,300,300' --save_model 0 --batch_size 3500 --csls --csls_k 3 --random_seed 42 --exp_name 'IJCAI_MEAformer_sf_0_500-Norm' --exp_id 'v1_zh_en_0.3' --workers 12 --dist 0 --accumulation_steps 1 --scheduler cos --attr_dim 300 --img_dim 300 --name_dim 300 --char_dim 300 --hidden_size 300 --tau '0.1' --structure_encoder gat --num_attention_heads 1 --num_hidden_layers 1 --use_surface 0 --use_intermediate 1 --enable_sota --replay 0 --w_hypergraph 1

loading raw data...
INFO - 12/17/25 16:06:08 - 0:00:02 - 77.09% entities have images
INFO - 12/17/25 16:06:08 - 0:00:02 - image feature shape:(38960, 2048)
INFO - 12/17/25 16:06:08 - 0:00:02 - #left entity : 19388, #right entity: 19572
INFO - 12/17/25 16:06:08 - 0:00:02 - #left entity not in train set: 14888, #right entity not in train set: 15072
INFO - 12/17/25 16:06:09 - 0:00:03 - relation feature shape:(38960, 1000)
INFO - 12/17/25 16:06:10 - 0:00:04 - attribute feature shape:(38960, 1000)
INFO - 12/17/25 16:06:10 - 0:00:04 - -----dataset summary-----
INFO - 12/17/25 16:06:10 - 0:00:04 - dataset:		 /root/data/mmkg/DBP15K/zh_en
INFO - 12/17/25 16:06:10 - 0:00:04 - triple num:	 165556
INFO - 12/17/25 16:06:10 - 0:00:04 - entity num:	 38960
INFO - 12/17/25 16:06:10 - 0:00:04 - relation num:	 3024
INFO - 12/17/25 16:06:10 - 0:00:04 - train ill num:	 4500 	 test ill num:	 10500
INFO - 12/17/25 16:06:10 - 0:00:04 - -------------------------
getting a sparse tensor r_adj...
/root/autodl-tmp/peaformer/src/utils.py:237: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:605.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO - 12/17/25 16:06:10 - 0:00:04 - Generating Graph Topology Features (Degree + PageRank)...
INFO - 12/17/25 16:06:11 - 0:00:05 - Topology Features Generated. Shape: torch.Size([38960, 2])
INFO - 12/17/25 16:06:11 - 0:00:05 - Constructing Visual-Attribute Dual Hypergraph...
INFO - 12/17/25 16:06:27 - 0:00:21 - Dual Hypergraph Constructed. Shape: torch.Size([38960, 3000])
INFO - 12/17/25 16:06:28 - 0:00:21 - Random init...
INFO - 12/17/25 16:06:28 - 0:00:21 - total params num: 14224307
INFO - 12/17/25 16:06:28 - 0:00:21 - warmup_steps: 75
INFO - 12/17/25 16:06:28 - 0:00:21 - total_steps: 500
INFO - 12/17/25 16:06:28 - 0:00:21 - weight_decay: 0.0001
  0%|                                                                                                                                        | 0/250 [00:00<?, ?it/s]Train | Ep [0/250] Step [3/500] LR [0.00001] Loss 152.88960 :   0%|                                                                          | 0/250 [00:03<?, ?it/s]INFO - 12/17/25 16:06:35 - 0:00:29 - Ep 0 | l2r: acc of top [1, 10, 50] = [0.2158 0.4084 0.5956], mr = 428.934, mrr = 0.282, Loss = 152.8896
INFO - 12/17/25 16:06:35 - 0:00:29 - Ep 0 | r2l: acc of top [1, 10, 50] = [0.2065 0.3908 0.5785], mr = 362.173, mrr = 0.270, Loss = 152.8896
INFO - 12/17/25 16:06:35 - 0:00:29 - Best model update in Ep 0: MRR from [0.0] --> [0.2823793529094231] ... 
Train | Ep [0/250] Step [3/500] LR [0.00001] Loss 152.88960 :   0%|▎                                                                 | 1/250 [00:07<30:29,  7.35s/it]Train | Ep [1/250] Step [5/500] LR [0.00003] Loss 152.64457 :   0%|▎                                                                 | 1/250 [00:09<30:29,  7.35s/it]INFO - 12/17/25 16:06:41 - 0:00:35 - Ep 1 | l2r: acc of top [1, 10, 50] = [0.2278 0.4195 0.607 ], mr = 399.679, mrr = 0.294, Loss = 152.6446
INFO - 12/17/25 16:06:41 - 0:00:35 - Ep 1 | r2l: acc of top [1, 10, 50] = [0.2144 0.401  0.5915], mr = 339.471, mrr = 0.279, Loss = 152.6446
INFO - 12/17/25 16:06:41 - 0:00:35 - Best model update in Ep 1: MRR from [0.2823793529094231] --> [0.2941197811495226] ... 
Train | Ep [1/250] Step [5/500] LR [0.00003] Loss 152.64457 :   1%|▌                                                                 | 2/250 [00:13<27:20,  6.61s/it]Train | Ep [2/250] Step [7/500] LR [0.00004] Loss 151.87121 :   1%|▌                                                                 | 2/250 [00:15<27:20,  6.61s/it]INFO - 12/17/25 16:06:47 - 0:00:41 - Ep 2 | l2r: acc of top [1, 10, 50] = [0.2522 0.4417 0.6235], mr = 353.811, mrr = 0.317, Loss = 151.8712
INFO - 12/17/25 16:06:47 - 0:00:41 - Ep 2 | r2l: acc of top [1, 10, 50] = [0.2323 0.423  0.6111], mr = 303.658, mrr = 0.298, Loss = 151.8712
INFO - 12/17/25 16:06:47 - 0:00:41 - Best model update in Ep 2: MRR from [0.2941197811495226] --> [0.3168433487511025] ... 
Train | Ep [2/250] Step [7/500] LR [0.00004] Loss 151.87121 :   1%|▊                                                                 | 3/250 [00:19<26:10,  6.36s/it]Train | Ep [3/250] Step [9/500] LR [0.00005] Loss 150.97850 :   1%|▊                                                                 | 3/250 [00:21<26:10,  6.36s/it]INFO - 12/17/25 16:06:53 - 0:00:47 - Ep 3 | l2r: acc of top [1, 10, 50] = [0.284  0.4677 0.645 ], mr = 302.369, mrr = 0.347, Loss = 150.9785
INFO - 12/17/25 16:06:53 - 0:00:47 - Ep 3 | r2l: acc of top [1, 10, 50] = [0.2586 0.4534 0.6349], mr = 262.993, mrr = 0.325, Loss = 150.9785
INFO - 12/17/25 16:06:53 - 0:00:47 - Best model update in Ep 3: MRR from [0.3168433487511025] --> [0.3471577391891817] ... 
Train | Ep [3/250] Step [9/500] LR [0.00005] Loss 150.97850 :   2%|█                                                                 | 4/250 [00:25<25:37,  6.25s/it]Train | Ep [4/250] Step [11/500] LR [0.00007] Loss 149.22588 :   2%|█                                                                | 4/250 [00:27<25:37,  6.25s/it]INFO - 12/17/25 16:07:00 - 0:00:53 - Ep 4 | l2r: acc of top [1, 10, 50] = [0.321 0.489 0.655], mr = 259.520, mrr = 0.379, Loss = 149.2259
INFO - 12/17/25 16:07:00 - 0:00:53 - Ep 4 | r2l: acc of top [1, 10, 50] = [0.295  0.4846 0.657 ], mr = 228.953, mrr = 0.359, Loss = 149.2259
INFO - 12/17/25 16:07:00 - 0:00:53 - Best model update in Ep 4: MRR from [0.3471577391891817] --> [0.3792524600856289] ... 
Train | Ep [4/250] Step [11/500] LR [0.00007] Loss 149.22588 :   2%|█▎                                                               | 5/250 [00:31<25:37,  6.28s/it]Train | Ep [5/250] Step [13/500] LR [0.00008] Loss 147.83672 :   2%|█▎                                                               | 5/250 [00:34<25:37,  6.28s/it]INFO - 12/17/25 16:07:06 - 0:01:00 - Ep 5 | l2r: acc of top [1, 10, 50] = [0.3482 0.5003 0.659 ], mr = 234.749, mrr = 0.400, Loss = 147.8367
INFO - 12/17/25 16:07:06 - 0:01:00 - Ep 5 | r2l: acc of top [1, 10, 50] = [0.3282 0.5039 0.6618], mr = 209.475, mrr = 0.388, Loss = 147.8367
INFO - 12/17/25 16:07:06 - 0:01:00 - Best model update in Ep 5: MRR from [0.3792524600856289] --> [0.40022303638952905] ... 
Train | Ep [5/250] Step [13/500] LR [0.00008] Loss 147.83672 :   2%|█▌                                                               | 6/250 [00:38<25:24,  6.25s/it]Train | Ep [6/250] Step [15/500] LR [0.00009] Loss 145.87457 :   2%|█▌                                                               | 6/250 [00:40<25:24,  6.25s/it]INFO - 12/17/25 16:07:12 - 0:01:06 - Ep 6 | l2r: acc of top [1, 10, 50] = [0.361  0.5047 0.6615], mr = 219.482, mrr = 0.411, Loss = 145.8746
INFO - 12/17/25 16:07:12 - 0:01:06 - Ep 6 | r2l: acc of top [1, 10, 50] = [0.3453 0.5107 0.662 ], mr = 199.133, mrr = 0.403, Loss = 145.8746
INFO - 12/17/25 16:07:12 - 0:01:06 - Best model update in Ep 6: MRR from [0.40022303638952905] --> [0.4108398589833031] ... 
Train | Ep [6/250] Step [15/500] LR [0.00009] Loss 145.87457 :   3%|█▊                                                               | 7/250 [00:44<25:20,  6.26s/it]Train | Ep [7/250] Step [17/500] LR [0.00011] Loss 144.32658 :   3%|█▊                                                               | 7/250 [00:46<25:20,  6.26s/it]INFO - 12/17/25 16:07:18 - 0:01:12 - Ep 7 | l2r: acc of top [1, 10, 50] = [0.3665 0.5089 0.6663], mr = 200.430, mrr = 0.416, Loss = 144.3266
INFO - 12/17/25 16:07:18 - 0:01:12 - Ep 7 | r2l: acc of top [1, 10, 50] = [0.3533 0.5155 0.6686], mr = 184.387, mrr = 0.410, Loss = 144.3266
INFO - 12/17/25 16:07:18 - 0:01:12 - Best model update in Ep 7: MRR from [0.4108398589833031] --> [0.4162111548553254] ... 
Train | Ep [7/250] Step [17/500] LR [0.00011] Loss 144.32658 :   3%|██                                                               | 8/250 [00:50<25:10,  6.24s/it]Train | Ep [8/250] Step [19/500] LR [0.00012] Loss 142.41657 :   3%|██                                                               | 8/250 [00:52<25:10,  6.24s/it]INFO - 12/17/25 16:07:24 - 0:01:18 - Ep 8 | l2r: acc of top [1, 10, 50] = [0.3692 0.5171 0.6754], mr = 176.651, mrr = 0.420, Loss = 142.4166
INFO - 12/17/25 16:07:24 - 0:01:18 - Ep 8 | r2l: acc of top [1, 10, 50] = [0.3583 0.5217 0.6772], mr = 163.488, mrr = 0.416, Loss = 142.4166
INFO - 12/17/25 16:07:24 - 0:01:18 - Best model update in Ep 8: MRR from [0.4162111548553254] --> [0.42006591591110987] ... 
Train | Ep [8/250] Step [19/500] LR [0.00012] Loss 142.41657 :   4%|██▎                                                              | 9/250 [00:56<24:58,  6.22s/it]Train | Ep [9/250] Step [21/500] LR [0.00013] Loss 140.78377 :   4%|██▎                                                              | 9/250 [00:58<24:58,  6.22s/it]INFO - 12/17/25 16:07:31 - 0:01:24 - Ep 9 | l2r: acc of top [1, 10, 50] = [0.3735 0.5255 0.684 ], mr = 152.921, mrr = 0.425, Loss = 140.7838
INFO - 12/17/25 16:07:31 - 0:01:24 - Ep 9 | r2l: acc of top [1, 10, 50] = [0.3635 0.5296 0.6891], mr = 141.862, mrr = 0.422, Loss = 140.7838
INFO - 12/17/25 16:07:31 - 0:01:24 - Best model update in Ep 9: MRR from [0.42006591591110987] --> [0.425285391322995] ... 
Train | Ep [9/250] Step [21/500] LR [0.00013] Loss 140.78377 :   4%|██▌                                                             | 10/250 [01:02<24:50,  6.21s/it]Train | Ep [10/250] Step [23/500] LR [0.00015] Loss 139.07478 :   4%|██▌                                                            | 10/250 [01:05<24:50,  6.21s/it]INFO - 12/17/25 16:07:37 - 0:01:31 - Ep 10 | l2r: acc of top [1, 10, 50] = [0.3775 0.5321 0.6948], mr = 132.589, mrr = 0.430, Loss = 139.0748
INFO - 12/17/25 16:07:37 - 0:01:31 - Ep 10 | r2l: acc of top [1, 10, 50] = [0.3716 0.5344 0.6989], mr = 122.712, mrr = 0.429, Loss = 139.0748
INFO - 12/17/25 16:07:37 - 0:01:31 - Best model update in Ep 10: MRR from [0.425285391322995] --> [0.43032426129111306] ... 
Train | Ep [10/250] Step [23/500] LR [0.00015] Loss 139.07478 :   4%|██▊                                                            | 11/250 [01:09<24:37,  6.18s/it]Train | Ep [11/250] Step [25/500] LR [0.00016] Loss 136.67867 :   4%|██▊                                                            | 11/250 [01:11<24:37,  6.18s/it]INFO - 12/17/25 16:07:43 - 0:01:37 - Ep 11 | l2r: acc of top [1, 10, 50] = [0.3818 0.5396 0.7062], mr = 115.861, mrr = 0.436, Loss = 136.6787
INFO - 12/17/25 16:07:43 - 0:01:37 - Ep 11 | r2l: acc of top [1, 10, 50] = [0.3781 0.5419 0.7118], mr = 106.633, mrr = 0.435, Loss = 136.6787
INFO - 12/17/25 16:07:43 - 0:01:37 - Best model update in Ep 11: MRR from [0.43032426129111306] --> [0.43564754568979214] ... 
Train | Ep [11/250] Step [25/500] LR [0.00016] Loss 136.67867 :   5%|███                                                            | 12/250 [01:15<24:27,  6.17s/it]Train | Ep [12/250] Step [27/500] LR [0.00017] Loss 133.90903 :   5%|███                                                            | 12/250 [01:17<24:27,  6.17s/it]INFO - 12/17/25 16:07:49 - 0:01:43 - Ep 12 | l2r: acc of top [1, 10, 50] = [0.3874 0.5504 0.7184], mr = 101.437, mrr = 0.442, Loss = 133.9090
INFO - 12/17/25 16:07:49 - 0:01:43 - Ep 12 | r2l: acc of top [1, 10, 50] = [0.3849 0.5535 0.725 ], mr = 93.498, mrr = 0.443, Loss = 133.9090
INFO - 12/17/25 16:07:49 - 0:01:43 - Best model update in Ep 12: MRR from [0.43564754568979214] --> [0.44205878068931415] ... 
Train | Ep [12/250] Step [27/500] LR [0.00017] Loss 133.90903 :   5%|███▎                                                           | 13/250 [01:21<24:18,  6.15s/it]Train | Ep [13/250] Step [29/500] LR [0.00019] Loss 130.83530 :   5%|███▎                                                           | 13/250 [01:23<24:18,  6.15s/it]INFO - 12/17/25 16:07:55 - 0:01:49 - Ep 13 | l2r: acc of top [1, 10, 50] = [0.3931 0.5589 0.7326], mr = 88.932, mrr = 0.449, Loss = 130.8353
INFO - 12/17/25 16:07:55 - 0:01:49 - Ep 13 | r2l: acc of top [1, 10, 50] = [0.3926 0.565  0.7389], mr = 82.728, mrr = 0.451, Loss = 130.8353
INFO - 12/17/25 16:07:55 - 0:01:49 - Best model update in Ep 13: MRR from [0.44205878068931415] --> [0.44920313847972815] ... 
Train | Ep [13/250] Step [29/500] LR [0.00019] Loss 130.83530 :   6%|███▌                                                           | 14/250 [01:27<24:27,  6.22s/it]Train | Ep [14/250] Step [31/500] LR [0.00020] Loss 127.74654 :   6%|███▌                                                           | 14/250 [01:29<24:27,  6.22s/it]INFO - 12/17/25 16:08:02 - 0:01:55 - Ep 14 | l2r: acc of top [1, 10, 50] = [0.3999 0.5685 0.7445], mr = 78.564, mrr = 0.457, Loss = 127.7465
INFO - 12/17/25 16:08:02 - 0:01:55 - Ep 14 | r2l: acc of top [1, 10, 50] = [0.3981 0.5758 0.7505], mr = 73.576, mrr = 0.458, Loss = 127.7465
INFO - 12/17/25 16:08:02 - 0:01:55 - Best model update in Ep 14: MRR from [0.44920313847972815] --> [0.45713167279896144] ... 
Train | Ep [14/250] Step [31/500] LR [0.00020] Loss 127.74654 :   6%|███▊                                                           | 15/250 [01:33<24:18,  6.21s/it]Train | Ep [15/250] Step [33/500] LR [0.00021] Loss 123.78607 :   6%|███▊                                                           | 15/250 [01:35<24:18,  6.21s/it]INFO - 12/17/25 16:08:08 - 0:02:01 - Ep 15 | l2r: acc of top [1, 10, 50] = [0.4068 0.5797 0.7584], mr = 69.815, mrr = 0.465, Loss = 123.7861
INFO - 12/17/25 16:08:08 - 0:02:01 - Ep 15 | r2l: acc of top [1, 10, 50] = [0.4043 0.5871 0.764 ], mr = 65.734, mrr = 0.465, Loss = 123.7861
INFO - 12/17/25 16:08:08 - 0:02:01 - Best model update in Ep 15: MRR from [0.45713167279896144] --> [0.4650928793285068] ... 
Train | Ep [15/250] Step [33/500] LR [0.00021] Loss 123.78607 :   6%|████                                                           | 16/250 [01:40<24:08,  6.19s/it]Train | Ep [16/250] Step [35/500] LR [0.00023] Loss 119.78795 :   6%|████                                                           | 16/250 [01:42<24:08,  6.19s/it]INFO - 12/17/25 16:08:14 - 0:02:08 - Ep 16 | l2r: acc of top [1, 10, 50] = [0.4147 0.5933 0.7758], mr = 61.139, mrr = 0.475, Loss = 119.7879
INFO - 12/17/25 16:08:14 - 0:02:08 - Ep 16 | r2l: acc of top [1, 10, 50] = [0.4116 0.6016 0.7802], mr = 58.252, mrr = 0.475, Loss = 119.7879
INFO - 12/17/25 16:08:14 - 0:02:08 - Best model update in Ep 16: MRR from [0.4650928793285068] --> [0.4752288343341903] ... 
Train | Ep [16/250] Step [35/500] LR [0.00023] Loss 119.78795 :   7%|████▎                                                          | 17/250 [01:46<24:05,  6.20s/it]Train | Ep [17/250] Step [37/500] LR [0.00024] Loss 116.02777 :   7%|████▎                                                          | 17/250 [01:48<24:05,  6.20s/it]INFO - 12/17/25 16:08:20 - 0:02:14 - Ep 17 | l2r: acc of top [1, 10, 50] = [0.4249 0.611  0.797 ], mr = 52.025, mrr = 0.488, Loss = 116.0278
INFO - 12/17/25 16:08:20 - 0:02:14 - Ep 17 | r2l: acc of top [1, 10, 50] = [0.4227 0.6173 0.797 ], mr = 50.379, mrr = 0.488, Loss = 116.0278
INFO - 12/17/25 16:08:20 - 0:02:14 - Best model update in Ep 17: MRR from [0.4752288343341903] --> [0.48771931313806177] ... 
Train | Ep [17/250] Step [37/500] LR [0.00024] Loss 116.02777 :   7%|████▌                                                          | 18/250 [01:52<24:05,  6.23s/it]Train | Ep [18/250] Step [39/500] LR [0.00025] Loss 111.70317 :   7%|████▌                                                          | 18/250 [01:54<24:05,  6.23s/it]INFO - 12/17/25 16:08:27 - 0:02:20 - Ep 18 | l2r: acc of top [1, 10, 50] = [0.4393 0.6378 0.8232], mr = 42.935, mrr = 0.505, Loss = 111.7032
INFO - 12/17/25 16:08:27 - 0:02:20 - Ep 18 | r2l: acc of top [1, 10, 50] = [0.4384 0.6432 0.8215], mr = 42.161, mrr = 0.507, Loss = 111.7032
INFO - 12/17/25 16:08:27 - 0:02:20 - Best model update in Ep 18: MRR from [0.48771931313806177] --> [0.5054334550213753] ... 
Train | Ep [18/250] Step [39/500] LR [0.00025] Loss 111.70317 :   8%|████▊                                                          | 19/250 [01:58<24:00,  6.24s/it]Train | Ep [19/250] Step [41/500] LR [0.00027] Loss 107.34133 :   8%|████▊                                                          | 19/250 [02:00<24:00,  6.24s/it]INFO - 12/17/25 16:08:33 - 0:02:26 - Ep 19 | l2r: acc of top [1, 10, 50] = [0.463  0.6759 0.8579], mr = 33.556, mrr = 0.534, Loss = 107.3413
INFO - 12/17/25 16:08:33 - 0:02:26 - Ep 19 | r2l: acc of top [1, 10, 50] = [0.4634 0.686  0.8545], mr = 33.601, mrr = 0.536, Loss = 107.3413
INFO - 12/17/25 16:08:33 - 0:02:26 - Best model update in Ep 19: MRR from [0.5054334550213753] --> [0.5338550296364798] ... 
Train | Ep [19/250] Step [41/500] LR [0.00027] Loss 107.34133 :   8%|█████                                                          | 20/250 [02:05<23:55,  6.24s/it]Train | Ep [20/250] Step [43/500] LR [0.00028] Loss 102.79731 :   8%|█████                                                          | 20/250 [02:07<23:55,  6.24s/it]INFO - 12/17/25 16:08:39 - 0:02:33 - Ep 20 | l2r: acc of top [1, 10, 50] = [0.4907 0.7257 0.8891], mr = 25.468, mrr = 0.568, Loss = 102.7973
INFO - 12/17/25 16:08:39 - 0:02:33 - Ep 20 | r2l: acc of top [1, 10, 50] = [0.4964 0.7322 0.8892], mr = 25.708, mrr = 0.573, Loss = 102.7973
INFO - 12/17/25 16:08:39 - 0:02:33 - Best model update in Ep 20: MRR from [0.5338550296364798] --> [0.568176465439731] ... 
Train | Ep [20/250] Step [43/500] LR [0.00028] Loss 102.79731 :   8%|█████▎                                                         | 21/250 [02:11<23:58,  6.28s/it]Train | Ep [21/250] Step [45/500] LR [0.00029] Loss 97.50653 :   8%|█████▍                                                          | 21/250 [02:13<23:58,  6.28s/it]INFO - 12/17/25 16:08:46 - 0:02:39 - Ep 21 | l2r: acc of top [1, 10, 50] = [0.5258 0.7723 0.9175], mr = 19.583, mrr = 0.608, Loss = 97.5065
INFO - 12/17/25 16:08:46 - 0:02:39 - Ep 21 | r2l: acc of top [1, 10, 50] = [0.5286 0.7783 0.9152], mr = 19.874, mrr = 0.610, Loss = 97.5065
INFO - 12/17/25 16:08:46 - 0:02:39 - Best model update in Ep 21: MRR from [0.568176465439731] --> [0.6075998288700556] ... 
Train | Ep [21/250] Step [45/500] LR [0.00029] Loss 97.50653 :   9%|█████▋                                                          | 22/250 [02:17<24:00,  6.32s/it]Train | Ep [22/250] Step [47/500] LR [0.00031] Loss 92.25679 :   9%|█████▋                                                          | 22/250 [02:19<24:00,  6.32s/it]INFO - 12/17/25 16:08:52 - 0:02:46 - Ep 22 | l2r: acc of top [1, 10, 50] = [0.5582 0.8064 0.9353], mr = 15.673, mrr = 0.640, Loss = 92.2568
INFO - 12/17/25 16:08:52 - 0:02:46 - Ep 22 | r2l: acc of top [1, 10, 50] = [0.5535 0.8107 0.9345], mr = 15.915, mrr = 0.638, Loss = 92.2568
INFO - 12/17/25 16:08:52 - 0:02:46 - Best model update in Ep 22: MRR from [0.6075998288700556] --> [0.6403130298895174] ... 
Train | Ep [22/250] Step [47/500] LR [0.00031] Loss 92.25679 :   9%|█████▉                                                          | 23/250 [02:24<23:54,  6.32s/it]Train | Ep [23/250] Step [49/500] LR [0.00032] Loss 88.35632 :   9%|█████▉                                                          | 23/250 [02:26<23:54,  6.32s/it]INFO - 12/17/25 16:08:58 - 0:02:52 - Ep 23 | l2r: acc of top [1, 10, 50] = [0.5775 0.8331 0.9481], mr = 12.775, mrr = 0.661, Loss = 88.3563
INFO - 12/17/25 16:08:58 - 0:02:52 - Ep 23 | r2l: acc of top [1, 10, 50] = [0.5716 0.835  0.9476], mr = 12.864, mrr = 0.658, Loss = 88.3563
INFO - 12/17/25 16:08:58 - 0:02:52 - Best model update in Ep 23: MRR from [0.6403130298895174] --> [0.6614015213470551] ... 
Train | Ep [23/250] Step [49/500] LR [0.00032] Loss 88.35632 :  10%|██████▏                                                         | 24/250 [02:30<23:25,  6.22s/it]Train | Ep [24/250] Step [51/500] LR [0.00033] Loss 85.07730 :  10%|██████▏                                                         | 24/250 [02:32<23:25,  6.22s/it]INFO - 12/17/25 16:09:04 - 0:02:58 - Ep 24 | l2r: acc of top [1, 10, 50] = [0.5872 0.849  0.9566], mr = 10.724, mrr = 0.674, Loss = 85.0773
INFO - 12/17/25 16:09:04 - 0:02:58 - Ep 24 | r2l: acc of top [1, 10, 50] = [0.5851 0.8518 0.9567], mr = 10.767, mrr = 0.673, Loss = 85.0773
INFO - 12/17/25 16:09:04 - 0:02:58 - Best model update in Ep 24: MRR from [0.6614015213470551] --> [0.673844289286131] ... 
Train | Ep [24/250] Step [51/500] LR [0.00033] Loss 85.07730 :  10%|██████▍                                                         | 25/250 [02:36<23:06,  6.16s/it]Train | Ep [25/250] Step [53/500] LR [0.00035] Loss 81.75049 :  10%|██████▍                                                         | 25/250 [02:38<23:06,  6.16s/it]INFO - 12/17/25 16:09:10 - 0:03:04 - Ep 25 | l2r: acc of top [1, 10, 50] = [0.6015 0.8623 0.9637], mr = 9.076, mrr = 0.688, Loss = 81.7505
INFO - 12/17/25 16:09:10 - 0:03:04 - Ep 25 | r2l: acc of top [1, 10, 50] = [0.5988 0.8652 0.9659], mr = 9.130, mrr = 0.688, Loss = 81.7505
INFO - 12/17/25 16:09:10 - 0:03:04 - Best model update in Ep 25: MRR from [0.673844289286131] --> [0.6882924767101455] ... 
Train | Ep [25/250] Step [53/500] LR [0.00035] Loss 81.75049 :  10%|██████▋                                                         | 26/250 [02:42<22:58,  6.16s/it]Train | Ep [26/250] Step [55/500] LR [0.00036] Loss 79.42878 :  10%|██████▋                                                         | 26/250 [02:44<22:58,  6.16s/it]INFO - 12/17/25 16:09:16 - 0:03:10 - Ep 26 | l2r: acc of top [1, 10, 50] = [0.6168 0.8794 0.9714], mr = 7.666, mrr = 0.704, Loss = 79.4288
INFO - 12/17/25 16:09:16 - 0:03:10 - Ep 26 | r2l: acc of top [1, 10, 50] = [0.6154 0.881  0.972 ], mr = 7.740, mrr = 0.704, Loss = 79.4288
INFO - 12/17/25 16:09:16 - 0:03:10 - Best model update in Ep 26: MRR from [0.6882924767101455] --> [0.7036902646048458] ... 
Train | Ep [26/250] Step [55/500] LR [0.00036] Loss 79.42878 :  11%|██████▉                                                         | 27/250 [02:48<23:04,  6.21s/it]Train | Ep [27/250] Step [57/500] LR [0.00037] Loss 77.03131 :  11%|██████▉                                                         | 27/250 [02:50<23:04,  6.21s/it]INFO - 12/17/25 16:09:23 - 0:03:16 - Ep 27 | l2r: acc of top [1, 10, 50] = [0.633  0.8922 0.9774], mr = 6.471, mrr = 0.720, Loss = 77.0313
INFO - 12/17/25 16:09:23 - 0:03:16 - Ep 27 | r2l: acc of top [1, 10, 50] = [0.6333 0.8953 0.9772], mr = 6.603, mrr = 0.720, Loss = 77.0313
INFO - 12/17/25 16:09:23 - 0:03:16 - Best model update in Ep 27: MRR from [0.7036902646048458] --> [0.7202692295948563] ... 
Train | Ep [27/250] Step [57/500] LR [0.00037] Loss 77.03131 :  11%|███████▏                                                        | 28/250 [02:54<23:01,  6.22s/it]Train | Ep [28/250] Step [59/500] LR [0.00039] Loss 74.07745 :  11%|███████▏                                                        | 28/250 [02:56<23:01,  6.22s/it]INFO - 12/17/25 16:09:29 - 0:03:23 - Ep 28 | l2r: acc of top [1, 10, 50] = [0.6474 0.904  0.9819], mr = 5.535, mrr = 0.734, Loss = 74.0775
INFO - 12/17/25 16:09:29 - 0:03:23 - Ep 28 | r2l: acc of top [1, 10, 50] = [0.6502 0.9071 0.9819], mr = 5.712, mrr = 0.735, Loss = 74.0775
INFO - 12/17/25 16:09:29 - 0:03:23 - Best model update in Ep 28: MRR from [0.7202692295948563] --> [0.7343519172152356] ... 
Train | Ep [28/250] Step [59/500] LR [0.00039] Loss 74.07745 :  12%|███████▍                                                        | 29/250 [03:01<23:03,  6.26s/it]Train | Ep [29/250] Step [61/500] LR [0.00040] Loss 71.85868 :  12%|███████▍                                                        | 29/250 [03:03<23:03,  6.26s/it]INFO - 12/17/25 16:09:35 - 0:03:29 - Ep 29 | l2r: acc of top [1, 10, 50] = [0.6613 0.9144 0.9843], mr = 4.948, mrr = 0.748, Loss = 71.8587
INFO - 12/17/25 16:09:35 - 0:03:29 - Ep 29 | r2l: acc of top [1, 10, 50] = [0.6625 0.9167 0.9852], mr = 5.153, mrr = 0.748, Loss = 71.8587
INFO - 12/17/25 16:09:35 - 0:03:29 - Best model update in Ep 29: MRR from [0.7343519172152356] --> [0.7482624444049443] ... 
Train | Ep [29/250] Step [61/500] LR [0.00040] Loss 71.85868 :  12%|███████▋                                                        | 30/250 [03:07<23:01,  6.28s/it]Train | Ep [30/250] Step [63/500] LR [0.00041] Loss 69.80445 :  12%|███████▋                                                        | 30/250 [03:09<23:01,  6.28s/it]INFO - 12/17/25 16:09:42 - 0:03:35 - Ep 30 | l2r: acc of top [1, 10, 50] = [0.6742 0.9225 0.9871], mr = 4.511, mrr = 0.760, Loss = 69.8044
INFO - 12/17/25 16:09:42 - 0:03:35 - Ep 30 | r2l: acc of top [1, 10, 50] = [0.6753 0.9236 0.9872], mr = 4.736, mrr = 0.760, Loss = 69.8044
INFO - 12/17/25 16:09:42 - 0:03:35 - Best model update in Ep 30: MRR from [0.7482624444049443] --> [0.7601468084556461] ... 
Train | Ep [30/250] Step [63/500] LR [0.00041] Loss 69.80445 :  12%|███████▉                                                        | 31/250 [03:13<23:04,  6.32s/it]Train | Ep [31/250] Step [65/500] LR [0.00043] Loss 67.41951 :  12%|███████▉                                                        | 31/250 [03:15<23:04,  6.32s/it]INFO - 12/17/25 16:09:48 - 0:03:42 - Ep 31 | l2r: acc of top [1, 10, 50] = [0.6852 0.9281 0.9886], mr = 4.263, mrr = 0.770, Loss = 67.4195
INFO - 12/17/25 16:09:48 - 0:03:42 - Ep 31 | r2l: acc of top [1, 10, 50] = [0.6844 0.9317 0.9881], mr = 4.471, mrr = 0.768, Loss = 67.4195
INFO - 12/17/25 16:09:48 - 0:03:42 - Best model update in Ep 31: MRR from [0.7601468084556461] --> [0.7700866501911104] ... 
Train | Ep [31/250] Step [65/500] LR [0.00043] Loss 67.41951 :  13%|████████▏                                                       | 32/250 [03:20<22:49,  6.28s/it]Train | Ep [32/250] Step [67/500] LR [0.00044] Loss 65.58053 :  13%|████████▏                                                       | 32/250 [03:22<22:49,  6.28s/it]INFO - 12/17/25 16:09:54 - 0:03:48 - Ep 32 | l2r: acc of top [1, 10, 50] = [0.6964 0.9344 0.9894], mr = 4.020, mrr = 0.780, Loss = 65.5805
INFO - 12/17/25 16:09:54 - 0:03:48 - Ep 32 | r2l: acc of top [1, 10, 50] = [0.6943 0.9366 0.9891], mr = 4.244, mrr = 0.777, Loss = 65.5805
INFO - 12/17/25 16:09:54 - 0:03:48 - Best model update in Ep 32: MRR from [0.7700866501911104] --> [0.779524998328602] ... 
Train | Ep [32/250] Step [67/500] LR [0.00044] Loss 65.58053 :  13%|████████▍                                                       | 33/250 [03:26<22:47,  6.30s/it]Train | Ep [33/250] Step [69/500] LR [0.00045] Loss 63.77808 :  13%|████████▍                                                       | 33/250 [03:28<22:47,  6.30s/it]INFO - 12/17/25 16:10:00 - 0:03:54 - Ep 33 | l2r: acc of top [1, 10, 50] = [0.7031 0.9378 0.9901], mr = 3.901, mrr = 0.786, Loss = 63.7781
INFO - 12/17/25 16:10:00 - 0:03:54 - Ep 33 | r2l: acc of top [1, 10, 50] = [0.7019 0.9407 0.99  ], mr = 4.099, mrr = 0.784, Loss = 63.7781
INFO - 12/17/25 16:10:00 - 0:03:54 - Best model update in Ep 33: MRR from [0.779524998328602] --> [0.7858554774976995] ... 
Train | Ep [33/250] Step [69/500] LR [0.00045] Loss 63.77808 :  14%|████████▋                                                       | 34/250 [03:32<22:34,  6.27s/it]Train | Ep [34/250] Step [71/500] LR [0.00047] Loss 62.40490 :  14%|████████▋                                                       | 34/250 [03:34<22:34,  6.27s/it]INFO - 12/17/25 16:10:07 - 0:04:00 - Ep 34 | l2r: acc of top [1, 10, 50] = [0.7095 0.9421 0.9908], mr = 3.770, mrr = 0.792, Loss = 62.4049
INFO - 12/17/25 16:10:07 - 0:04:00 - Ep 34 | r2l: acc of top [1, 10, 50] = [0.7098 0.9451 0.9904], mr = 3.979, mrr = 0.791, Loss = 62.4049
INFO - 12/17/25 16:10:07 - 0:04:00 - Best model update in Ep 34: MRR from [0.7858554774976995] --> [0.7918548750003492] ... 
Train | Ep [34/250] Step [71/500] LR [0.00047] Loss 62.40490 :  14%|████████▉                                                       | 35/250 [03:39<22:29,  6.28s/it]Train | Ep [35/250] Step [73/500] LR [0.00048] Loss 60.97988 :  14%|████████▉                                                       | 35/250 [03:41<22:29,  6.28s/it]INFO - 12/17/25 16:10:13 - 0:04:07 - Ep 35 | l2r: acc of top [1, 10, 50] = [0.7188 0.9465 0.9911], mr = 3.669, mrr = 0.799, Loss = 60.9799
INFO - 12/17/25 16:10:13 - 0:04:07 - Ep 35 | r2l: acc of top [1, 10, 50] = [0.716  0.9482 0.9902], mr = 3.878, mrr = 0.796, Loss = 60.9799
INFO - 12/17/25 16:10:13 - 0:04:07 - Best model update in Ep 35: MRR from [0.7918548750003492] --> [0.7988350010388015] ... 
Train | Ep [35/250] Step [73/500] LR [0.00048] Loss 60.97988 :  14%|█████████▏                                                      | 36/250 [03:45<22:12,  6.22s/it]Train | Ep [36/250] Step [75/500] LR [0.00049] Loss 59.53178 :  14%|█████████▏                                                      | 36/250 [03:47<22:12,  6.22s/it]INFO - 12/17/25 16:10:19 - 0:04:13 - Ep 36 | l2r: acc of top [1, 10, 50] = [0.7242 0.9503 0.9911], mr = 3.602, mrr = 0.804, Loss = 59.5318
INFO - 12/17/25 16:10:19 - 0:04:13 - Ep 36 | r2l: acc of top [1, 10, 50] = [0.7215 0.9508 0.9904], mr = 3.836, mrr = 0.801, Loss = 59.5318
INFO - 12/17/25 16:10:19 - 0:04:13 - Best model update in Ep 36: MRR from [0.7988350010388015] --> [0.8038661294072597] ... 
Train | Ep [36/250] Step [75/500] LR [0.00049] Loss 59.53178 :  15%|█████████▍                                                      | 37/250 [03:51<22:05,  6.22s/it]Train | Ep [37/250] Step [77/500] LR [0.00050] Loss 58.23753 :  15%|█████████▍                                                      | 37/250 [03:53<22:05,  6.22s/it]INFO - 12/17/25 16:10:25 - 0:04:19 - Ep 37 | l2r: acc of top [1, 10, 50] = [0.7295 0.9522 0.9915], mr = 3.559, mrr = 0.808, Loss = 58.2375
INFO - 12/17/25 16:10:25 - 0:04:19 - Ep 37 | r2l: acc of top [1, 10, 50] = [0.7272 0.9542 0.9903], mr = 3.773, mrr = 0.806, Loss = 58.2375
INFO - 12/17/25 16:10:25 - 0:04:19 - Best model update in Ep 37: MRR from [0.8038661294072597] --> [0.8083411646070793] ... 
Train | Ep [37/250] Step [77/500] LR [0.00050] Loss 58.23753 :  15%|█████████▋                                                      | 38/250 [03:57<22:05,  6.25s/it]Train | Ep [38/250] Step [79/500] LR [0.00050] Loss 56.72412 :  15%|█████████▋                                                      | 38/250 [03:59<22:05,  6.25s/it]INFO - 12/17/25 16:10:32 - 0:04:25 - Ep 38 | l2r: acc of top [1, 10, 50] = [0.7334 0.9539 0.9917], mr = 3.541, mrr = 0.812, Loss = 56.7241
INFO - 12/17/25 16:10:32 - 0:04:25 - Ep 38 | r2l: acc of top [1, 10, 50] = [0.7338 0.9551 0.9905], mr = 3.766, mrr = 0.811, Loss = 56.7241
INFO - 12/17/25 16:10:32 - 0:04:25 - Best model update in Ep 38: MRR from [0.8083411646070793] --> [0.8117939396107798] ... 
Train | Ep [38/250] Step [79/500] LR [0.00050] Loss 56.72412 :  16%|█████████▉                                                      | 39/250 [04:03<22:04,  6.28s/it]Train | Ep [39/250] Step [81/500] LR [0.00050] Loss 55.66329 :  16%|█████████▉                                                      | 39/250 [04:06<22:04,  6.28s/it]INFO - 12/17/25 16:10:38 - 0:04:32 - Ep 39 | l2r: acc of top [1, 10, 50] = [0.7391 0.9545 0.9916], mr = 3.507, mrr = 0.816, Loss = 55.6633
INFO - 12/17/25 16:10:38 - 0:04:32 - Ep 39 | r2l: acc of top [1, 10, 50] = [0.7373 0.9555 0.9905], mr = 3.757, mrr = 0.814, Loss = 55.6633
INFO - 12/17/25 16:10:38 - 0:04:32 - Best model update in Ep 39: MRR from [0.8117939396107798] --> [0.815790711036608] ... 
Train | Ep [39/250] Step [81/500] LR [0.00050] Loss 55.66329 :  16%|██████████▏                                                     | 40/250 [04:10<22:10,  6.34s/it]Train | Ep [40/250] Step [83/500] LR [0.00050] Loss 54.81724 :  16%|██████████▏                                                     | 40/250 [04:12<22:10,  6.34s/it]INFO - 12/17/25 16:10:45 - 0:04:38 - Ep 40 | l2r: acc of top [1, 10, 50] = [0.7435 0.9556 0.9918], mr = 3.469, mrr = 0.819, Loss = 54.8172
INFO - 12/17/25 16:10:45 - 0:04:38 - Ep 40 | r2l: acc of top [1, 10, 50] = [0.7416 0.9567 0.9902], mr = 3.736, mrr = 0.817, Loss = 54.8172
INFO - 12/17/25 16:10:45 - 0:04:38 - Best model update in Ep 40: MRR from [0.815790711036608] --> [0.8194579198647209] ... 
Train | Ep [40/250] Step [83/500] LR [0.00050] Loss 54.81724 :  16%|██████████▍                                                     | 41/250 [04:16<22:08,  6.36s/it]Train | Ep [41/250] Step [85/500] LR [0.00050] Loss 54.18635 :  16%|██████████▍                                                     | 41/250 [04:19<22:08,  6.36s/it]INFO - 12/17/25 16:10:51 - 0:04:45 - Ep 41 | l2r: acc of top [1, 10, 50] = [0.7488 0.9562 0.9921], mr = 3.477, mrr = 0.822, Loss = 54.1864
INFO - 12/17/25 16:10:51 - 0:04:45 - Ep 41 | r2l: acc of top [1, 10, 50] = [0.7447 0.9574 0.9904], mr = 3.731, mrr = 0.820, Loss = 54.1864
INFO - 12/17/25 16:10:51 - 0:04:45 - Best model update in Ep 41: MRR from [0.8194579198647209] --> [0.8222930889553878] ... 
Train | Ep [41/250] Step [85/500] LR [0.00050] Loss 54.18635 :  17%|██████████▊                                                     | 42/250 [04:23<22:08,  6.39s/it]Train | Ep [42/250] Step [87/500] LR [0.00050] Loss 53.45437 :  17%|██████████▊                                                     | 42/250 [04:25<22:08,  6.39s/it]INFO - 12/17/25 16:10:57 - 0:04:51 - Ep 42 | l2r: acc of top [1, 10, 50] = [0.7529 0.9571 0.9915], mr = 3.427, mrr = 0.826, Loss = 53.4544
INFO - 12/17/25 16:10:57 - 0:04:51 - Ep 42 | r2l: acc of top [1, 10, 50] = [0.7482 0.9579 0.9903], mr = 3.711, mrr = 0.822, Loss = 53.4544
INFO - 12/17/25 16:10:57 - 0:04:51 - Best model update in Ep 42: MRR from [0.8222930889553878] --> [0.8256092926381351] ... 
Train | Ep [42/250] Step [87/500] LR [0.00050] Loss 53.45437 :  17%|███████████                                                     | 43/250 [04:29<21:59,  6.37s/it]Train | Ep [43/250] Step [89/500] LR [0.00050] Loss 52.48891 :  17%|███████████                                                     | 43/250 [04:31<21:59,  6.37s/it]INFO - 12/17/25 16:11:04 - 0:04:57 - Ep 43 | l2r: acc of top [1, 10, 50] = [0.7534 0.9569 0.9917], mr = 3.438, mrr = 0.826, Loss = 52.4889
INFO - 12/17/25 16:11:04 - 0:04:57 - Ep 43 | r2l: acc of top [1, 10, 50] = [0.751  0.9582 0.9905], mr = 3.689, mrr = 0.824, Loss = 52.4889
INFO - 12/17/25 16:11:04 - 0:04:57 - Best model update in Ep 43: MRR from [0.8256092926381351] --> [0.8260039710633351] ... 
Train | Ep [43/250] Step [89/500] LR [0.00050] Loss 52.48891 :  18%|███████████▎                                                    | 44/250 [04:36<21:52,  6.37s/it]Train | Ep [44/250] Step [91/500] LR [0.00050] Loss 51.60813 :  18%|███████████▎                                                    | 44/250 [04:38<21:52,  6.37s/it]INFO - 12/17/25 16:11:10 - 0:05:04 - Ep 44 | l2r: acc of top [1, 10, 50] = [0.7567 0.9578 0.9916], mr = 3.421, mrr = 0.828, Loss = 51.6081
INFO - 12/17/25 16:11:10 - 0:05:04 - Ep 44 | r2l: acc of top [1, 10, 50] = [0.752  0.959  0.9906], mr = 3.680, mrr = 0.825, Loss = 51.6081
INFO - 12/17/25 16:11:10 - 0:05:04 - Best model update in Ep 44: MRR from [0.8260039710633351] --> [0.8280051142351524] ... 
Train | Ep [44/250] Step [91/500] LR [0.00050] Loss 51.60813 :  18%|███████████▌                                                    | 45/250 [04:42<21:49,  6.39s/it]Train | Ep [45/250] Step [93/500] LR [0.00050] Loss 51.09798 :  18%|███████████▌                                                    | 45/250 [04:44<21:49,  6.39s/it]INFO - 12/17/25 16:11:17 - 0:05:10 - Ep 45 | l2r: acc of top [1, 10, 50] = [0.7593 0.9579 0.9913], mr = 3.396, mrr = 0.830, Loss = 51.0980
INFO - 12/17/25 16:11:17 - 0:05:10 - Ep 45 | r2l: acc of top [1, 10, 50] = [0.7553 0.9596 0.9902], mr = 3.660, mrr = 0.828, Loss = 51.0980
INFO - 12/17/25 16:11:17 - 0:05:10 - Best model update in Ep 45: MRR from [0.8280051142351524] --> [0.8300536950220235] ... 
Train | Ep [45/250] Step [93/500] LR [0.00050] Loss 51.09798 :  18%|███████████▊                                                    | 46/250 [04:48<21:40,  6.37s/it]Train | Ep [46/250] Step [95/500] LR [0.00050] Loss 50.34255 :  18%|███████████▊                                                    | 46/250 [04:50<21:40,  6.37s/it]INFO - 12/17/25 16:11:23 - 0:05:17 - Ep 46 | l2r: acc of top [1, 10, 50] = [0.7593 0.9586 0.9914], mr = 3.441, mrr = 0.830, Loss = 50.3426
INFO - 12/17/25 16:11:23 - 0:05:17 - Ep 46 | r2l: acc of top [1, 10, 50] = [0.7549 0.9593 0.9906], mr = 3.686, mrr = 0.827, Loss = 50.3426
INFO - 12/17/25 16:11:23 - 0:05:17 - Best model update in Ep 46: MRR from [0.8300536950220235] --> [0.8301350874853094] ... 
Train | Ep [46/250] Step [95/500] LR [0.00050] Loss 50.34255 :  19%|████████████                                                    | 47/250 [04:55<21:28,  6.35s/it]Train | Ep [47/250] Step [97/500] LR [0.00050] Loss 49.65065 :  19%|████████████                                                    | 47/250 [04:57<21:28,  6.35s/it]INFO - 12/17/25 16:11:29 - 0:05:23 - Ep 47 | l2r: acc of top [1, 10, 50] = [0.7622 0.9589 0.991 ], mr = 3.420, mrr = 0.832, Loss = 49.6506
INFO - 12/17/25 16:11:29 - 0:05:23 - Ep 47 | r2l: acc of top [1, 10, 50] = [0.7588 0.96   0.99  ], mr = 3.685, mrr = 0.830, Loss = 49.6506
INFO - 12/17/25 16:11:29 - 0:05:23 - Best model update in Ep 47: MRR from [0.8301350874853094] --> [0.8321173438343529] ... 
Train | Ep [47/250] Step [97/500] LR [0.00050] Loss 49.65065 :  19%|████████████▎                                                   | 48/250 [05:01<21:14,  6.31s/it]Train | Ep [48/250] Step [99/500] LR [0.00050] Loss 49.01775 :  19%|████████████▎                                                   | 48/250 [05:03<21:14,  6.31s/it]INFO - 12/17/25 16:11:35 - 0:05:29 - Ep 48 | l2r: acc of top [1, 10, 50] = [0.7646 0.9588 0.9911], mr = 3.443, mrr = 0.834, Loss = 49.0177
INFO - 12/17/25 16:11:35 - 0:05:29 - Ep 48 | r2l: acc of top [1, 10, 50] = [0.7612 0.9598 0.9899], mr = 3.677, mrr = 0.832, Loss = 49.0177
INFO - 12/17/25 16:11:35 - 0:05:29 - Best model update in Ep 48: MRR from [0.8321173438343529] --> [0.8337436389007997] ... 
Train | Ep [48/250] Step [99/500] LR [0.00050] Loss 49.01775 :  20%|████████████▌                                                   | 49/250 [05:07<20:59,  6.27s/it]Train | Ep [49/250] Step [101/500] LR [0.00050] Loss 48.61901 :  20%|████████████▎                                                  | 49/250 [05:09<20:59,  6.27s/it]INFO - 12/17/25 16:11:42 - 0:05:35 - Ep 49 | l2r: acc of top [1, 10, 50] = [0.7641 0.9595 0.9912], mr = 3.460, mrr = 0.833, Loss = 48.6190
INFO - 12/17/25 16:11:42 - 0:05:35 - Ep 49 | r2l: acc of top [1, 10, 50] = [0.7594 0.9592 0.9902], mr = 3.729, mrr = 0.831, Loss = 48.6190
Train | Ep [49/250] Step [101/500] LR [0.00050] Loss 48.61901 :  20%|████████████▌                                                  | 50/250 [05:13<20:57,  6.29s/it]Train | Ep [50/250] Step [103/500] LR [0.00050] Loss 47.95574 :  20%|████████████▌                                                  | 50/250 [05:15<20:57,  6.29s/it]INFO - 12/17/25 16:11:48 - 0:05:42 - Ep 50 | l2r: acc of top [1, 10, 50] = [0.7661 0.9596 0.9912], mr = 3.461, mrr = 0.835, Loss = 47.9557
INFO - 12/17/25 16:11:48 - 0:05:42 - Ep 50 | r2l: acc of top [1, 10, 50] = [0.7634 0.9598 0.99  ], mr = 3.722, mrr = 0.834, Loss = 47.9557
INFO - 12/17/25 16:11:48 - 0:05:42 - Best model update in Ep 50: MRR from [0.8337436389007997] --> [0.8348922274535069] ... 
Train | Ep [50/250] Step [103/500] LR [0.00050] Loss 47.95574 :  20%|████████████▊                                                  | 51/250 [05:20<20:52,  6.29s/it]Train | Ep [51/250] Step [105/500] LR [0.00049] Loss 47.76011 :  20%|████████████▊                                                  | 51/250 [05:22<20:52,  6.29s/it]INFO - 12/17/25 16:11:54 - 0:05:48 - Ep 51 | l2r: acc of top [1, 10, 50] = [0.7671 0.9596 0.991 ], mr = 3.467, mrr = 0.835, Loss = 47.7601
INFO - 12/17/25 16:11:54 - 0:05:48 - Ep 51 | r2l: acc of top [1, 10, 50] = [0.7637 0.9594 0.9901], mr = 3.739, mrr = 0.834, Loss = 47.7601
INFO - 12/17/25 16:11:54 - 0:05:48 - Best model update in Ep 51: MRR from [0.8348922274535069] --> [0.8354896920943706] ... 
Train | Ep [51/250] Step [105/500] LR [0.00049] Loss 47.76011 :  21%|█████████████                                                  | 52/250 [05:26<20:49,  6.31s/it]Train | Ep [52/250] Step [107/500] LR [0.00049] Loss 47.25991 :  21%|█████████████                                                  | 52/250 [05:28<20:49,  6.31s/it]INFO - 12/17/25 16:12:01 - 0:05:54 - Ep 52 | l2r: acc of top [1, 10, 50] = [0.7684 0.96   0.991 ], mr = 3.482, mrr = 0.836, Loss = 47.2599
INFO - 12/17/25 16:12:01 - 0:05:54 - Ep 52 | r2l: acc of top [1, 10, 50] = [0.7663 0.9594 0.9898], mr = 3.737, mrr = 0.836, Loss = 47.2599
INFO - 12/17/25 16:12:01 - 0:05:54 - Best model update in Ep 52: MRR from [0.8354896920943706] --> [0.8363285944934568] ... 
Train | Ep [52/250] Step [107/500] LR [0.00049] Loss 47.25991 :  21%|█████████████▎                                                 | 53/250 [05:32<20:47,  6.33s/it]Train | Ep [53/250] Step [109/500] LR [0.00049] Loss 46.70070 :  21%|█████████████▎                                                 | 53/250 [05:35<20:47,  6.33s/it]INFO - 12/17/25 16:12:07 - 0:06:01 - Ep 53 | l2r: acc of top [1, 10, 50] = [0.7676 0.9596 0.991 ], mr = 3.476, mrr = 0.836, Loss = 46.7007
INFO - 12/17/25 16:12:07 - 0:06:01 - Ep 53 | r2l: acc of top [1, 10, 50] = [0.7658 0.9593 0.9897], mr = 3.744, mrr = 0.836, Loss = 46.7007
Train | Ep [53/250] Step [109/500] LR [0.00049] Loss 46.70070 :  22%|█████████████▌                                                 | 54/250 [05:39<20:46,  6.36s/it]Train | Ep [54/250] Step [111/500] LR [0.00049] Loss 46.19986 :  22%|█████████████▌                                                 | 54/250 [05:41<20:46,  6.36s/it]INFO - 12/17/25 16:12:13 - 0:06:07 - Ep 54 | l2r: acc of top [1, 10, 50] = [0.7698 0.9598 0.9904], mr = 3.494, mrr = 0.837, Loss = 46.1999
INFO - 12/17/25 16:12:13 - 0:06:07 - Ep 54 | r2l: acc of top [1, 10, 50] = [0.7678 0.9591 0.9897], mr = 3.756, mrr = 0.837, Loss = 46.1999
INFO - 12/17/25 16:12:13 - 0:06:07 - Best model update in Ep 54: MRR from [0.8363285944934568] --> [0.8374099627198508] ... 
Train | Ep [54/250] Step [111/500] LR [0.00049] Loss 46.19986 :  22%|█████████████▊                                                 | 55/250 [05:45<20:40,  6.36s/it]Train | Ep [55/250] Step [113/500] LR [0.00049] Loss 45.59694 :  22%|█████████████▊                                                 | 55/250 [05:47<20:40,  6.36s/it]INFO - 12/17/25 16:12:20 - 0:06:13 - Ep 55 | l2r: acc of top [1, 10, 50] = [0.7704 0.9594 0.9908], mr = 3.487, mrr = 0.838, Loss = 45.5969
INFO - 12/17/25 16:12:20 - 0:06:13 - Ep 55 | r2l: acc of top [1, 10, 50] = [0.77   0.9592 0.9894], mr = 3.762, mrr = 0.838, Loss = 45.5969
INFO - 12/17/25 16:12:20 - 0:06:13 - Best model update in Ep 55: MRR from [0.8374099627198508] --> [0.8381457682882861] ... 
Train | Ep [55/250] Step [113/500] LR [0.00049] Loss 45.59694 :  22%|██████████████                                                 | 56/250 [05:51<20:33,  6.36s/it]Train | Ep [56/250] Step [115/500] LR [0.00049] Loss 45.37013 :  22%|██████████████                                                 | 56/250 [05:54<20:33,  6.36s/it]INFO - 12/17/25 16:12:26 - 0:06:20 - Ep 56 | l2r: acc of top [1, 10, 50] = [0.7717 0.9592 0.9904], mr = 3.501, mrr = 0.839, Loss = 45.3701
INFO - 12/17/25 16:12:26 - 0:06:20 - Ep 56 | r2l: acc of top [1, 10, 50] = [0.7701 0.9589 0.9893], mr = 3.792, mrr = 0.838, Loss = 45.3701
INFO - 12/17/25 16:12:26 - 0:06:20 - Best model update in Ep 56: MRR from [0.8381457682882861] --> [0.8387369450523317] ... 
Train | Ep [56/250] Step [115/500] LR [0.00049] Loss 45.37013 :  23%|██████████████▎                                                | 57/250 [05:58<20:24,  6.35s/it]Train | Ep [57/250] Step [117/500] LR [0.00049] Loss 45.12061 :  23%|██████████████▎                                                | 57/250 [06:00<20:24,  6.35s/it]INFO - 12/17/25 16:12:32 - 0:06:26 - Ep 57 | l2r: acc of top [1, 10, 50] = [0.7723 0.9589 0.9907], mr = 3.496, mrr = 0.839, Loss = 45.1206
INFO - 12/17/25 16:12:32 - 0:06:26 - Ep 57 | r2l: acc of top [1, 10, 50] = [0.7715 0.9597 0.9891], mr = 3.786, mrr = 0.839, Loss = 45.1206
INFO - 12/17/25 16:12:32 - 0:06:26 - Best model update in Ep 57: MRR from [0.8387369450523317] --> [0.8392260615116096] ... 
Train | Ep [57/250] Step [117/500] LR [0.00049] Loss 45.12061 :  23%|██████████████▌                                                | 58/250 [06:04<20:13,  6.32s/it]Train | Ep [58/250] Step [119/500] LR [0.00049] Loss 44.69186 :  23%|██████████████▌                                                | 58/250 [06:06<20:13,  6.32s/it]INFO - 12/17/25 16:12:39 - 0:06:32 - Ep 58 | l2r: acc of top [1, 10, 50] = [0.7724 0.9586 0.9904], mr = 3.517, mrr = 0.839, Loss = 44.6919
INFO - 12/17/25 16:12:39 - 0:06:32 - Ep 58 | r2l: acc of top [1, 10, 50] = [0.7718 0.9593 0.9892], mr = 3.840, mrr = 0.839, Loss = 44.6919
Train | Ep [58/250] Step [119/500] LR [0.00049] Loss 44.69186 :  24%|██████████████▊                                                | 59/250 [06:10<20:07,  6.32s/it]Train | Ep [59/250] Step [121/500] LR [0.00049] Loss 44.50351 :  24%|██████████████▊                                                | 59/250 [06:12<20:07,  6.32s/it]INFO - 12/17/25 16:12:45 - 0:06:38 - Ep 59 | l2r: acc of top [1, 10, 50] = [0.7739 0.9599 0.9907], mr = 3.512, mrr = 0.840, Loss = 44.5035
INFO - 12/17/25 16:12:45 - 0:06:38 - Ep 59 | r2l: acc of top [1, 10, 50] = [0.7732 0.9599 0.9895], mr = 3.831, mrr = 0.840, Loss = 44.5035
INFO - 12/17/25 16:12:45 - 0:06:38 - Best model update in Ep 59: MRR from [0.8392260615116096] --> [0.840154065809495] ... 
Train | Ep [59/250] Step [121/500] LR [0.00049] Loss 44.50351 :  24%|███████████████                                                | 60/250 [06:17<19:48,  6.26s/it]Train | Ep [60/250] Step [123/500] LR [0.00049] Loss 43.83286 :  24%|███████████████                                                | 60/250 [06:19<19:48,  6.26s/it]INFO - 12/17/25 16:12:51 - 0:06:45 - Ep 60 | l2r: acc of top [1, 10, 50] = [0.7732 0.9585 0.9901], mr = 3.570, mrr = 0.839, Loss = 43.8329
INFO - 12/17/25 16:12:51 - 0:06:45 - Ep 60 | r2l: acc of top [1, 10, 50] = [0.772  0.9594 0.9892], mr = 3.926, mrr = 0.839, Loss = 43.8329
Train | Ep [60/250] Step [123/500] LR [0.00049] Loss 43.83286 :  24%|███████████████▎                                               | 61/250 [06:23<19:44,  6.27s/it]Train | Ep [61/250] Step [125/500] LR [0.00048] Loss 43.92180 :  24%|███████████████▎                                               | 61/250 [06:25<19:44,  6.27s/it]INFO - 12/17/25 16:12:57 - 0:06:51 - Ep 61 | l2r: acc of top [1, 10, 50] = [0.7766 0.9594 0.9905], mr = 3.548, mrr = 0.842, Loss = 43.9218
INFO - 12/17/25 16:12:57 - 0:06:51 - Ep 61 | r2l: acc of top [1, 10, 50] = [0.775  0.96   0.9896], mr = 3.873, mrr = 0.841, Loss = 43.9218
INFO - 12/17/25 16:12:57 - 0:06:51 - Best model update in Ep 61: MRR from [0.840154065809495] --> [0.8418106963441194] ... 
Train | Ep [61/250] Step [125/500] LR [0.00048] Loss 43.92180 :  25%|███████████████▌                                               | 62/250 [06:29<19:36,  6.26s/it]Train | Ep [62/250] Step [127/500] LR [0.00048] Loss 43.10771 :  25%|███████████████▌                                               | 62/250 [06:31<19:36,  6.26s/it]INFO - 12/17/25 16:13:04 - 0:06:57 - Ep 62 | l2r: acc of top [1, 10, 50] = [0.7747 0.959  0.99  ], mr = 3.608, mrr = 0.840, Loss = 43.1077
INFO - 12/17/25 16:13:04 - 0:06:57 - Ep 62 | r2l: acc of top [1, 10, 50] = [0.7733 0.9588 0.989 ], mr = 4.006, mrr = 0.840, Loss = 43.1077
Train | Ep [62/250] Step [127/500] LR [0.00048] Loss 43.10771 :  25%|███████████████▉                                               | 63/250 [06:35<19:34,  6.28s/it]Train | Ep [63/250] Step [129/500] LR [0.00048] Loss 43.19716 :  25%|███████████████▉                                               | 63/250 [06:37<19:34,  6.28s/it]INFO - 12/17/25 16:13:10 - 0:07:04 - Ep 63 | l2r: acc of top [1, 10, 50] = [0.7766 0.9595 0.9901], mr = 3.618, mrr = 0.842, Loss = 43.1972
INFO - 12/17/25 16:13:10 - 0:07:04 - Ep 63 | r2l: acc of top [1, 10, 50] = [0.7759 0.9597 0.9892], mr = 3.959, mrr = 0.842, Loss = 43.1972
Train | Ep [63/250] Step [129/500] LR [0.00048] Loss 43.19716 :  26%|████████████████▏                                              | 64/250 [06:42<19:27,  6.28s/it]Train | Ep [64/250] Step [131/500] LR [0.00048] Loss 42.87504 :  26%|████████████████▏                                              | 64/250 [06:44<19:27,  6.28s/it]INFO - 12/17/25 16:13:16 - 0:07:10 - Ep 64 | l2r: acc of top [1, 10, 50] = [0.7776 0.9596 0.9901], mr = 3.623, mrr = 0.842, Loss = 42.8750
INFO - 12/17/25 16:13:16 - 0:07:10 - Ep 64 | r2l: acc of top [1, 10, 50] = [0.7763 0.9596 0.9895], mr = 3.992, mrr = 0.842, Loss = 42.8750
INFO - 12/17/25 16:13:16 - 0:07:10 - Best model update in Ep 64: MRR from [0.8418106963441194] --> [0.8421208435112014] ... 
Train | Ep [64/250] Step [131/500] LR [0.00048] Loss 42.87504 :  26%|████████████████▍                                              | 65/250 [06:48<19:25,  6.30s/it]Train | Ep [65/250] Step [133/500] LR [0.00048] Loss 42.31914 :  26%|████████████████▍                                              | 65/250 [06:50<19:25,  6.30s/it]INFO - 12/17/25 16:13:23 - 0:07:16 - Ep 65 | l2r: acc of top [1, 10, 50] = [0.7775 0.9591 0.9903], mr = 3.678, mrr = 0.842, Loss = 42.3191
INFO - 12/17/25 16:13:23 - 0:07:16 - Ep 65 | r2l: acc of top [1, 10, 50] = [0.7761 0.9596 0.9896], mr = 4.029, mrr = 0.842, Loss = 42.3191
Train | Ep [65/250] Step [133/500] LR [0.00048] Loss 42.31914 :  26%|████████████████▋                                              | 66/250 [06:54<19:18,  6.29s/it]Train | Ep [66/250] Step [135/500] LR [0.00048] Loss 42.19009 :  26%|████████████████▋                                              | 66/250 [06:56<19:18,  6.29s/it]INFO - 12/17/25 16:13:29 - 0:07:22 - Ep 66 | l2r: acc of top [1, 10, 50] = [0.7778 0.9605 0.9901], mr = 3.649, mrr = 0.843, Loss = 42.1901
INFO - 12/17/25 16:13:29 - 0:07:22 - Ep 66 | r2l: acc of top [1, 10, 50] = [0.7778 0.9597 0.9892], mr = 4.011, mrr = 0.843, Loss = 42.1901
INFO - 12/17/25 16:13:29 - 0:07:22 - Best model update in Ep 66: MRR from [0.8421208435112014] --> [0.8425119541354167] ... 
Train | Ep [66/250] Step [135/500] LR [0.00048] Loss 42.19009 :  27%|████████████████▉                                              | 67/250 [07:01<19:10,  6.29s/it]Train | Ep [67/250] Step [137/500] LR [0.00048] Loss 41.83284 :  27%|████████████████▉                                              | 67/250 [07:03<19:10,  6.29s/it]INFO - 12/17/25 16:13:35 - 0:07:29 - Ep 67 | l2r: acc of top [1, 10, 50] = [0.7769 0.9598 0.99  ], mr = 3.711, mrr = 0.842, Loss = 41.8328
INFO - 12/17/25 16:13:35 - 0:07:29 - Ep 67 | r2l: acc of top [1, 10, 50] = [0.777  0.9583 0.9896], mr = 4.060, mrr = 0.842, Loss = 41.8328
Train | Ep [67/250] Step [137/500] LR [0.00048] Loss 41.83284 :  27%|█████████████████▏                                             | 68/250 [07:07<19:02,  6.28s/it]Train | Ep [68/250] Step [139/500] LR [0.00047] Loss 41.94121 :  27%|█████████████████▏                                             | 68/250 [07:09<19:02,  6.28s/it]INFO - 12/17/25 16:13:41 - 0:07:35 - Ep 68 | l2r: acc of top [1, 10, 50] = [0.7784 0.9599 0.9899], mr = 3.696, mrr = 0.843, Loss = 41.9412
INFO - 12/17/25 16:13:41 - 0:07:35 - Ep 68 | r2l: acc of top [1, 10, 50] = [0.7783 0.9596 0.9894], mr = 4.041, mrr = 0.843, Loss = 41.9412
INFO - 12/17/25 16:13:41 - 0:07:35 - Best model update in Ep 68: MRR from [0.8425119541354167] --> [0.8429685354738808] ... 
Train | Ep [68/250] Step [139/500] LR [0.00047] Loss 41.94121 :  28%|█████████████████▍                                             | 69/250 [07:13<18:57,  6.29s/it]Train | Ep [69/250] Step [141/500] LR [0.00047] Loss 41.54984 :  28%|█████████████████▍                                             | 69/250 [07:15<18:57,  6.29s/it]INFO - 12/17/25 16:13:48 - 0:07:41 - Ep 69 | l2r: acc of top [1, 10, 50] = [0.7768 0.9594 0.9897], mr = 3.754, mrr = 0.842, Loss = 41.5498
INFO - 12/17/25 16:13:48 - 0:07:41 - Ep 69 | r2l: acc of top [1, 10, 50] = [0.7776 0.959  0.9893], mr = 4.091, mrr = 0.842, Loss = 41.5498
Train | Ep [69/250] Step [141/500] LR [0.00047] Loss 41.54984 :  28%|█████████████████▋                                             | 70/250 [07:19<18:52,  6.29s/it]Train | Ep [70/250] Step [143/500] LR [0.00047] Loss 41.51239 :  28%|█████████████████▋                                             | 70/250 [07:22<18:52,  6.29s/it]INFO - 12/17/25 16:13:54 - 0:07:48 - Ep 70 | l2r: acc of top [1, 10, 50] = [0.7782 0.9595 0.9896], mr = 3.771, mrr = 0.843, Loss = 41.5124
INFO - 12/17/25 16:13:54 - 0:07:48 - Ep 70 | r2l: acc of top [1, 10, 50] = [0.7772 0.959  0.9891], mr = 4.110, mrr = 0.842, Loss = 41.5124
Train | Ep [70/250] Step [143/500] LR [0.00047] Loss 41.51239 :  28%|█████████████████▉                                             | 71/250 [07:26<18:44,  6.28s/it]Train | Ep [71/250] Step [145/500] LR [0.00047] Loss 41.07619 :  28%|█████████████████▉                                             | 71/250 [07:28<18:44,  6.28s/it]INFO - 12/17/25 16:14:00 - 0:07:54 - Ep 71 | l2r: acc of top [1, 10, 50] = [0.7795 0.9592 0.9895], mr = 3.794, mrr = 0.843, Loss = 41.0762
INFO - 12/17/25 16:14:00 - 0:07:54 - Ep 71 | r2l: acc of top [1, 10, 50] = [0.7784 0.9594 0.9893], mr = 4.137, mrr = 0.843, Loss = 41.0762
INFO - 12/17/25 16:14:00 - 0:07:54 - Best model update in Ep 71: MRR from [0.8429685354738808] --> [0.8432167426047215] ... 
Train | Ep [71/250] Step [145/500] LR [0.00047] Loss 41.07619 :  29%|██████████████████▏                                            | 72/250 [07:32<18:34,  6.26s/it]Train | Ep [72/250] Step [147/500] LR [0.00047] Loss 40.90018 :  29%|██████████████████▏                                            | 72/250 [07:34<18:34,  6.26s/it]INFO - 12/17/25 16:14:06 - 0:08:00 - Ep 72 | l2r: acc of top [1, 10, 50] = [0.7789 0.9593 0.9895], mr = 3.848, mrr = 0.843, Loss = 40.9002
INFO - 12/17/25 16:14:06 - 0:08:00 - Ep 72 | r2l: acc of top [1, 10, 50] = [0.7768 0.9585 0.9892], mr = 4.196, mrr = 0.842, Loss = 40.9002
Train | Ep [72/250] Step [147/500] LR [0.00047] Loss 40.90018 :  29%|██████████████████▍                                            | 73/250 [07:38<18:22,  6.23s/it]Train | Ep [73/250] Step [149/500] LR [0.00046] Loss 40.49830 :  29%|██████████████████▍                                            | 73/250 [07:40<18:22,  6.23s/it]INFO - 12/17/25 16:14:12 - 0:08:06 - Ep 73 | l2r: acc of top [1, 10, 50] = [0.7806 0.9599 0.9892], mr = 3.833, mrr = 0.844, Loss = 40.4983
INFO - 12/17/25 16:14:12 - 0:08:06 - Ep 73 | r2l: acc of top [1, 10, 50] = [0.7799 0.9592 0.989 ], mr = 4.214, mrr = 0.844, Loss = 40.4983
INFO - 12/17/25 16:14:12 - 0:08:06 - Best model update in Ep 73: MRR from [0.8432167426047215] --> [0.8439034752077078] ... 
Train | Ep [73/250] Step [149/500] LR [0.00046] Loss 40.49830 :  30%|██████████████████▋                                            | 74/250 [07:44<18:14,  6.22s/it]Train | Ep [74/250] Step [151/500] LR [0.00046] Loss 40.21835 :  30%|██████████████████▋                                            | 74/250 [07:46<18:14,  6.22s/it]INFO - 12/17/25 16:14:19 - 0:08:12 - Ep 74 | l2r: acc of top [1, 10, 50] = [0.7792 0.959  0.9891], mr = 3.895, mrr = 0.843, Loss = 40.2184
INFO - 12/17/25 16:14:19 - 0:08:12 - Ep 74 | r2l: acc of top [1, 10, 50] = [0.7777 0.9591 0.9891], mr = 4.262, mrr = 0.843, Loss = 40.2184
Train | Ep [74/250] Step [151/500] LR [0.00046] Loss 40.21835 :  30%|██████████████████▉                                            | 75/250 [07:50<18:10,  6.23s/it]Train | Ep [75/250] Step [153/500] LR [0.00046] Loss 40.44815 :  30%|██████████████████▉                                            | 75/250 [07:53<18:10,  6.23s/it]INFO - 12/17/25 16:14:25 - 0:08:19 - Ep 75 | l2r: acc of top [1, 10, 50] = [0.7809 0.9593 0.9892], mr = 3.867, mrr = 0.844, Loss = 40.4482
INFO - 12/17/25 16:14:25 - 0:08:19 - Ep 75 | r2l: acc of top [1, 10, 50] = [0.7789 0.9589 0.9893], mr = 4.280, mrr = 0.844, Loss = 40.4482
INFO - 12/17/25 16:14:25 - 0:08:19 - Best model update in Ep 75: MRR from [0.8439034752077078] --> [0.8441933614274134] ... 
Train | Ep [75/250] Step [153/500] LR [0.00046] Loss 40.44815 :  30%|███████████████████▏                                           | 76/250 [07:57<18:07,  6.25s/it]Train | Ep [76/250] Step [155/500] LR [0.00046] Loss 40.21429 :  30%|███████████████████▏                                           | 76/250 [07:59<18:07,  6.25s/it]INFO - 12/17/25 16:14:31 - 0:08:25 - Ep 76 | l2r: acc of top [1, 10, 50] = [0.779  0.959  0.9891], mr = 3.922, mrr = 0.843, Loss = 40.2143
INFO - 12/17/25 16:14:31 - 0:08:25 - Ep 76 | r2l: acc of top [1, 10, 50] = [0.7791 0.9581 0.989 ], mr = 4.324, mrr = 0.844, Loss = 40.2143
Train | Ep [76/250] Step [155/500] LR [0.00046] Loss 40.21429 :  31%|███████████████████▍                                           | 77/250 [08:03<18:00,  6.25s/it]Train | Ep [77/250] Step [157/500] LR [0.00046] Loss 39.79887 :  31%|███████████████████▍                                           | 77/250 [08:05<18:00,  6.25s/it]INFO - 12/17/25 16:14:38 - 0:08:31 - Ep 77 | l2r: acc of top [1, 10, 50] = [0.7806 0.9592 0.9895], mr = 3.927, mrr = 0.844, Loss = 39.7989
INFO - 12/17/25 16:14:38 - 0:08:31 - Ep 77 | r2l: acc of top [1, 10, 50] = [0.7784 0.9586 0.9894], mr = 4.357, mrr = 0.843, Loss = 39.7989
Train | Ep [77/250] Step [157/500] LR [0.00046] Loss 39.79887 :  31%|███████████████████▋                                           | 78/250 [08:09<17:59,  6.27s/it]Train | Ep [78/250] Step [159/500] LR [0.00045] Loss 39.65887 :  31%|███████████████████▋                                           | 78/250 [08:12<17:59,  6.27s/it]INFO - 12/17/25 16:14:44 - 0:08:38 - Ep 78 | l2r: acc of top [1, 10, 50] = [0.7797 0.959  0.9891], mr = 3.980, mrr = 0.843, Loss = 39.6589
INFO - 12/17/25 16:14:44 - 0:08:38 - Ep 78 | r2l: acc of top [1, 10, 50] = [0.7792 0.9579 0.9891], mr = 4.401, mrr = 0.844, Loss = 39.6589
Train | Ep [78/250] Step [159/500] LR [0.00045] Loss 39.65887 :  32%|███████████████████▉                                           | 79/250 [08:16<17:57,  6.30s/it]Train | Ep [79/250] Step [161/500] LR [0.00045] Loss 39.52924 :  32%|███████████████████▉                                           | 79/250 [08:18<17:57,  6.30s/it]INFO - 12/17/25 16:14:50 - 0:08:44 - Ep 79 | l2r: acc of top [1, 10, 50] = [0.7823 0.9591 0.9893], mr = 3.989, mrr = 0.845, Loss = 39.5292
INFO - 12/17/25 16:14:50 - 0:08:44 - Ep 79 | r2l: acc of top [1, 10, 50] = [0.7805 0.9589 0.9891], mr = 4.439, mrr = 0.844, Loss = 39.5292
INFO - 12/17/25 16:14:50 - 0:08:44 - Best model update in Ep 79: MRR from [0.8441933614274134] --> [0.8449162966769183] ... 
Train | Ep [79/250] Step [161/500] LR [0.00045] Loss 39.52924 :  32%|████████████████████▏                                          | 80/250 [08:22<17:45,  6.27s/it]Train | Ep [80/250] Step [163/500] LR [0.00045] Loss 39.28171 :  32%|████████████████████▏                                          | 80/250 [08:24<17:45,  6.27s/it]INFO - 12/17/25 16:14:56 - 0:08:50 - Ep 80 | l2r: acc of top [1, 10, 50] = [0.7814 0.9585 0.9892], mr = 4.009, mrr = 0.844, Loss = 39.2817
INFO - 12/17/25 16:14:56 - 0:08:50 - Ep 80 | r2l: acc of top [1, 10, 50] = [0.781  0.9587 0.989 ], mr = 4.459, mrr = 0.845, Loss = 39.2817
Train | Ep [80/250] Step [163/500] LR [0.00045] Loss 39.28171 :  32%|████████████████████▍                                          | 81/250 [08:28<17:40,  6.28s/it]Train | Ep [81/250] Step [165/500] LR [0.00045] Loss 39.12964 :  32%|████████████████████▍                                          | 81/250 [08:30<17:40,  6.28s/it]INFO - 12/17/25 16:15:03 - 0:08:57 - Ep 81 | l2r: acc of top [1, 10, 50] = [0.7823 0.9588 0.9891], mr = 4.066, mrr = 0.845, Loss = 39.1296
INFO - 12/17/25 16:15:03 - 0:08:57 - Ep 81 | r2l: acc of top [1, 10, 50] = [0.7803 0.959  0.989 ], mr = 4.494, mrr = 0.844, Loss = 39.1296
INFO - 12/17/25 16:15:03 - 0:08:57 - Best model update in Ep 81: MRR from [0.8449162966769183] --> [0.8450621598961221] ... 
Train | Ep [81/250] Step [165/500] LR [0.00045] Loss 39.12964 :  33%|████████████████████▋                                          | 82/250 [08:35<17:39,  6.31s/it]Train | Ep [82/250] Step [167/500] LR [0.00045] Loss 38.98547 :  33%|████████████████████▋                                          | 82/250 [08:37<17:39,  6.31s/it]INFO - 12/17/25 16:15:09 - 0:09:03 - Ep 82 | l2r: acc of top [1, 10, 50] = [0.7816 0.9587 0.9891], mr = 4.049, mrr = 0.845, Loss = 38.9855
INFO - 12/17/25 16:15:09 - 0:09:03 - Ep 82 | r2l: acc of top [1, 10, 50] = [0.781  0.9588 0.989 ], mr = 4.511, mrr = 0.845, Loss = 38.9855
Train | Ep [82/250] Step [167/500] LR [0.00045] Loss 38.98547 :  33%|████████████████████▉                                          | 83/250 [08:41<17:24,  6.25s/it]Train | Ep [83/250] Step [169/500] LR [0.00044] Loss 38.76561 :  33%|████████████████████▉                                          | 83/250 [08:43<17:24,  6.25s/it]INFO - 12/17/25 16:15:15 - 0:09:09 - Ep 83 | l2r: acc of top [1, 10, 50] = [0.7819 0.958  0.9891], mr = 4.100, mrr = 0.845, Loss = 38.7656
INFO - 12/17/25 16:15:15 - 0:09:09 - Ep 83 | r2l: acc of top [1, 10, 50] = [0.7801 0.9583 0.989 ], mr = 4.560, mrr = 0.844, Loss = 38.7656
Train | Ep [83/250] Step [169/500] LR [0.00044] Loss 38.76561 :  34%|█████████████████████▏                                         | 84/250 [08:47<17:15,  6.24s/it]Train | Ep [84/250] Step [171/500] LR [0.00044] Loss 38.48716 :  34%|█████████████████████▏                                         | 84/250 [08:49<17:15,  6.24s/it]INFO - 12/17/25 16:15:21 - 0:09:15 - Ep 84 | l2r: acc of top [1, 10, 50] = [0.7814 0.9585 0.9891], mr = 4.087, mrr = 0.845, Loss = 38.4872
INFO - 12/17/25 16:15:21 - 0:09:15 - Ep 84 | r2l: acc of top [1, 10, 50] = [0.7803 0.9589 0.9891], mr = 4.559, mrr = 0.844, Loss = 38.4872
Train | Ep [84/250] Step [171/500] LR [0.00044] Loss 38.48716 :  34%|█████████████████████▍                                         | 85/250 [08:53<17:05,  6.22s/it]Train | Ep [85/250] Step [173/500] LR [0.00044] Loss 38.40538 :  34%|█████████████████████▍                                         | 85/250 [08:55<17:05,  6.22s/it]INFO - 12/17/25 16:15:28 - 0:09:21 - Ep 85 | l2r: acc of top [1, 10, 50] = [0.7825 0.9585 0.989 ], mr = 4.146, mrr = 0.845, Loss = 38.4054
INFO - 12/17/25 16:15:28 - 0:09:21 - Ep 85 | r2l: acc of top [1, 10, 50] = [0.7802 0.9583 0.989 ], mr = 4.601, mrr = 0.844, Loss = 38.4054
Train | Ep [85/250] Step [173/500] LR [0.00044] Loss 38.40538 :  34%|█████████████████████▋                                         | 86/250 [08:59<17:02,  6.24s/it]Train | Ep [86/250] Step [175/500] LR [0.00044] Loss 38.28899 :  34%|█████████████████████▋                                         | 86/250 [09:01<17:02,  6.24s/it]INFO - 12/17/25 16:15:34 - 0:09:28 - Ep 86 | l2r: acc of top [1, 10, 50] = [0.782  0.9586 0.9887], mr = 4.143, mrr = 0.845, Loss = 38.2890
INFO - 12/17/25 16:15:34 - 0:09:28 - Ep 86 | r2l: acc of top [1, 10, 50] = [0.7813 0.9581 0.9889], mr = 4.639, mrr = 0.844, Loss = 38.2890
Train | Ep [86/250] Step [175/500] LR [0.00044] Loss 38.28899 :  35%|█████████████████████▉                                         | 87/250 [09:06<17:02,  6.27s/it]Train | Ep [87/250] Step [177/500] LR [0.00043] Loss 38.20422 :  35%|█████████████████████▉                                         | 87/250 [09:08<17:02,  6.27s/it]INFO - 12/17/25 16:15:40 - 0:09:34 - Ep 87 | l2r: acc of top [1, 10, 50] = [0.7817 0.9583 0.9886], mr = 4.203, mrr = 0.845, Loss = 38.2042
INFO - 12/17/25 16:15:40 - 0:09:34 - Ep 87 | r2l: acc of top [1, 10, 50] = [0.7815 0.9584 0.989 ], mr = 4.633, mrr = 0.845, Loss = 38.2042
Train | Ep [87/250] Step [177/500] LR [0.00043] Loss 38.20422 :  35%|██████████████████████▏                                        | 88/250 [09:12<17:00,  6.30s/it]Train | Ep [88/250] Step [179/500] LR [0.00043] Loss 37.97476 :  35%|██████████████████████▏                                        | 88/250 [09:14<17:00,  6.30s/it]INFO - 12/17/25 16:15:47 - 0:09:40 - Ep 88 | l2r: acc of top [1, 10, 50] = [0.783  0.9587 0.9884], mr = 4.195, mrr = 0.845, Loss = 37.9748
INFO - 12/17/25 16:15:47 - 0:09:40 - Ep 88 | r2l: acc of top [1, 10, 50] = [0.7813 0.9582 0.9889], mr = 4.694, mrr = 0.845, Loss = 37.9748
INFO - 12/17/25 16:15:47 - 0:09:40 - Best model update in Ep 88: MRR from [0.8450621598961221] --> [0.8453831484770921] ... 
Train | Ep [88/250] Step [179/500] LR [0.00043] Loss 37.97476 :  36%|██████████████████████▍                                        | 89/250 [09:18<16:55,  6.31s/it]Train | Ep [89/250] Step [181/500] LR [0.00043] Loss 37.93128 :  36%|██████████████████████▍                                        | 89/250 [09:21<16:55,  6.31s/it]INFO - 12/17/25 16:15:53 - 0:09:47 - Ep 89 | l2r: acc of top [1, 10, 50] = [0.7818 0.9578 0.9885], mr = 4.264, mrr = 0.845, Loss = 37.9313
INFO - 12/17/25 16:15:53 - 0:09:47 - Ep 89 | r2l: acc of top [1, 10, 50] = [0.7808 0.9577 0.989 ], mr = 4.716, mrr = 0.845, Loss = 37.9313
Train | Ep [89/250] Step [181/500] LR [0.00043] Loss 37.93128 :  36%|██████████████████████▋                                        | 90/250 [09:25<16:51,  6.32s/it]Train | Ep [90/250] Step [183/500] LR [0.00043] Loss 37.75203 :  36%|██████████████████████▋                                        | 90/250 [09:27<16:51,  6.32s/it]INFO - 12/17/25 16:15:59 - 0:09:53 - Ep 90 | l2r: acc of top [1, 10, 50] = [0.7821 0.9582 0.9883], mr = 4.277, mrr = 0.845, Loss = 37.7520
INFO - 12/17/25 16:15:59 - 0:09:53 - Ep 90 | r2l: acc of top [1, 10, 50] = [0.782  0.9578 0.989 ], mr = 4.788, mrr = 0.845, Loss = 37.7520
Train | Ep [90/250] Step [183/500] LR [0.00043] Loss 37.75203 :  36%|██████████████████████▉                                        | 91/250 [09:31<16:43,  6.31s/it]Train | Ep [91/250] Step [185/500] LR [0.00042] Loss 37.46652 :  36%|██████████████████████▉                                        | 91/250 [09:33<16:43,  6.31s/it]INFO - 12/17/25 16:16:06 - 0:09:59 - Ep 91 | l2r: acc of top [1, 10, 50] = [0.7811 0.9582 0.9882], mr = 4.336, mrr = 0.844, Loss = 37.4665
INFO - 12/17/25 16:16:06 - 0:09:59 - Ep 91 | r2l: acc of top [1, 10, 50] = [0.7811 0.9576 0.989 ], mr = 4.792, mrr = 0.845, Loss = 37.4665
Train | Ep [91/250] Step [185/500] LR [0.00042] Loss 37.46652 :  37%|███████████████████████▏                                       | 92/250 [09:37<16:37,  6.31s/it]Train | Ep [92/250] Step [187/500] LR [0.00042] Loss 37.57938 :  37%|███████████████████████▏                                       | 92/250 [09:39<16:37,  6.31s/it]INFO - 12/17/25 16:16:12 - 0:10:06 - Ep 92 | l2r: acc of top [1, 10, 50] = [0.7823 0.9578 0.9881], mr = 4.352, mrr = 0.845, Loss = 37.5794
INFO - 12/17/25 16:16:12 - 0:10:06 - Ep 92 | r2l: acc of top [1, 10, 50] = [0.7804 0.958  0.9888], mr = 4.843, mrr = 0.844, Loss = 37.5794
Train | Ep [92/250] Step [187/500] LR [0.00042] Loss 37.57938 :  37%|███████████████████████▍                                       | 93/250 [09:44<16:30,  6.31s/it]Train | Ep [93/250] Step [189/500] LR [0.00042] Loss 37.47705 :  37%|███████████████████████▍                                       | 93/250 [09:46<16:30,  6.31s/it]INFO - 12/17/25 16:16:18 - 0:10:12 - Ep 93 | l2r: acc of top [1, 10, 50] = [0.781  0.9584 0.988 ], mr = 4.407, mrr = 0.844, Loss = 37.4771
INFO - 12/17/25 16:16:18 - 0:10:12 - Ep 93 | r2l: acc of top [1, 10, 50] = [0.7819 0.9574 0.989 ], mr = 4.864, mrr = 0.845, Loss = 37.4771
Train | Ep [93/250] Step [189/500] LR [0.00042] Loss 37.47705 :  38%|███████████████████████▋                                       | 94/250 [09:50<16:21,  6.29s/it]Train | Ep [94/250] Step [191/500] LR [0.00041] Loss 37.08916 :  38%|███████████████████████▋                                       | 94/250 [09:52<16:21,  6.29s/it]INFO - 12/17/25 16:16:24 - 0:10:18 - Ep 94 | l2r: acc of top [1, 10, 50] = [0.7807 0.9576 0.9881], mr = 4.427, mrr = 0.844, Loss = 37.0892
INFO - 12/17/25 16:16:24 - 0:10:18 - Ep 94 | r2l: acc of top [1, 10, 50] = [0.7808 0.9583 0.989 ], mr = 4.940, mrr = 0.844, Loss = 37.0892
Train | Ep [94/250] Step [191/500] LR [0.00041] Loss 37.08916 :  38%|███████████████████████▉                                       | 95/250 [09:56<16:09,  6.26s/it]Train | Ep [95/250] Step [193/500] LR [0.00041] Loss 37.07047 :  38%|███████████████████████▉                                       | 95/250 [09:58<16:09,  6.26s/it]INFO - 12/17/25 16:16:31 - 0:10:24 - Ep 95 | l2r: acc of top [1, 10, 50] = [0.7818 0.9579 0.9883], mr = 4.470, mrr = 0.844, Loss = 37.0705
INFO - 12/17/25 16:16:31 - 0:10:24 - Ep 95 | r2l: acc of top [1, 10, 50] = [0.7804 0.9571 0.9889], mr = 4.951, mrr = 0.844, Loss = 37.0705
Train | Ep [95/250] Step [193/500] LR [0.00041] Loss 37.07047 :  38%|████████████████████████▏                                      | 96/250 [10:02<16:02,  6.25s/it]Train | Ep [96/250] Step [195/500] LR [0.00041] Loss 36.99703 :  38%|████████████████████████▏                                      | 96/250 [10:04<16:02,  6.25s/it]INFO - 12/17/25 16:16:37 - 0:10:31 - Ep 96 | l2r: acc of top [1, 10, 50] = [0.7797 0.9577 0.9877], mr = 4.501, mrr = 0.843, Loss = 36.9970
INFO - 12/17/25 16:16:37 - 0:10:31 - Ep 96 | r2l: acc of top [1, 10, 50] = [0.7811 0.9572 0.9887], mr = 5.050, mrr = 0.844, Loss = 36.9970
Train | Ep [96/250] Step [195/500] LR [0.00041] Loss 36.99703 :  39%|████████████████████████▍                                      | 97/250 [10:09<15:58,  6.26s/it]Train | Ep [97/250] Step [197/500] LR [0.00041] Loss 36.73846 :  39%|████████████████████████▍                                      | 97/250 [10:11<15:58,  6.26s/it]INFO - 12/17/25 16:16:43 - 0:10:37 - Ep 97 | l2r: acc of top [1, 10, 50] = [0.7804 0.9572 0.9877], mr = 4.538, mrr = 0.844, Loss = 36.7385
INFO - 12/17/25 16:16:43 - 0:10:37 - Ep 97 | r2l: acc of top [1, 10, 50] = [0.7803 0.9568 0.9885], mr = 5.058, mrr = 0.844, Loss = 36.7385
Train | Ep [97/250] Step [197/500] LR [0.00041] Loss 36.73846 :  39%|████████████████████████▋                                      | 98/250 [10:15<15:55,  6.29s/it]Train | Ep [98/250] Step [199/500] LR [0.00040] Loss 36.61469 :  39%|████████████████████████▋                                      | 98/250 [10:17<15:55,  6.29s/it]INFO - 12/17/25 16:16:50 - 0:10:43 - Ep 98 | l2r: acc of top [1, 10, 50] = [0.7819 0.9572 0.9876], mr = 4.576, mrr = 0.845, Loss = 36.6147
INFO - 12/17/25 16:16:50 - 0:10:43 - Ep 98 | r2l: acc of top [1, 10, 50] = [0.7808 0.9573 0.9884], mr = 5.166, mrr = 0.844, Loss = 36.6147
Train | Ep [98/250] Step [199/500] LR [0.00040] Loss 36.61469 :  40%|████████████████████████▉                                      | 99/250 [10:21<15:54,  6.32s/it]Train | Ep [99/250] Step [201/500] LR [0.00040] Loss 36.58413 :  40%|████████████████████████▉                                      | 99/250 [10:23<15:54,  6.32s/it]INFO - 12/17/25 16:16:56 - 0:10:50 - Ep 99 | l2r: acc of top [1, 10, 50] = [0.7812 0.9572 0.9881], mr = 4.600, mrr = 0.844, Loss = 36.5841
INFO - 12/17/25 16:16:56 - 0:10:50 - Ep 99 | r2l: acc of top [1, 10, 50] = [0.7793 0.9577 0.9883], mr = 5.187, mrr = 0.843, Loss = 36.5841
Train | Ep [99/250] Step [201/500] LR [0.00040] Loss 36.58413 :  40%|████████████████████████▊                                     | 100/250 [10:28<15:48,  6.32s/it]Train | Ep [100/250] Step [203/500] LR [0.00040] Loss 36.44605 :  40%|████████████████████████▍                                    | 100/250 [10:30<15:48,  6.32s/it]INFO - 12/17/25 16:17:02 - 0:10:56 - Ep 100 | l2r: acc of top [1, 10, 50] = [0.7827 0.9567 0.9879], mr = 4.667, mrr = 0.845, Loss = 36.4461
INFO - 12/17/25 16:17:02 - 0:10:56 - Ep 100 | r2l: acc of top [1, 10, 50] = [0.7811 0.9565 0.9884], mr = 5.261, mrr = 0.844, Loss = 36.4461
Train | Ep [100/250] Step [203/500] LR [0.00040] Loss 36.44605 :  40%|████████████████████████▋                                    | 101/250 [10:34<15:45,  6.35s/it]Train | Ep [101/250] Step [205/500] LR [0.00039] Loss 36.28255 :  40%|████████████████████████▋                                    | 101/250 [10:36<15:45,  6.35s/it]INFO - 12/17/25 16:17:09 - 0:11:02 - Ep 101 | l2r: acc of top [1, 10, 50] = [0.7816 0.9569 0.9877], mr = 4.694, mrr = 0.844, Loss = 36.2825
INFO - 12/17/25 16:17:09 - 0:11:02 - Ep 101 | r2l: acc of top [1, 10, 50] = [0.7806 0.957  0.9883], mr = 5.274, mrr = 0.844, Loss = 36.2825
Train | Ep [101/250] Step [205/500] LR [0.00039] Loss 36.28255 :  41%|████████████████████████▉                                    | 102/250 [10:40<15:40,  6.35s/it]Train | Ep [102/250] Step [207/500] LR [0.00039] Loss 36.19764 :  41%|████████████████████████▉                                    | 102/250 [10:43<15:40,  6.35s/it]INFO - 12/17/25 16:17:15 - 0:11:09 - Ep 102 | l2r: acc of top [1, 10, 50] = [0.7817 0.957  0.9873], mr = 4.763, mrr = 0.844, Loss = 36.1976
INFO - 12/17/25 16:17:15 - 0:11:09 - Ep 102 | r2l: acc of top [1, 10, 50] = [0.7799 0.9555 0.9881], mr = 5.336, mrr = 0.843, Loss = 36.1976
Train | Ep [102/250] Step [207/500] LR [0.00039] Loss 36.19764 :  41%|█████████████████████████▏                                   | 103/250 [10:47<15:32,  6.35s/it]Train | Ep [103/250] Step [209/500] LR [0.00039] Loss 36.15835 :  41%|█████████████████████████▏                                   | 103/250 [10:49<15:32,  6.35s/it]INFO - 12/17/25 16:17:21 - 0:11:15 - Ep 103 | l2r: acc of top [1, 10, 50] = [0.7819 0.9568 0.9873], mr = 4.792, mrr = 0.844, Loss = 36.1584
INFO - 12/17/25 16:17:21 - 0:11:15 - Ep 103 | r2l: acc of top [1, 10, 50] = [0.78   0.9556 0.9881], mr = 5.384, mrr = 0.844, Loss = 36.1584
Train | Ep [103/250] Step [209/500] LR [0.00039] Loss 36.15835 :  42%|█████████████████████████▍                                   | 104/250 [10:53<15:21,  6.31s/it]Train | Ep [104/250] Step [211/500] LR [0.00039] Loss 35.77485 :  42%|█████████████████████████▍                                   | 104/250 [10:55<15:21,  6.31s/it]INFO - 12/17/25 16:17:28 - 0:11:21 - Ep 104 | l2r: acc of top [1, 10, 50] = [0.779  0.9567 0.9872], mr = 4.830, mrr = 0.843, Loss = 35.7748
INFO - 12/17/25 16:17:28 - 0:11:21 - Ep 104 | r2l: acc of top [1, 10, 50] = [0.7796 0.9557 0.9881], mr = 5.403, mrr = 0.843, Loss = 35.7748
Train | Ep [104/250] Step [211/500] LR [0.00039] Loss 35.77485 :  42%|█████████████████████████▌                                   | 105/250 [10:59<15:13,  6.30s/it]Train | Ep [105/250] Step [213/500] LR [0.00038] Loss 35.82244 :  42%|█████████████████████████▌                                   | 105/250 [11:01<15:13,  6.30s/it]INFO - 12/17/25 16:17:34 - 0:11:27 - Ep 105 | l2r: acc of top [1, 10, 50] = [0.7796 0.9556 0.987 ], mr = 4.874, mrr = 0.843, Loss = 35.8224
INFO - 12/17/25 16:17:34 - 0:11:27 - Ep 105 | r2l: acc of top [1, 10, 50] = [0.7793 0.9558 0.9881], mr = 5.462, mrr = 0.843, Loss = 35.8224
Train | Ep [105/250] Step [213/500] LR [0.00038] Loss 35.82244 :  42%|█████████████████████████▊                                   | 106/250 [11:05<15:00,  6.25s/it]Train | Ep [106/250] Step [215/500] LR [0.00038] Loss 35.72844 :  42%|█████████████████████████▊                                   | 106/250 [11:08<15:00,  6.25s/it]INFO - 12/17/25 16:17:40 - 0:11:34 - Ep 106 | l2r: acc of top [1, 10, 50] = [0.7774 0.956  0.9876], mr = 4.907, mrr = 0.841, Loss = 35.7284
INFO - 12/17/25 16:17:40 - 0:11:34 - Ep 106 | r2l: acc of top [1, 10, 50] = [0.7785 0.9557 0.9879], mr = 5.524, mrr = 0.843, Loss = 35.7284
Train | Ep [106/250] Step [215/500] LR [0.00038] Loss 35.72844 :  43%|██████████████████████████                                   | 107/250 [11:12<14:56,  6.27s/it]Train | Ep [107/250] Step [217/500] LR [0.00038] Loss 35.66265 :  43%|██████████████████████████                                   | 107/250 [11:14<14:56,  6.27s/it]INFO - 12/17/25 16:17:46 - 0:11:40 - Ep 107 | l2r: acc of top [1, 10, 50] = [0.7793 0.9556 0.9866], mr = 4.921, mrr = 0.842, Loss = 35.6626
INFO - 12/17/25 16:17:46 - 0:11:40 - Ep 107 | r2l: acc of top [1, 10, 50] = [0.7794 0.9552 0.9878], mr = 5.588, mrr = 0.843, Loss = 35.6626
Train | Ep [107/250] Step [217/500] LR [0.00038] Loss 35.66265 :  43%|██████████████████████████▎                                  | 108/250 [11:18<14:49,  6.26s/it]Train | Ep [108/250] Step [219/500] LR [0.00037] Loss 35.71811 :  43%|██████████████████████████▎                                  | 108/250 [11:20<14:49,  6.26s/it]INFO - 12/17/25 16:17:53 - 0:11:46 - Ep 108 | l2r: acc of top [1, 10, 50] = [0.7789 0.955  0.9872], mr = 4.963, mrr = 0.842, Loss = 35.7181
INFO - 12/17/25 16:17:53 - 0:11:46 - Ep 108 | r2l: acc of top [1, 10, 50] = [0.7781 0.9549 0.9878], mr = 5.627, mrr = 0.842, Loss = 35.7181
Train | Ep [108/250] Step [219/500] LR [0.00037] Loss 35.71811 :  44%|██████████████████████████▌                                  | 109/250 [11:24<14:45,  6.28s/it]Train | Ep [109/250] Step [221/500] LR [0.00037] Loss 35.47234 :  44%|██████████████████████████▌                                  | 109/250 [11:26<14:45,  6.28s/it]INFO - 12/17/25 16:17:59 - 0:11:53 - Ep 109 | l2r: acc of top [1, 10, 50] = [0.7776 0.9549 0.9871], mr = 5.012, mrr = 0.842, Loss = 35.4723
INFO - 12/17/25 16:17:59 - 0:11:53 - Ep 109 | r2l: acc of top [1, 10, 50] = [0.7781 0.9554 0.9873], mr = 5.699, mrr = 0.842, Loss = 35.4723
Train | Ep [109/250] Step [221/500] LR [0.00037] Loss 35.47234 :  44%|██████████████████████████▊                                  | 110/250 [11:31<14:42,  6.30s/it]Train | Ep [110/250] Step [223/500] LR [0.00037] Loss 35.38401 :  44%|██████████████████████████▊                                  | 110/250 [11:33<14:42,  6.30s/it]INFO - 12/17/25 16:18:05 - 0:11:59 - Ep 110 | l2r: acc of top [1, 10, 50] = [0.7784 0.9547 0.987 ], mr = 5.054, mrr = 0.842, Loss = 35.3840
INFO - 12/17/25 16:18:05 - 0:11:59 - Ep 110 | r2l: acc of top [1, 10, 50] = [0.7774 0.9549 0.9875], mr = 5.735, mrr = 0.842, Loss = 35.3840
Train | Ep [110/250] Step [223/500] LR [0.00037] Loss 35.38401 :  44%|███████████████████████████                                  | 111/250 [11:37<14:39,  6.33s/it]Train | Ep [111/250] Step [225/500] LR [0.00036] Loss 35.35933 :  44%|███████████████████████████                                  | 111/250 [11:39<14:39,  6.33s/it]INFO - 12/17/25 16:18:12 - 0:12:05 - Ep 111 | l2r: acc of top [1, 10, 50] = [0.7776 0.9551 0.9869], mr = 5.109, mrr = 0.841, Loss = 35.3593
INFO - 12/17/25 16:18:12 - 0:12:05 - Ep 111 | r2l: acc of top [1, 10, 50] = [0.778  0.9548 0.9876], mr = 5.797, mrr = 0.842, Loss = 35.3593
Train | Ep [111/250] Step [225/500] LR [0.00036] Loss 35.35933 :  45%|███████████████████████████▎                                 | 112/250 [11:43<14:30,  6.31s/it]Train | Ep [112/250] Step [227/500] LR [0.00036] Loss 35.34084 :  45%|███████████████████████████▎                                 | 112/250 [11:45<14:30,  6.31s/it]INFO - 12/17/25 16:18:18 - 0:12:12 - Ep 112 | l2r: acc of top [1, 10, 50] = [0.7778 0.9554 0.9872], mr = 5.141, mrr = 0.842, Loss = 35.3408
INFO - 12/17/25 16:18:18 - 0:12:12 - Ep 112 | r2l: acc of top [1, 10, 50] = [0.778  0.9553 0.9876], mr = 5.818, mrr = 0.842, Loss = 35.3408
Train | Ep [112/250] Step [227/500] LR [0.00036] Loss 35.34084 :  45%|███████████████████████████▌                                 | 113/250 [11:50<14:28,  6.34s/it]Train | Ep [113/250] Step [229/500] LR [0.00036] Loss 35.38965 :  45%|███████████████████████████▌                                 | 113/250 [11:52<14:28,  6.34s/it]INFO - 12/17/25 16:18:24 - 0:12:18 - Ep 113 | l2r: acc of top [1, 10, 50] = [0.7778 0.9548 0.9871], mr = 5.183, mrr = 0.841, Loss = 35.3896
INFO - 12/17/25 16:18:24 - 0:12:18 - Ep 113 | r2l: acc of top [1, 10, 50] = [0.7779 0.9547 0.9875], mr = 5.859, mrr = 0.842, Loss = 35.3896
Train | Ep [113/250] Step [229/500] LR [0.00036] Loss 35.38965 :  46%|███████████████████████████▊                                 | 114/250 [11:56<14:21,  6.33s/it]Train | Ep [114/250] Step [231/500] LR [0.00035] Loss 34.93162 :  46%|███████████████████████████▊                                 | 114/250 [11:58<14:21,  6.33s/it]INFO - 12/17/25 16:18:31 - 0:12:24 - Ep 114 | l2r: acc of top [1, 10, 50] = [0.7765 0.9543 0.9872], mr = 5.222, mrr = 0.841, Loss = 34.9316
INFO - 12/17/25 16:18:31 - 0:12:24 - Ep 114 | r2l: acc of top [1, 10, 50] = [0.7778 0.9545 0.9874], mr = 5.884, mrr = 0.842, Loss = 34.9316
Train | Ep [114/250] Step [231/500] LR [0.00035] Loss 34.93162 :  46%|████████████████████████████                                 | 115/250 [12:02<14:11,  6.31s/it]Train | Ep [115/250] Step [233/500] LR [0.00035] Loss 35.12657 :  46%|████████████████████████████                                 | 115/250 [12:04<14:11,  6.31s/it]INFO - 12/17/25 16:18:37 - 0:12:31 - Ep 115 | l2r: acc of top [1, 10, 50] = [0.7754 0.9544 0.987 ], mr = 5.247, mrr = 0.840, Loss = 35.1266
INFO - 12/17/25 16:18:37 - 0:12:31 - Ep 115 | r2l: acc of top [1, 10, 50] = [0.7779 0.9539 0.9872], mr = 5.944, mrr = 0.841, Loss = 35.1266
Train | Ep [115/250] Step [233/500] LR [0.00035] Loss 35.12657 :  46%|████████████████████████████▎                                | 116/250 [12:09<14:04,  6.30s/it]Train | Ep [116/250] Step [235/500] LR [0.00035] Loss 35.07989 :  46%|████████████████████████████▎                                | 116/250 [12:11<14:04,  6.30s/it]INFO - 12/17/25 16:18:43 - 0:12:37 - Ep 116 | l2r: acc of top [1, 10, 50] = [0.7754 0.9541 0.9868], mr = 5.310, mrr = 0.840, Loss = 35.0799
INFO - 12/17/25 16:18:43 - 0:12:37 - Ep 116 | r2l: acc of top [1, 10, 50] = [0.7778 0.9541 0.9873], mr = 5.938, mrr = 0.841, Loss = 35.0799
Train | Ep [116/250] Step [235/500] LR [0.00035] Loss 35.07989 :  47%|████████████████████████████▌                                | 117/250 [12:15<13:49,  6.24s/it]Train | Ep [117/250] Step [237/500] LR [0.00034] Loss 34.77014 :  47%|████████████████████████████▌                                | 117/250 [12:17<13:49,  6.24s/it]INFO - 12/17/25 16:18:49 - 0:12:43 - Ep 117 | l2r: acc of top [1, 10, 50] = [0.7756 0.9545 0.9866], mr = 5.366, mrr = 0.840, Loss = 34.7701
INFO - 12/17/25 16:18:49 - 0:12:43 - Ep 117 | r2l: acc of top [1, 10, 50] = [0.7786 0.954  0.9872], mr = 5.991, mrr = 0.842, Loss = 34.7701
Train | Ep [117/250] Step [237/500] LR [0.00034] Loss 34.77014 :  47%|████████████████████████████▊                                | 118/250 [12:21<13:48,  6.28s/it]Train | Ep [118/250] Step [239/500] LR [0.00034] Loss 34.79961 :  47%|████████████████████████████▊                                | 118/250 [12:23<13:48,  6.28s/it]INFO - 12/17/25 16:18:56 - 0:12:49 - Ep 118 | l2r: acc of top [1, 10, 50] = [0.7768 0.9541 0.9866], mr = 5.450, mrr = 0.840, Loss = 34.7996
INFO - 12/17/25 16:18:56 - 0:12:49 - Ep 118 | r2l: acc of top [1, 10, 50] = [0.7784 0.9536 0.9869], mr = 6.051, mrr = 0.841, Loss = 34.7996
Train | Ep [118/250] Step [239/500] LR [0.00034] Loss 34.79961 :  48%|█████████████████████████████                                | 119/250 [12:27<13:45,  6.30s/it]Train | Ep [119/250] Step [241/500] LR [0.00034] Loss 34.59447 :  48%|█████████████████████████████                                | 119/250 [12:29<13:45,  6.30s/it]INFO - 12/17/25 16:19:02 - 0:12:56 - Ep 119 | l2r: acc of top [1, 10, 50] = [0.7754 0.9544 0.9864], mr = 5.450, mrr = 0.840, Loss = 34.5945
INFO - 12/17/25 16:19:02 - 0:12:56 - Ep 119 | r2l: acc of top [1, 10, 50] = [0.7774 0.9536 0.987 ], mr = 6.088, mrr = 0.841, Loss = 34.5945
Train | Ep [119/250] Step [241/500] LR [0.00034] Loss 34.59447 :  48%|█████████████████████████████▎                               | 120/250 [12:34<13:37,  6.29s/it]Train | Ep [120/250] Step [243/500] LR [0.00033] Loss 34.51972 :  48%|█████████████████████████████▎                               | 120/250 [12:36<13:37,  6.29s/it]INFO - 12/17/25 16:19:08 - 0:13:02 - Ep 120 | l2r: acc of top [1, 10, 50] = [0.7755 0.9546 0.9862], mr = 5.546, mrr = 0.839, Loss = 34.5197
INFO - 12/17/25 16:19:08 - 0:13:02 - Ep 120 | r2l: acc of top [1, 10, 50] = [0.7767 0.9532 0.9871], mr = 6.143, mrr = 0.840, Loss = 34.5197
Train | Ep [120/250] Step [243/500] LR [0.00033] Loss 34.51972 :  48%|█████████████████████████████▌                               | 121/250 [12:40<13:31,  6.29s/it]Train | Ep [121/250] Step [245/500] LR [0.00033] Loss 34.33495 :  48%|█████████████████████████████▌                               | 121/250 [12:42<13:31,  6.29s/it]INFO - 12/17/25 16:19:15 - 0:13:08 - Ep 121 | l2r: acc of top [1, 10, 50] = [0.7749 0.9542 0.9861], mr = 5.588, mrr = 0.839, Loss = 34.3349
INFO - 12/17/25 16:19:15 - 0:13:08 - Ep 121 | r2l: acc of top [1, 10, 50] = [0.7766 0.9529 0.9868], mr = 6.269, mrr = 0.840, Loss = 34.3349
Train | Ep [121/250] Step [245/500] LR [0.00033] Loss 34.33495 :  49%|█████████████████████████████▊                               | 122/250 [12:46<13:30,  6.33s/it]Train | Ep [122/250] Step [247/500] LR [0.00033] Loss 34.15517 :  49%|█████████████████████████████▊                               | 122/250 [12:49<13:30,  6.33s/it]INFO - 12/17/25 16:19:21 - 0:13:15 - Ep 122 | l2r: acc of top [1, 10, 50] = [0.7737 0.9542 0.9862], mr = 5.705, mrr = 0.838, Loss = 34.1552
INFO - 12/17/25 16:19:21 - 0:13:15 - Ep 122 | r2l: acc of top [1, 10, 50] = [0.7759 0.9529 0.9866], mr = 6.470, mrr = 0.840, Loss = 34.1552
Train | Ep [122/250] Step [247/500] LR [0.00033] Loss 34.15517 :  49%|██████████████████████████████                               | 123/250 [12:53<13:24,  6.33s/it]Train | Ep [123/250] Step [249/500] LR [0.00032] Loss 34.16881 :  49%|██████████████████████████████                               | 123/250 [12:55<13:24,  6.33s/it]INFO - 12/17/25 16:19:27 - 0:13:21 - Ep 123 | l2r: acc of top [1, 10, 50] = [0.7736 0.9536 0.9856], mr = 5.802, mrr = 0.838, Loss = 34.1688
INFO - 12/17/25 16:19:27 - 0:13:21 - Ep 123 | r2l: acc of top [1, 10, 50] = [0.7756 0.952  0.9863], mr = 6.640, mrr = 0.839, Loss = 34.1688
Train | Ep [123/250] Step [249/500] LR [0.00032] Loss 34.16881 :  50%|██████████████████████████████▎                              | 124/250 [12:59<13:17,  6.33s/it]Train | Ep [124/250] Step [251/500] LR [0.00032] Loss 34.00217 :  50%|██████████████████████████████▎                              | 124/250 [13:01<13:17,  6.33s/it]INFO - 12/17/25 16:19:34 - 0:13:27 - Ep 124 | l2r: acc of top [1, 10, 50] = [0.7738 0.9536 0.9859], mr = 5.854, mrr = 0.839, Loss = 34.0022
INFO - 12/17/25 16:19:34 - 0:13:27 - Ep 124 | r2l: acc of top [1, 10, 50] = [0.7766 0.953  0.987 ], mr = 6.734, mrr = 0.840, Loss = 34.0022
Train | Ep [124/250] Step [251/500] LR [0.00032] Loss 34.00217 :  50%|██████████████████████████████▌                              | 125/250 [13:05<13:09,  6.32s/it]Train | Ep [125/250] Step [253/500] LR [0.00031] Loss 34.04585 :  50%|██████████████████████████████▌                              | 125/250 [13:07<13:09,  6.32s/it]INFO - 12/17/25 16:19:40 - 0:13:34 - Ep 125 | l2r: acc of top [1, 10, 50] = [0.7736 0.9543 0.9854], mr = 5.945, mrr = 0.838, Loss = 34.0458
INFO - 12/17/25 16:19:40 - 0:13:34 - Ep 125 | r2l: acc of top [1, 10, 50] = [0.7751 0.9521 0.9865], mr = 6.853, mrr = 0.839, Loss = 34.0458
Train | Ep [125/250] Step [253/500] LR [0.00031] Loss 34.04585 :  50%|██████████████████████████████▋                              | 126/250 [13:12<13:00,  6.29s/it]Train | Ep [126/250] Step [255/500] LR [0.00031] Loss 34.04715 :  50%|██████████████████████████████▋                              | 126/250 [13:14<13:00,  6.29s/it]INFO - 12/17/25 16:19:46 - 0:13:40 - Ep 126 | l2r: acc of top [1, 10, 50] = [0.7743 0.9533 0.9853], mr = 6.025, mrr = 0.838, Loss = 34.0471
INFO - 12/17/25 16:19:46 - 0:13:40 - Ep 126 | r2l: acc of top [1, 10, 50] = [0.7763 0.9524 0.9865], mr = 6.928, mrr = 0.840, Loss = 34.0471
Train | Ep [126/250] Step [255/500] LR [0.00031] Loss 34.04715 :  51%|██████████████████████████████▉                              | 127/250 [13:18<12:55,  6.31s/it]Train | Ep [127/250] Step [257/500] LR [0.00031] Loss 34.05325 :  51%|██████████████████████████████▉                              | 127/250 [13:20<12:55,  6.31s/it]INFO - 12/17/25 16:19:52 - 0:13:46 - Ep 127 | l2r: acc of top [1, 10, 50] = [0.7736 0.9537 0.9851], mr = 6.092, mrr = 0.838, Loss = 34.0533
INFO - 12/17/25 16:19:52 - 0:13:46 - Ep 127 | r2l: acc of top [1, 10, 50] = [0.7757 0.9519 0.9865], mr = 7.024, mrr = 0.839, Loss = 34.0533
Train | Ep [127/250] Step [257/500] LR [0.00031] Loss 34.05325 :  51%|███████████████████████████████▏                             | 128/250 [13:24<12:44,  6.27s/it]Train | Ep [128/250] Step [259/500] LR [0.00030] Loss 33.92810 :  51%|███████████████████████████████▏                             | 128/250 [13:26<12:44,  6.27s/it]INFO - 12/17/25 16:19:59 - 0:13:52 - Ep 128 | l2r: acc of top [1, 10, 50] = [0.7723 0.953  0.9849], mr = 6.120, mrr = 0.837, Loss = 33.9281
INFO - 12/17/25 16:19:59 - 0:13:52 - Ep 128 | r2l: acc of top [1, 10, 50] = [0.7753 0.9516 0.9865], mr = 7.082, mrr = 0.839, Loss = 33.9281
Train | Ep [128/250] Step [259/500] LR [0.00030] Loss 33.92810 :  52%|███████████████████████████████▍                             | 129/250 [13:30<12:36,  6.25s/it]Train | Ep [129/250] Step [261/500] LR [0.00030] Loss 33.88600 :  52%|███████████████████████████████▍                             | 129/250 [13:32<12:36,  6.25s/it]INFO - 12/17/25 16:20:05 - 0:13:59 - Ep 129 | l2r: acc of top [1, 10, 50] = [0.7719 0.9534 0.9851], mr = 6.172, mrr = 0.837, Loss = 33.8860
INFO - 12/17/25 16:20:05 - 0:13:59 - Ep 129 | r2l: acc of top [1, 10, 50] = [0.7752 0.9516 0.9866], mr = 7.099, mrr = 0.839, Loss = 33.8860
Train | Ep [129/250] Step [261/500] LR [0.00030] Loss 33.88600 :  52%|███████████████████████████████▋                             | 130/250 [13:37<12:35,  6.29s/it]Train | Ep [130/250] Step [263/500] LR [0.00030] Loss 33.81379 :  52%|███████████████████████████████▋                             | 130/250 [13:39<12:35,  6.29s/it]INFO - 12/17/25 16:20:11 - 0:14:05 - Ep 130 | l2r: acc of top [1, 10, 50] = [0.773  0.9532 0.9857], mr = 6.165, mrr = 0.838, Loss = 33.8138
INFO - 12/17/25 16:20:11 - 0:14:05 - Ep 130 | r2l: acc of top [1, 10, 50] = [0.775  0.9519 0.9868], mr = 7.150, mrr = 0.839, Loss = 33.8138
Train | Ep [130/250] Step [263/500] LR [0.00030] Loss 33.81379 :  52%|███████████████████████████████▉                             | 131/250 [13:43<12:30,  6.31s/it]Train | Ep [131/250] Step [265/500] LR [0.00029] Loss 33.60163 :  52%|███████████████████████████████▉                             | 131/250 [13:45<12:30,  6.31s/it]INFO - 12/17/25 16:20:18 - 0:14:11 - Ep 131 | l2r: acc of top [1, 10, 50] = [0.7725 0.953  0.9854], mr = 6.157, mrr = 0.837, Loss = 33.6016
INFO - 12/17/25 16:20:18 - 0:14:11 - Ep 131 | r2l: acc of top [1, 10, 50] = [0.7749 0.9521 0.9863], mr = 7.150, mrr = 0.839, Loss = 33.6016
Train | Ep [131/250] Step [265/500] LR [0.00029] Loss 33.60163 :  53%|████████████████████████████████▏                            | 132/250 [13:49<12:27,  6.34s/it]Train | Ep [132/250] Step [267/500] LR [0.00029] Loss 33.75716 :  53%|████████████████████████████████▏                            | 132/250 [13:52<12:27,  6.34s/it]INFO - 12/17/25 16:20:24 - 0:14:18 - Ep 132 | l2r: acc of top [1, 10, 50] = [0.7709 0.9529 0.9857], mr = 6.182, mrr = 0.836, Loss = 33.7572
INFO - 12/17/25 16:20:24 - 0:14:18 - Ep 132 | r2l: acc of top [1, 10, 50] = [0.7743 0.9514 0.9858], mr = 7.239, mrr = 0.838, Loss = 33.7572
Train | Ep [132/250] Step [267/500] LR [0.00029] Loss 33.75716 :  53%|████████████████████████████████▍                            | 133/250 [13:56<12:22,  6.34s/it]Train | Ep [133/250] Step [269/500] LR [0.00029] Loss 33.52865 :  53%|████████████████████████████████▍                            | 133/250 [13:58<12:22,  6.34s/it]INFO - 12/17/25 16:20:30 - 0:14:24 - Ep 133 | l2r: acc of top [1, 10, 50] = [0.7708 0.9523 0.9858], mr = 6.199, mrr = 0.836, Loss = 33.5287
INFO - 12/17/25 16:20:30 - 0:14:24 - Ep 133 | r2l: acc of top [1, 10, 50] = [0.7739 0.9512 0.9859], mr = 7.292, mrr = 0.838, Loss = 33.5287
Train | Ep [133/250] Step [269/500] LR [0.00029] Loss 33.52865 :  54%|████████████████████████████████▋                            | 134/250 [14:02<12:17,  6.36s/it]Train | Ep [134/250] Step [271/500] LR [0.00028] Loss 33.38534 :  54%|████████████████████████████████▋                            | 134/250 [14:04<12:17,  6.36s/it]INFO - 12/17/25 16:20:37 - 0:14:31 - Ep 134 | l2r: acc of top [1, 10, 50] = [0.7693 0.9524 0.9856], mr = 6.230, mrr = 0.835, Loss = 33.3853
INFO - 12/17/25 16:20:37 - 0:14:31 - Ep 134 | r2l: acc of top [1, 10, 50] = [0.774  0.9509 0.9859], mr = 7.324, mrr = 0.838, Loss = 33.3853
Train | Ep [134/250] Step [271/500] LR [0.00028] Loss 33.38534 :  54%|████████████████████████████████▉                            | 135/250 [14:09<12:17,  6.41s/it]Train | Ep [135/250] Step [273/500] LR [0.00028] Loss 33.51365 :  54%|████████████████████████████████▉                            | 135/250 [14:11<12:17,  6.41s/it]INFO - 12/17/25 16:20:43 - 0:14:37 - Ep 135 | l2r: acc of top [1, 10, 50] = [0.7708 0.9521 0.9856], mr = 6.239, mrr = 0.836, Loss = 33.5136
INFO - 12/17/25 16:20:43 - 0:14:37 - Ep 135 | r2l: acc of top [1, 10, 50] = [0.7757 0.951  0.9859], mr = 7.292, mrr = 0.839, Loss = 33.5136
Train | Ep [135/250] Step [273/500] LR [0.00028] Loss 33.51365 :  54%|█████████████████████████████████▏                           | 136/250 [14:15<12:09,  6.40s/it]Train | Ep [136/250] Step [275/500] LR [0.00027] Loss 33.32382 :  54%|█████████████████████████████████▏                           | 136/250 [14:17<12:09,  6.40s/it]INFO - 12/17/25 16:20:50 - 0:14:43 - Ep 136 | l2r: acc of top [1, 10, 50] = [0.7694 0.951  0.9852], mr = 6.241, mrr = 0.835, Loss = 33.3238
INFO - 12/17/25 16:20:50 - 0:14:43 - Ep 136 | r2l: acc of top [1, 10, 50] = [0.7734 0.9509 0.9857], mr = 7.304, mrr = 0.838, Loss = 33.3238
Train | Ep [136/250] Step [275/500] LR [0.00027] Loss 33.32382 :  55%|█████████████████████████████████▍                           | 137/250 [14:22<12:03,  6.40s/it]Train | Ep [137/250] Step [277/500] LR [0.00027] Loss 33.38831 :  55%|█████████████████████████████████▍                           | 137/250 [14:24<12:03,  6.40s/it]INFO - 12/17/25 16:20:56 - 0:14:50 - Ep 137 | l2r: acc of top [1, 10, 50] = [0.7699 0.9512 0.9847], mr = 6.288, mrr = 0.835, Loss = 33.3883
INFO - 12/17/25 16:20:56 - 0:14:50 - Ep 137 | r2l: acc of top [1, 10, 50] = [0.7748 0.9506 0.9862], mr = 7.280, mrr = 0.838, Loss = 33.3883
Train | Ep [137/250] Step [277/500] LR [0.00027] Loss 33.38831 :  55%|█████████████████████████████████▋                           | 138/250 [14:28<11:53,  6.37s/it]Train | Ep [138/250] Step [279/500] LR [0.00027] Loss 33.24783 :  55%|█████████████████████████████████▋                           | 138/250 [14:30<11:53,  6.37s/it]INFO - 12/17/25 16:21:02 - 0:14:56 - Ep 138 | l2r: acc of top [1, 10, 50] = [0.7698 0.9521 0.9851], mr = 6.336, mrr = 0.835, Loss = 33.2478
INFO - 12/17/25 16:21:02 - 0:14:56 - Ep 138 | r2l: acc of top [1, 10, 50] = [0.7742 0.9508 0.9858], mr = 7.326, mrr = 0.838, Loss = 33.2478
Train | Ep [138/250] Step [279/500] LR [0.00027] Loss 33.24783 :  56%|█████████████████████████████████▉                           | 139/250 [14:34<11:40,  6.31s/it]Train | Ep [139/250] Step [281/500] LR [0.00026] Loss 33.10294 :  56%|█████████████████████████████████▉                           | 139/250 [14:36<11:40,  6.31s/it]INFO - 12/17/25 16:21:08 - 0:15:02 - Ep 139 | l2r: acc of top [1, 10, 50] = [0.7693 0.9511 0.985 ], mr = 6.437, mrr = 0.835, Loss = 33.1029
INFO - 12/17/25 16:21:08 - 0:15:02 - Ep 139 | r2l: acc of top [1, 10, 50] = [0.7735 0.9505 0.9864], mr = 7.389, mrr = 0.838, Loss = 33.1029
Train | Ep [139/250] Step [281/500] LR [0.00026] Loss 33.10294 :  56%|██████████████████████████████████▏                          | 140/250 [14:40<11:32,  6.29s/it]Train | Ep [140/250] Step [283/500] LR [0.00026] Loss 33.20302 :  56%|██████████████████████████████████▏                          | 140/250 [14:42<11:32,  6.29s/it]INFO - 12/17/25 16:21:15 - 0:15:09 - Ep 140 | l2r: acc of top [1, 10, 50] = [0.7674 0.9504 0.9847], mr = 6.506, mrr = 0.833, Loss = 33.2030
INFO - 12/17/25 16:21:15 - 0:15:09 - Ep 140 | r2l: acc of top [1, 10, 50] = [0.7723 0.9505 0.9858], mr = 7.430, mrr = 0.837, Loss = 33.2030
Train | Ep [140/250] Step [283/500] LR [0.00026] Loss 33.20302 :  56%|██████████████████████████████████▍                          | 141/250 [14:47<11:29,  6.33s/it]Train | Ep [141/250] Step [285/500] LR [0.00026] Loss 33.16077 :  56%|██████████████████████████████████▍                          | 141/250 [14:49<11:29,  6.33s/it]INFO - 12/17/25 16:21:21 - 0:15:15 - Ep 141 | l2r: acc of top [1, 10, 50] = [0.767  0.9501 0.9843], mr = 6.507, mrr = 0.833, Loss = 33.1608
INFO - 12/17/25 16:21:21 - 0:15:15 - Ep 141 | r2l: acc of top [1, 10, 50] = [0.7711 0.9503 0.9859], mr = 7.532, mrr = 0.836, Loss = 33.1608
Train | Ep [141/250] Step [285/500] LR [0.00026] Loss 33.16077 :  57%|██████████████████████████████████▋                          | 142/250 [14:53<11:19,  6.29s/it]Train | Ep [142/250] Step [287/500] LR [0.00025] Loss 32.93218 :  57%|██████████████████████████████████▋                          | 142/250 [14:55<11:19,  6.29s/it]INFO - 12/17/25 16:21:27 - 0:15:21 - Ep 142 | l2r: acc of top [1, 10, 50] = [0.7681 0.9498 0.9845], mr = 6.567, mrr = 0.834, Loss = 32.9322
INFO - 12/17/25 16:21:27 - 0:15:21 - Ep 142 | r2l: acc of top [1, 10, 50] = [0.7715 0.9501 0.986 ], mr = 7.536, mrr = 0.836, Loss = 32.9322
Train | Ep [142/250] Step [287/500] LR [0.00025] Loss 32.93218 :  57%|██████████████████████████████████▉                          | 143/250 [14:59<11:13,  6.30s/it]Train | Ep [143/250] Step [289/500] LR [0.00025] Loss 32.92716 :  57%|██████████████████████████████████▉                          | 143/250 [15:01<11:13,  6.30s/it]INFO - 12/17/25 16:21:34 - 0:15:27 - Ep 143 | l2r: acc of top [1, 10, 50] = [0.7702 0.9513 0.9852], mr = 6.461, mrr = 0.835, Loss = 32.9272
INFO - 12/17/25 16:21:34 - 0:15:27 - Ep 143 | r2l: acc of top [1, 10, 50] = [0.7741 0.9508 0.9864], mr = 7.503, mrr = 0.838, Loss = 32.9272
Train | Ep [143/250] Step [289/500] LR [0.00025] Loss 32.92716 :  58%|███████████████████████████████████▏                         | 144/250 [15:05<11:04,  6.27s/it]Train | Ep [144/250] Step [291/500] LR [0.00025] Loss 32.86598 :  58%|███████████████████████████████████▏                         | 144/250 [15:07<11:04,  6.27s/it]INFO - 12/17/25 16:21:40 - 0:15:34 - Ep 144 | l2r: acc of top [1, 10, 50] = [0.7685 0.9511 0.9845], mr = 6.567, mrr = 0.834, Loss = 32.8660
INFO - 12/17/25 16:21:40 - 0:15:34 - Ep 144 | r2l: acc of top [1, 10, 50] = [0.773  0.9508 0.986 ], mr = 7.476, mrr = 0.837, Loss = 32.8660
Train | Ep [144/250] Step [291/500] LR [0.00025] Loss 32.86598 :  58%|███████████████████████████████████▍                         | 145/250 [15:12<10:58,  6.28s/it]Train | Ep [145/250] Step [293/500] LR [0.00024] Loss 32.76536 :  58%|███████████████████████████████████▍                         | 145/250 [15:14<10:58,  6.28s/it]INFO - 12/17/25 16:21:46 - 0:15:40 - Ep 145 | l2r: acc of top [1, 10, 50] = [0.7691 0.9517 0.985 ], mr = 6.599, mrr = 0.835, Loss = 32.7654
INFO - 12/17/25 16:21:46 - 0:15:40 - Ep 145 | r2l: acc of top [1, 10, 50] = [0.7733 0.951  0.9862], mr = 7.526, mrr = 0.837, Loss = 32.7654
Train | Ep [145/250] Step [293/500] LR [0.00024] Loss 32.76536 :  58%|███████████████████████████████████▌                         | 146/250 [15:18<10:53,  6.28s/it]Train | Ep [146/250] Step [295/500] LR [0.00024] Loss 32.82653 :  58%|███████████████████████████████████▌                         | 146/250 [15:20<10:53,  6.28s/it]INFO - 12/17/25 16:21:53 - 0:15:46 - Ep 146 | l2r: acc of top [1, 10, 50] = [0.769  0.9512 0.9851], mr = 6.660, mrr = 0.834, Loss = 32.8265
INFO - 12/17/25 16:21:53 - 0:15:46 - Ep 146 | r2l: acc of top [1, 10, 50] = [0.7726 0.9508 0.9862], mr = 7.618, mrr = 0.837, Loss = 32.8265
Train | Ep [146/250] Step [295/500] LR [0.00024] Loss 32.82653 :  59%|███████████████████████████████████▊                         | 147/250 [15:24<10:52,  6.34s/it]Train | Ep [147/250] Step [297/500] LR [0.00023] Loss 32.69950 :  59%|███████████████████████████████████▊                         | 147/250 [15:27<10:52,  6.34s/it]INFO - 12/17/25 16:21:59 - 0:15:53 - Ep 147 | l2r: acc of top [1, 10, 50] = [0.7685 0.9509 0.9847], mr = 6.709, mrr = 0.834, Loss = 32.6995
INFO - 12/17/25 16:21:59 - 0:15:53 - Ep 147 | r2l: acc of top [1, 10, 50] = [0.7728 0.95   0.9859], mr = 7.696, mrr = 0.837, Loss = 32.6995
Train | Ep [147/250] Step [297/500] LR [0.00023] Loss 32.69950 :  59%|████████████████████████████████████                         | 148/250 [15:31<10:48,  6.35s/it]Train | Ep [148/250] Step [299/500] LR [0.00023] Loss 32.62831 :  59%|████████████████████████████████████                         | 148/250 [15:33<10:48,  6.35s/it]INFO - 12/17/25 16:22:05 - 0:15:59 - Ep 148 | l2r: acc of top [1, 10, 50] = [0.7697 0.9504 0.9846], mr = 6.731, mrr = 0.834, Loss = 32.6283
INFO - 12/17/25 16:22:05 - 0:15:59 - Ep 148 | r2l: acc of top [1, 10, 50] = [0.7733 0.9499 0.9861], mr = 7.838, mrr = 0.837, Loss = 32.6283
Train | Ep [148/250] Step [299/500] LR [0.00023] Loss 32.62831 :  60%|████████████████████████████████████▎                        | 149/250 [15:37<10:41,  6.35s/it]Train | Ep [149/250] Step [301/500] LR [0.00023] Loss 32.62791 :  60%|████████████████████████████████████▎                        | 149/250 [15:39<10:41,  6.35s/it]INFO - 12/17/25 16:22:11 - 0:16:05 - Ep 149 | l2r: acc of top [1, 10, 50] = [0.7681 0.9504 0.9841], mr = 6.799, mrr = 0.833, Loss = 32.6279
INFO - 12/17/25 16:22:11 - 0:16:05 - Ep 149 | r2l: acc of top [1, 10, 50] = [0.7722 0.9503 0.9857], mr = 7.908, mrr = 0.837, Loss = 32.6279
Train | Ep [149/250] Step [301/500] LR [0.00023] Loss 32.62791 :  60%|████████████████████████████████████▌                        | 150/250 [15:43<10:27,  6.27s/it]Train | Ep [150/250] Step [303/500] LR [0.00022] Loss 32.51480 :  60%|████████████████████████████████████▌                        | 150/250 [15:45<10:27,  6.27s/it]INFO - 12/17/25 16:22:18 - 0:16:11 - Ep 150 | l2r: acc of top [1, 10, 50] = [0.7691 0.9505 0.9846], mr = 6.750, mrr = 0.834, Loss = 32.5148
INFO - 12/17/25 16:22:18 - 0:16:11 - Ep 150 | r2l: acc of top [1, 10, 50] = [0.7722 0.9505 0.9858], mr = 7.949, mrr = 0.837, Loss = 32.5148
Train | Ep [150/250] Step [303/500] LR [0.00022] Loss 32.51480 :  60%|████████████████████████████████████▊                        | 151/250 [15:49<10:18,  6.25s/it]Train | Ep [151/250] Step [305/500] LR [0.00022] Loss 32.53547 :  60%|████████████████████████████████████▊                        | 151/250 [15:52<10:18,  6.25s/it]INFO - 12/17/25 16:22:24 - 0:16:18 - Ep 151 | l2r: acc of top [1, 10, 50] = [0.7685 0.9503 0.9846], mr = 6.850, mrr = 0.834, Loss = 32.5355
INFO - 12/17/25 16:22:24 - 0:16:18 - Ep 151 | r2l: acc of top [1, 10, 50] = [0.771  0.9502 0.9854], mr = 7.930, mrr = 0.836, Loss = 32.5355
Train | Ep [151/250] Step [305/500] LR [0.00022] Loss 32.53547 :  61%|█████████████████████████████████████                        | 152/250 [15:56<10:13,  6.26s/it]Train | Ep [152/250] Step [307/500] LR [0.00022] Loss 32.57421 :  61%|█████████████████████████████████████                        | 152/250 [15:58<10:13,  6.26s/it]INFO - 12/17/25 16:22:30 - 0:16:24 - Ep 152 | l2r: acc of top [1, 10, 50] = [0.7687 0.9503 0.9846], mr = 6.800, mrr = 0.834, Loss = 32.5742
INFO - 12/17/25 16:22:30 - 0:16:24 - Ep 152 | r2l: acc of top [1, 10, 50] = [0.7711 0.9508 0.9858], mr = 7.902, mrr = 0.836, Loss = 32.5742
Train | Ep [152/250] Step [307/500] LR [0.00022] Loss 32.57421 :  61%|█████████████████████████████████████▎                       | 153/250 [16:02<10:09,  6.28s/it]Train | Ep [153/250] Step [309/500] LR [0.00021] Loss 32.41332 :  61%|█████████████████████████████████████▎                       | 153/250 [16:04<10:09,  6.28s/it]INFO - 12/17/25 16:22:37 - 0:16:30 - Ep 153 | l2r: acc of top [1, 10, 50] = [0.7682 0.95   0.9847], mr = 6.871, mrr = 0.834, Loss = 32.4133
INFO - 12/17/25 16:22:37 - 0:16:30 - Ep 153 | r2l: acc of top [1, 10, 50] = [0.7721 0.9503 0.9859], mr = 7.967, mrr = 0.836, Loss = 32.4133
Train | Ep [153/250] Step [309/500] LR [0.00021] Loss 32.41332 :  62%|█████████████████████████████████████▌                       | 154/250 [16:09<10:08,  6.33s/it]Train | Ep [154/250] Step [311/500] LR [0.00021] Loss 32.19032 :  62%|█████████████████████████████████████▌                       | 154/250 [16:11<10:08,  6.33s/it]INFO - 12/17/25 16:22:43 - 0:16:37 - Ep 154 | l2r: acc of top [1, 10, 50] = [0.7689 0.9504 0.9846], mr = 7.020, mrr = 0.834, Loss = 32.1903
INFO - 12/17/25 16:22:43 - 0:16:37 - Ep 154 | r2l: acc of top [1, 10, 50] = [0.771  0.95   0.9856], mr = 8.042, mrr = 0.835, Loss = 32.1903
Train | Ep [154/250] Step [311/500] LR [0.00021] Loss 32.19032 :  62%|█████████████████████████████████████▊                       | 155/250 [16:15<10:02,  6.34s/it]Train | Ep [155/250] Step [313/500] LR [0.00020] Loss 32.23805 :  62%|█████████████████████████████████████▊                       | 155/250 [16:17<10:02,  6.34s/it]INFO - 12/17/25 16:22:49 - 0:16:43 - Ep 155 | l2r: acc of top [1, 10, 50] = [0.7678 0.9501 0.9844], mr = 7.024, mrr = 0.833, Loss = 32.2381
INFO - 12/17/25 16:22:49 - 0:16:43 - Ep 155 | r2l: acc of top [1, 10, 50] = [0.7711 0.9504 0.9856], mr = 8.121, mrr = 0.836, Loss = 32.2381
Train | Ep [155/250] Step [313/500] LR [0.00020] Loss 32.23805 :  62%|██████████████████████████████████████                       | 156/250 [16:21<09:56,  6.35s/it]Train | Ep [156/250] Step [315/500] LR [0.00020] Loss 32.29691 :  62%|██████████████████████████████████████                       | 156/250 [16:23<09:56,  6.35s/it]INFO - 12/17/25 16:22:56 - 0:16:50 - Ep 156 | l2r: acc of top [1, 10, 50] = [0.7673 0.9495 0.9841], mr = 7.135, mrr = 0.833, Loss = 32.2969
INFO - 12/17/25 16:22:56 - 0:16:50 - Ep 156 | r2l: acc of top [1, 10, 50] = [0.771  0.9497 0.9854], mr = 8.189, mrr = 0.835, Loss = 32.2969
Train | Ep [156/250] Step [315/500] LR [0.00020] Loss 32.29691 :  63%|██████████████████████████████████████▎                      | 157/250 [16:28<09:51,  6.36s/it]Train | Ep [157/250] Step [317/500] LR [0.00020] Loss 32.40206 :  63%|██████████████████████████████████████▎                      | 157/250 [16:30<09:51,  6.36s/it]INFO - 12/17/25 16:23:02 - 0:16:56 - Ep 157 | l2r: acc of top [1, 10, 50] = [0.767  0.9493 0.9839], mr = 7.229, mrr = 0.832, Loss = 32.4021
INFO - 12/17/25 16:23:02 - 0:16:56 - Ep 157 | r2l: acc of top [1, 10, 50] = [0.7698 0.9495 0.9854], mr = 8.290, mrr = 0.834, Loss = 32.4021
Train | Ep [157/250] Step [317/500] LR [0.00020] Loss 32.40206 :  63%|██████████████████████████████████████▌                      | 158/250 [16:34<09:43,  6.34s/it]Train | Ep [158/250] Step [319/500] LR [0.00019] Loss 32.05822 :  63%|██████████████████████████████████████▌                      | 158/250 [16:36<09:43,  6.34s/it]INFO - 12/17/25 16:23:09 - 0:17:02 - Ep 158 | l2r: acc of top [1, 10, 50] = [0.7656 0.9494 0.9839], mr = 7.266, mrr = 0.832, Loss = 32.0582
INFO - 12/17/25 16:23:09 - 0:17:02 - Ep 158 | r2l: acc of top [1, 10, 50] = [0.7691 0.9493 0.9853], mr = 8.317, mrr = 0.834, Loss = 32.0582
Train | Ep [158/250] Step [319/500] LR [0.00019] Loss 32.05822 :  64%|██████████████████████████████████████▊                      | 159/250 [16:40<09:37,  6.34s/it]Train | Ep [159/250] Step [321/500] LR [0.00019] Loss 32.02747 :  64%|██████████████████████████████████████▊                      | 159/250 [16:42<09:37,  6.34s/it]INFO - 12/17/25 16:23:15 - 0:17:09 - Ep 159 | l2r: acc of top [1, 10, 50] = [0.765 0.949 0.984], mr = 7.355, mrr = 0.831, Loss = 32.0275
INFO - 12/17/25 16:23:15 - 0:17:09 - Ep 159 | r2l: acc of top [1, 10, 50] = [0.7694 0.9489 0.9851], mr = 8.368, mrr = 0.834, Loss = 32.0275
Train | Ep [159/250] Step [321/500] LR [0.00019] Loss 32.02747 :  64%|███████████████████████████████████████                      | 160/250 [16:47<09:30,  6.34s/it]Train | Ep [160/250] Step [323/500] LR [0.00019] Loss 32.24576 :  64%|███████████████████████████████████████                      | 160/250 [16:49<09:30,  6.34s/it]INFO - 12/17/25 16:23:21 - 0:17:15 - Ep 160 | l2r: acc of top [1, 10, 50] = [0.7656 0.949  0.9842], mr = 7.390, mrr = 0.832, Loss = 32.2458
INFO - 12/17/25 16:23:21 - 0:17:15 - Ep 160 | r2l: acc of top [1, 10, 50] = [0.7694 0.949  0.9853], mr = 8.379, mrr = 0.834, Loss = 32.2458
Train | Ep [160/250] Step [323/500] LR [0.00019] Loss 32.24576 :  64%|███████████████████████████████████████▎                     | 161/250 [16:53<09:20,  6.30s/it]Train | Ep [161/250] Step [325/500] LR [0.00018] Loss 31.99958 :  64%|███████████████████████████████████████▎                     | 161/250 [16:55<09:20,  6.30s/it]INFO - 12/17/25 16:23:27 - 0:17:21 - Ep 161 | l2r: acc of top [1, 10, 50] = [0.7658 0.9493 0.9839], mr = 7.465, mrr = 0.832, Loss = 31.9996
INFO - 12/17/25 16:23:27 - 0:17:21 - Ep 161 | r2l: acc of top [1, 10, 50] = [0.7706 0.9492 0.9854], mr = 8.428, mrr = 0.835, Loss = 31.9996
Train | Ep [161/250] Step [325/500] LR [0.00018] Loss 31.99958 :  65%|███████████████████████████████████████▌                     | 162/250 [16:59<09:10,  6.25s/it]Train | Ep [162/250] Step [327/500] LR [0.00018] Loss 32.06876 :  65%|███████████████████████████████████████▌                     | 162/250 [17:01<09:10,  6.25s/it]INFO - 12/17/25 16:23:34 - 0:17:27 - Ep 162 | l2r: acc of top [1, 10, 50] = [0.7665 0.949  0.9839], mr = 7.484, mrr = 0.832, Loss = 32.0688
INFO - 12/17/25 16:23:34 - 0:17:27 - Ep 162 | r2l: acc of top [1, 10, 50] = [0.7704 0.949  0.9852], mr = 8.481, mrr = 0.835, Loss = 32.0688
Train | Ep [162/250] Step [327/500] LR [0.00018] Loss 32.06876 :  65%|███████████████████████████████████████▊                     | 163/250 [17:05<09:08,  6.31s/it]Train | Ep [163/250] Step [329/500] LR [0.00018] Loss 31.93425 :  65%|███████████████████████████████████████▊                     | 163/250 [17:07<09:08,  6.31s/it]INFO - 12/17/25 16:23:40 - 0:17:34 - Ep 163 | l2r: acc of top [1, 10, 50] = [0.7658 0.9481 0.9839], mr = 7.585, mrr = 0.831, Loss = 31.9343
INFO - 12/17/25 16:23:40 - 0:17:34 - Ep 163 | r2l: acc of top [1, 10, 50] = [0.7695 0.9489 0.9851], mr = 8.525, mrr = 0.834, Loss = 31.9343
Train | Ep [163/250] Step [329/500] LR [0.00018] Loss 31.93425 :  66%|████████████████████████████████████████                     | 164/250 [17:12<09:03,  6.32s/it]Train | Ep [164/250] Step [331/500] LR [0.00017] Loss 31.96618 :  66%|████████████████████████████████████████                     | 164/250 [17:14<09:03,  6.32s/it]INFO - 12/17/25 16:23:46 - 0:17:40 - Ep 164 | l2r: acc of top [1, 10, 50] = [0.7653 0.9484 0.9839], mr = 7.600, mrr = 0.831, Loss = 31.9662
INFO - 12/17/25 16:23:46 - 0:17:40 - Ep 164 | r2l: acc of top [1, 10, 50] = [0.7695 0.9491 0.985 ], mr = 8.587, mrr = 0.834, Loss = 31.9662
Train | Ep [164/250] Step [331/500] LR [0.00017] Loss 31.96618 :  66%|████████████████████████████████████████▎                    | 165/250 [17:18<08:56,  6.32s/it]Train | Ep [165/250] Step [333/500] LR [0.00017] Loss 31.81802 :  66%|████████████████████████████████████████▎                    | 165/250 [17:20<08:56,  6.32s/it]INFO - 12/17/25 16:23:53 - 0:17:46 - Ep 165 | l2r: acc of top [1, 10, 50] = [0.7656 0.9482 0.9839], mr = 7.656, mrr = 0.831, Loss = 31.8180
INFO - 12/17/25 16:23:53 - 0:17:46 - Ep 165 | r2l: acc of top [1, 10, 50] = [0.7697 0.9483 0.985 ], mr = 8.619, mrr = 0.834, Loss = 31.8180
Train | Ep [165/250] Step [333/500] LR [0.00017] Loss 31.81802 :  66%|████████████████████████████████████████▌                    | 166/250 [17:24<08:50,  6.31s/it]Train | Ep [166/250] Step [335/500] LR [0.00017] Loss 31.81613 :  66%|████████████████████████████████████████▌                    | 166/250 [17:26<08:50,  6.31s/it]INFO - 12/17/25 16:23:59 - 0:17:53 - Ep 166 | l2r: acc of top [1, 10, 50] = [0.7651 0.9476 0.9838], mr = 7.662, mrr = 0.831, Loss = 31.8161
INFO - 12/17/25 16:23:59 - 0:17:53 - Ep 166 | r2l: acc of top [1, 10, 50] = [0.7696 0.9487 0.985 ], mr = 8.651, mrr = 0.834, Loss = 31.8161
Train | Ep [166/250] Step [335/500] LR [0.00017] Loss 31.81613 :  67%|████████████████████████████████████████▋                    | 167/250 [17:31<08:44,  6.32s/it]Train | Ep [167/250] Step [337/500] LR [0.00016] Loss 32.00513 :  67%|████████████████████████████████████████▋                    | 167/250 [17:33<08:44,  6.32s/it]INFO - 12/17/25 16:24:05 - 0:17:59 - Ep 167 | l2r: acc of top [1, 10, 50] = [0.7656 0.948  0.9833], mr = 7.768, mrr = 0.831, Loss = 32.0051
INFO - 12/17/25 16:24:05 - 0:17:59 - Ep 167 | r2l: acc of top [1, 10, 50] = [0.7694 0.9479 0.9849], mr = 8.710, mrr = 0.834, Loss = 32.0051
Train | Ep [167/250] Step [337/500] LR [0.00016] Loss 32.00513 :  67%|████████████████████████████████████████▉                    | 168/250 [17:37<08:39,  6.34s/it]Train | Ep [168/250] Step [339/500] LR [0.00016] Loss 31.73599 :  67%|████████████████████████████████████████▉                    | 168/250 [17:39<08:39,  6.34s/it]INFO - 12/17/25 16:24:12 - 0:18:05 - Ep 168 | l2r: acc of top [1, 10, 50] = [0.7652 0.9476 0.9834], mr = 7.826, mrr = 0.831, Loss = 31.7360
INFO - 12/17/25 16:24:12 - 0:18:05 - Ep 168 | r2l: acc of top [1, 10, 50] = [0.7699 0.9484 0.9849], mr = 8.736, mrr = 0.834, Loss = 31.7360
Train | Ep [168/250] Step [339/500] LR [0.00016] Loss 31.73599 :  68%|█████████████████████████████████████████▏                   | 169/250 [17:43<08:30,  6.30s/it]Train | Ep [169/250] Step [341/500] LR [0.00016] Loss 31.66926 :  68%|█████████████████████████████████████████▏                   | 169/250 [17:45<08:30,  6.30s/it]INFO - 12/17/25 16:24:18 - 0:18:12 - Ep 169 | l2r: acc of top [1, 10, 50] = [0.7657 0.9477 0.9835], mr = 7.839, mrr = 0.831, Loss = 31.6693
INFO - 12/17/25 16:24:18 - 0:18:12 - Ep 169 | r2l: acc of top [1, 10, 50] = [0.7696 0.9482 0.985 ], mr = 8.787, mrr = 0.834, Loss = 31.6693
Train | Ep [169/250] Step [341/500] LR [0.00016] Loss 31.66926 :  68%|█████████████████████████████████████████▍                   | 170/250 [17:50<08:25,  6.31s/it]Train | Ep [170/250] Step [343/500] LR [0.00015] Loss 31.46858 :  68%|█████████████████████████████████████████▍                   | 170/250 [17:52<08:25,  6.31s/it]INFO - 12/17/25 16:24:24 - 0:18:18 - Ep 170 | l2r: acc of top [1, 10, 50] = [0.7654 0.9473 0.9836], mr = 7.990, mrr = 0.831, Loss = 31.4686
INFO - 12/17/25 16:24:24 - 0:18:18 - Ep 170 | r2l: acc of top [1, 10, 50] = [0.7694 0.9478 0.9847], mr = 8.832, mrr = 0.833, Loss = 31.4686
Train | Ep [170/250] Step [343/500] LR [0.00015] Loss 31.46858 :  68%|█████████████████████████████████████████▋                   | 171/250 [17:56<08:18,  6.31s/it]Train | Ep [171/250] Step [345/500] LR [0.00015] Loss 31.57027 :  68%|█████████████████████████████████████████▋                   | 171/250 [17:58<08:18,  6.31s/it]INFO - 12/17/25 16:24:30 - 0:18:24 - Ep 171 | l2r: acc of top [1, 10, 50] = [0.7642 0.9469 0.9835], mr = 8.047, mrr = 0.830, Loss = 31.5703
INFO - 12/17/25 16:24:30 - 0:18:24 - Ep 171 | r2l: acc of top [1, 10, 50] = [0.7688 0.9478 0.9847], mr = 8.909, mrr = 0.833, Loss = 31.5703
Train | Ep [171/250] Step [345/500] LR [0.00015] Loss 31.57027 :  69%|█████████████████████████████████████████▉                   | 172/250 [18:02<08:09,  6.28s/it]Train | Ep [172/250] Step [347/500] LR [0.00015] Loss 31.65872 :  69%|█████████████████████████████████████████▉                   | 172/250 [18:04<08:09,  6.28s/it]INFO - 12/17/25 16:24:37 - 0:18:30 - Ep 172 | l2r: acc of top [1, 10, 50] = [0.765  0.9474 0.9832], mr = 8.048, mrr = 0.830, Loss = 31.6587
INFO - 12/17/25 16:24:37 - 0:18:30 - Ep 172 | r2l: acc of top [1, 10, 50] = [0.7696 0.9477 0.9848], mr = 8.966, mrr = 0.833, Loss = 31.6587
Train | Ep [172/250] Step [347/500] LR [0.00015] Loss 31.65872 :  69%|██████████████████████████████████████████▏                  | 173/250 [18:08<08:01,  6.25s/it]Train | Ep [173/250] Step [349/500] LR [0.00014] Loss 31.64788 :  69%|██████████████████████████████████████████▏                  | 173/250 [18:10<08:01,  6.25s/it]INFO - 12/17/25 16:24:43 - 0:18:37 - Ep 173 | l2r: acc of top [1, 10, 50] = [0.7649 0.9474 0.9831], mr = 8.067, mrr = 0.830, Loss = 31.6479
INFO - 12/17/25 16:24:43 - 0:18:37 - Ep 173 | r2l: acc of top [1, 10, 50] = [0.7695 0.9478 0.985 ], mr = 8.986, mrr = 0.833, Loss = 31.6479
Train | Ep [173/250] Step [349/500] LR [0.00014] Loss 31.64788 :  70%|██████████████████████████████████████████▍                  | 174/250 [18:15<07:56,  6.27s/it]Train | Ep [174/250] Step [351/500] LR [0.00014] Loss 31.64168 :  70%|██████████████████████████████████████████▍                  | 174/250 [18:17<07:56,  6.27s/it]INFO - 12/17/25 16:24:49 - 0:18:43 - Ep 174 | l2r: acc of top [1, 10, 50] = [0.7638 0.9473 0.983 ], mr = 8.079, mrr = 0.830, Loss = 31.6417
INFO - 12/17/25 16:24:49 - 0:18:43 - Ep 174 | r2l: acc of top [1, 10, 50] = [0.769  0.9477 0.9848], mr = 8.966, mrr = 0.833, Loss = 31.6417
Train | Ep [174/250] Step [351/500] LR [0.00014] Loss 31.64168 :  70%|██████████████████████████████████████████▋                  | 175/250 [18:21<07:53,  6.31s/it]Train | Ep [175/250] Step [353/500] LR [0.00014] Loss 31.45407 :  70%|██████████████████████████████████████████▋                  | 175/250 [18:23<07:53,  6.31s/it]INFO - 12/17/25 16:24:56 - 0:18:49 - Ep 175 | l2r: acc of top [1, 10, 50] = [0.7629 0.9466 0.983 ], mr = 8.179, mrr = 0.829, Loss = 31.4541
INFO - 12/17/25 16:24:56 - 0:18:49 - Ep 175 | r2l: acc of top [1, 10, 50] = [0.7689 0.9472 0.9844], mr = 8.990, mrr = 0.832, Loss = 31.4541
Train | Ep [175/250] Step [353/500] LR [0.00014] Loss 31.45407 :  70%|██████████████████████████████████████████▉                  | 176/250 [18:27<07:50,  6.35s/it]Train | Ep [176/250] Step [355/500] LR [0.00013] Loss 31.31663 :  70%|██████████████████████████████████████████▉                  | 176/250 [18:30<07:50,  6.35s/it]INFO - 12/17/25 16:25:02 - 0:18:56 - Ep 176 | l2r: acc of top [1, 10, 50] = [0.7624 0.947  0.9832], mr = 8.240, mrr = 0.829, Loss = 31.3166
INFO - 12/17/25 16:25:02 - 0:18:56 - Ep 176 | r2l: acc of top [1, 10, 50] = [0.7688 0.947  0.9845], mr = 9.006, mrr = 0.833, Loss = 31.3166
Train | Ep [176/250] Step [355/500] LR [0.00013] Loss 31.31663 :  71%|███████████████████████████████████████████▏                 | 177/250 [18:34<07:45,  6.38s/it]Train | Ep [177/250] Step [357/500] LR [0.00013] Loss 31.34328 :  71%|███████████████████████████████████████████▏                 | 177/250 [18:36<07:45,  6.38s/it]INFO - 12/17/25 16:25:09 - 0:19:02 - Ep 177 | l2r: acc of top [1, 10, 50] = [0.7628 0.9473 0.9827], mr = 8.299, mrr = 0.829, Loss = 31.3433
INFO - 12/17/25 16:25:09 - 0:19:02 - Ep 177 | r2l: acc of top [1, 10, 50] = [0.769  0.9469 0.9845], mr = 9.049, mrr = 0.833, Loss = 31.3433
Train | Ep [177/250] Step [357/500] LR [0.00013] Loss 31.34328 :  71%|███████████████████████████████████████████▍                 | 178/250 [18:40<07:39,  6.38s/it]Train | Ep [178/250] Step [359/500] LR [0.00013] Loss 31.41254 :  71%|███████████████████████████████████████████▍                 | 178/250 [18:43<07:39,  6.38s/it]INFO - 12/17/25 16:25:15 - 0:19:09 - Ep 178 | l2r: acc of top [1, 10, 50] = [0.7627 0.9475 0.9827], mr = 8.364, mrr = 0.829, Loss = 31.4125
INFO - 12/17/25 16:25:15 - 0:19:09 - Ep 178 | r2l: acc of top [1, 10, 50] = [0.7684 0.9469 0.9843], mr = 9.120, mrr = 0.833, Loss = 31.4125
Train | Ep [178/250] Step [359/500] LR [0.00013] Loss 31.41254 :  72%|███████████████████████████████████████████▋                 | 179/250 [18:47<07:33,  6.39s/it]Train | Ep [179/250] Step [361/500] LR [0.00012] Loss 31.37344 :  72%|███████████████████████████████████████████▋                 | 179/250 [18:49<07:33,  6.39s/it]INFO - 12/17/25 16:25:21 - 0:19:15 - Ep 179 | l2r: acc of top [1, 10, 50] = [0.7629 0.9472 0.9826], mr = 8.403, mrr = 0.829, Loss = 31.3734
INFO - 12/17/25 16:25:21 - 0:19:15 - Ep 179 | r2l: acc of top [1, 10, 50] = [0.7685 0.9469 0.9846], mr = 9.185, mrr = 0.832, Loss = 31.3734
Train | Ep [179/250] Step [361/500] LR [0.00012] Loss 31.37344 :  72%|███████████████████████████████████████████▉                 | 180/250 [18:53<07:28,  6.40s/it]Train | Ep [180/250] Step [363/500] LR [0.00012] Loss 31.10553 :  72%|███████████████████████████████████████████▉                 | 180/250 [18:55<07:28,  6.40s/it]INFO - 12/17/25 16:25:28 - 0:19:21 - Ep 180 | l2r: acc of top [1, 10, 50] = [0.7622 0.9469 0.983 ], mr = 8.435, mrr = 0.829, Loss = 31.1055
INFO - 12/17/25 16:25:28 - 0:19:21 - Ep 180 | r2l: acc of top [1, 10, 50] = [0.7685 0.9464 0.9841], mr = 9.197, mrr = 0.832, Loss = 31.1055
Train | Ep [180/250] Step [363/500] LR [0.00012] Loss 31.10553 :  72%|████████████████████████████████████████████▏                | 181/250 [18:59<07:19,  6.37s/it]Train | Ep [181/250] Step [365/500] LR [0.00012] Loss 31.16518 :  72%|████████████████████████████████████████████▏                | 181/250 [19:02<07:19,  6.37s/it]INFO - 12/17/25 16:25:34 - 0:19:28 - Ep 181 | l2r: acc of top [1, 10, 50] = [0.761  0.9469 0.9826], mr = 8.619, mrr = 0.828, Loss = 31.1652
INFO - 12/17/25 16:25:34 - 0:19:28 - Ep 181 | r2l: acc of top [1, 10, 50] = [0.7671 0.9466 0.9844], mr = 9.291, mrr = 0.831, Loss = 31.1652
Train | Ep [181/250] Step [365/500] LR [0.00012] Loss 31.16518 :  73%|████████████████████████████████████████████▍                | 182/250 [19:06<07:10,  6.32s/it]Train | Ep [182/250] Step [367/500] LR [0.00011] Loss 31.14181 :  73%|████████████████████████████████████████████▍                | 182/250 [19:08<07:10,  6.32s/it]INFO - 12/17/25 16:25:40 - 0:19:34 - Ep 182 | l2r: acc of top [1, 10, 50] = [0.7622 0.947  0.9828], mr = 8.641, mrr = 0.829, Loss = 31.1418
INFO - 12/17/25 16:25:40 - 0:19:34 - Ep 182 | r2l: acc of top [1, 10, 50] = [0.7676 0.9466 0.9842], mr = 9.365, mrr = 0.832, Loss = 31.1418
Train | Ep [182/250] Step [367/500] LR [0.00011] Loss 31.14181 :  73%|████████████████████████████████████████████▋                | 183/250 [19:12<07:01,  6.29s/it]Train | Ep [183/250] Step [369/500] LR [0.00011] Loss 31.27637 :  73%|████████████████████████████████████████████▋                | 183/250 [19:14<07:01,  6.29s/it]INFO - 12/17/25 16:25:46 - 0:19:40 - Ep 183 | l2r: acc of top [1, 10, 50] = [0.7626 0.947  0.9826], mr = 8.695, mrr = 0.829, Loss = 31.2764
INFO - 12/17/25 16:25:46 - 0:19:40 - Ep 183 | r2l: acc of top [1, 10, 50] = [0.7671 0.9466 0.9844], mr = 9.421, mrr = 0.832, Loss = 31.2764
Train | Ep [183/250] Step [369/500] LR [0.00011] Loss 31.27637 :  74%|████████████████████████████████████████████▉                | 184/250 [19:18<06:54,  6.28s/it]Train | Ep [184/250] Step [371/500] LR [0.00011] Loss 31.23469 :  74%|████████████████████████████████████████████▉                | 184/250 [19:20<06:54,  6.28s/it]INFO - 12/17/25 16:25:53 - 0:19:47 - Ep 184 | l2r: acc of top [1, 10, 50] = [0.7621 0.9468 0.9824], mr = 8.785, mrr = 0.828, Loss = 31.2347
INFO - 12/17/25 16:25:53 - 0:19:47 - Ep 184 | r2l: acc of top [1, 10, 50] = [0.7667 0.9463 0.9842], mr = 9.464, mrr = 0.831, Loss = 31.2347
Train | Ep [184/250] Step [371/500] LR [0.00011] Loss 31.23469 :  74%|█████████████████████████████████████████████▏               | 185/250 [19:25<06:51,  6.33s/it]Train | Ep [185/250] Step [373/500] LR [0.00010] Loss 31.31542 :  74%|█████████████████████████████████████████████▏               | 185/250 [19:27<06:51,  6.33s/it]INFO - 12/17/25 16:25:59 - 0:19:53 - Ep 185 | l2r: acc of top [1, 10, 50] = [0.7621 0.9467 0.9823], mr = 8.811, mrr = 0.828, Loss = 31.3154
INFO - 12/17/25 16:25:59 - 0:19:53 - Ep 185 | r2l: acc of top [1, 10, 50] = [0.7664 0.9463 0.9842], mr = 9.481, mrr = 0.831, Loss = 31.3154
Train | Ep [185/250] Step [373/500] LR [0.00010] Loss 31.31542 :  74%|█████████████████████████████████████████████▍               | 186/250 [19:31<06:45,  6.34s/it]Train | Ep [186/250] Step [375/500] LR [0.00010] Loss 31.15089 :  74%|█████████████████████████████████████████████▍               | 186/250 [19:33<06:45,  6.34s/it]INFO - 12/17/25 16:26:05 - 0:19:59 - Ep 186 | l2r: acc of top [1, 10, 50] = [0.7628 0.947  0.9822], mr = 8.845, mrr = 0.829, Loss = 31.1509
INFO - 12/17/25 16:26:05 - 0:19:59 - Ep 186 | r2l: acc of top [1, 10, 50] = [0.7676 0.9465 0.9841], mr = 9.503, mrr = 0.832, Loss = 31.1509
Train | Ep [186/250] Step [375/500] LR [0.00010] Loss 31.15089 :  75%|█████████████████████████████████████████████▋               | 187/250 [19:37<06:37,  6.31s/it]Train | Ep [187/250] Step [377/500] LR [0.00010] Loss 30.94908 :  75%|█████████████████████████████████████████████▋               | 187/250 [19:39<06:37,  6.31s/it]INFO - 12/17/25 16:26:12 - 0:20:05 - Ep 187 | l2r: acc of top [1, 10, 50] = [0.7617 0.9468 0.9822], mr = 8.906, mrr = 0.828, Loss = 30.9491
INFO - 12/17/25 16:26:12 - 0:20:05 - Ep 187 | r2l: acc of top [1, 10, 50] = [0.767  0.946  0.9841], mr = 9.517, mrr = 0.831, Loss = 30.9491
Train | Ep [187/250] Step [377/500] LR [0.00010] Loss 30.94908 :  75%|█████████████████████████████████████████████▊               | 188/250 [19:43<06:30,  6.30s/it]Train | Ep [188/250] Step [379/500] LR [0.00009] Loss 31.09492 :  75%|█████████████████████████████████████████████▊               | 188/250 [19:46<06:30,  6.30s/it]INFO - 12/17/25 16:26:18 - 0:20:12 - Ep 188 | l2r: acc of top [1, 10, 50] = [0.7629 0.947  0.9822], mr = 8.944, mrr = 0.829, Loss = 31.0949
INFO - 12/17/25 16:26:18 - 0:20:12 - Ep 188 | r2l: acc of top [1, 10, 50] = [0.766  0.9463 0.9839], mr = 9.540, mrr = 0.831, Loss = 31.0949
Train | Ep [188/250] Step [379/500] LR [0.00009] Loss 31.09492 :  76%|██████████████████████████████████████████████               | 189/250 [19:50<06:26,  6.34s/it]Train | Ep [189/250] Step [381/500] LR [0.00009] Loss 31.01634 :  76%|██████████████████████████████████████████████               | 189/250 [19:52<06:26,  6.34s/it]INFO - 12/17/25 16:26:24 - 0:20:18 - Ep 189 | l2r: acc of top [1, 10, 50] = [0.763  0.9468 0.9822], mr = 8.959, mrr = 0.829, Loss = 31.0163
INFO - 12/17/25 16:26:24 - 0:20:18 - Ep 189 | r2l: acc of top [1, 10, 50] = [0.7673 0.9467 0.984 ], mr = 9.555, mrr = 0.831, Loss = 31.0163
Train | Ep [189/250] Step [381/500] LR [0.00009] Loss 31.01634 :  76%|██████████████████████████████████████████████▎              | 190/250 [19:56<06:20,  6.34s/it]Train | Ep [190/250] Step [383/500] LR [0.00009] Loss 31.20582 :  76%|██████████████████████████████████████████████▎              | 190/250 [19:58<06:20,  6.34s/it]INFO - 12/17/25 16:26:31 - 0:20:24 - Ep 190 | l2r: acc of top [1, 10, 50] = [0.7621 0.9463 0.9817], mr = 8.985, mrr = 0.828, Loss = 31.2058
INFO - 12/17/25 16:26:31 - 0:20:24 - Ep 190 | r2l: acc of top [1, 10, 50] = [0.767  0.9461 0.9841], mr = 9.588, mrr = 0.831, Loss = 31.2058
Train | Ep [190/250] Step [383/500] LR [0.00009] Loss 31.20582 :  76%|██████████████████████████████████████████████▌              | 191/250 [20:02<06:12,  6.31s/it]Train | Ep [191/250] Step [385/500] LR [0.00009] Loss 31.00115 :  76%|██████████████████████████████████████████████▌              | 191/250 [20:05<06:12,  6.31s/it]INFO - 12/17/25 16:26:37 - 0:20:31 - Ep 191 | l2r: acc of top [1, 10, 50] = [0.7621 0.9465 0.9819], mr = 8.924, mrr = 0.828, Loss = 31.0012
INFO - 12/17/25 16:26:37 - 0:20:31 - Ep 191 | r2l: acc of top [1, 10, 50] = [0.7668 0.9465 0.984 ], mr = 9.595, mrr = 0.831, Loss = 31.0012
Train | Ep [191/250] Step [385/500] LR [0.00009] Loss 31.00115 :  77%|██████████████████████████████████████████████▊              | 192/250 [20:09<06:04,  6.29s/it]Train | Ep [192/250] Step [387/500] LR [0.00008] Loss 30.99797 :  77%|██████████████████████████████████████████████▊              | 192/250 [20:11<06:04,  6.29s/it]INFO - 12/17/25 16:26:43 - 0:20:37 - Ep 192 | l2r: acc of top [1, 10, 50] = [0.7625 0.9461 0.9821], mr = 8.958, mrr = 0.828, Loss = 30.9980
INFO - 12/17/25 16:26:43 - 0:20:37 - Ep 192 | r2l: acc of top [1, 10, 50] = [0.7665 0.9469 0.9836], mr = 9.615, mrr = 0.831, Loss = 30.9980
Train | Ep [192/250] Step [387/500] LR [0.00008] Loss 30.99797 :  77%|███████████████████████████████████████████████              | 193/250 [20:15<05:57,  6.27s/it]Train | Ep [193/250] Step [389/500] LR [0.00008] Loss 31.12609 :  77%|███████████████████████████████████████████████              | 193/250 [20:17<05:57,  6.27s/it]INFO - 12/17/25 16:26:49 - 0:20:43 - Ep 193 | l2r: acc of top [1, 10, 50] = [0.7623 0.9458 0.9824], mr = 9.025, mrr = 0.828, Loss = 31.1261
INFO - 12/17/25 16:26:49 - 0:20:43 - Ep 193 | r2l: acc of top [1, 10, 50] = [0.7665 0.9466 0.9837], mr = 9.633, mrr = 0.831, Loss = 31.1261
Train | Ep [193/250] Step [389/500] LR [0.00008] Loss 31.12609 :  78%|███████████████████████████████████████████████▎             | 194/250 [20:21<05:50,  6.25s/it]Train | Ep [194/250] Step [391/500] LR [0.00008] Loss 30.98163 :  78%|███████████████████████████████████████████████▎             | 194/250 [20:23<05:50,  6.25s/it]INFO - 12/17/25 16:26:56 - 0:20:49 - Ep 194 | l2r: acc of top [1, 10, 50] = [0.7618 0.9458 0.9823], mr = 9.045, mrr = 0.828, Loss = 30.9816
INFO - 12/17/25 16:26:56 - 0:20:49 - Ep 194 | r2l: acc of top [1, 10, 50] = [0.7664 0.9457 0.9835], mr = 9.652, mrr = 0.831, Loss = 30.9816
Train | Ep [194/250] Step [391/500] LR [0.00008] Loss 30.98163 :  78%|███████████████████████████████████████████████▌             | 195/250 [20:28<05:45,  6.29s/it]Train | Ep [195/250] Step [393/500] LR [0.00008] Loss 30.83135 :  78%|███████████████████████████████████████████████▌             | 195/250 [20:30<05:45,  6.29s/it]INFO - 12/17/25 16:27:02 - 0:20:56 - Ep 195 | l2r: acc of top [1, 10, 50] = [0.7623 0.9451 0.9822], mr = 9.044, mrr = 0.828, Loss = 30.8313
INFO - 12/17/25 16:27:02 - 0:20:56 - Ep 195 | r2l: acc of top [1, 10, 50] = [0.7659 0.9454 0.9835], mr = 9.684, mrr = 0.830, Loss = 30.8313
Train | Ep [195/250] Step [393/500] LR [0.00008] Loss 30.83135 :  78%|███████████████████████████████████████████████▊             | 196/250 [20:34<05:38,  6.27s/it]Train | Ep [196/250] Step [395/500] LR [0.00007] Loss 30.91098 :  78%|███████████████████████████████████████████████▊             | 196/250 [20:36<05:38,  6.27s/it]INFO - 12/17/25 16:27:08 - 0:21:02 - Ep 196 | l2r: acc of top [1, 10, 50] = [0.7623 0.9448 0.982 ], mr = 9.016, mrr = 0.828, Loss = 30.9110
INFO - 12/17/25 16:27:08 - 0:21:02 - Ep 196 | r2l: acc of top [1, 10, 50] = [0.7662 0.9452 0.9836], mr = 9.745, mrr = 0.830, Loss = 30.9110
Train | Ep [196/250] Step [395/500] LR [0.00007] Loss 30.91098 :  79%|████████████████████████████████████████████████             | 197/250 [20:40<05:32,  6.28s/it]Train | Ep [197/250] Step [397/500] LR [0.00007] Loss 30.91190 :  79%|████████████████████████████████████████████████             | 197/250 [20:42<05:32,  6.28s/it]INFO - 12/17/25 16:27:15 - 0:21:08 - Ep 197 | l2r: acc of top [1, 10, 50] = [0.7617 0.9448 0.982 ], mr = 8.988, mrr = 0.828, Loss = 30.9119
INFO - 12/17/25 16:27:15 - 0:21:08 - Ep 197 | r2l: acc of top [1, 10, 50] = [0.7654 0.9454 0.9836], mr = 9.746, mrr = 0.830, Loss = 30.9119
Train | Ep [197/250] Step [397/500] LR [0.00007] Loss 30.91190 :  79%|████████████████████████████████████████████████▎            | 198/250 [20:46<05:26,  6.29s/it]Train | Ep [198/250] Step [399/500] LR [0.00007] Loss 30.68473 :  79%|████████████████████████████████████████████████▎            | 198/250 [20:48<05:26,  6.29s/it]INFO - 12/17/25 16:27:21 - 0:21:15 - Ep 198 | l2r: acc of top [1, 10, 50] = [0.7613 0.9443 0.9821], mr = 9.065, mrr = 0.827, Loss = 30.6847
INFO - 12/17/25 16:27:21 - 0:21:15 - Ep 198 | r2l: acc of top [1, 10, 50] = [0.7659 0.9448 0.9837], mr = 9.729, mrr = 0.830, Loss = 30.6847
Train | Ep [198/250] Step [399/500] LR [0.00007] Loss 30.68473 :  80%|████████████████████████████████████████████████▌            | 199/250 [20:53<05:21,  6.31s/it]Train | Ep [199/250] Step [401/500] LR [0.00007] Loss 30.77678 :  80%|████████████████████████████████████████████████▌            | 199/250 [20:55<05:21,  6.31s/it]INFO - 12/17/25 16:27:27 - 0:21:21 - Ep 199 | l2r: acc of top [1, 10, 50] = [0.761  0.944  0.9821], mr = 9.095, mrr = 0.827, Loss = 30.7768
INFO - 12/17/25 16:27:27 - 0:21:21 - Ep 199 | r2l: acc of top [1, 10, 50] = [0.7644 0.945  0.9836], mr = 9.759, mrr = 0.829, Loss = 30.7768
Train | Ep [199/250] Step [401/500] LR [0.00007] Loss 30.77678 :  80%|████████████████████████████████████████████████▊            | 200/250 [20:59<05:15,  6.30s/it]Train | Ep [200/250] Step [403/500] LR [0.00006] Loss 30.72696 :  80%|████████████████████████████████████████████████▊            | 200/250 [21:01<05:15,  6.30s/it]INFO - 12/17/25 16:27:34 - 0:21:27 - Ep 200 | l2r: acc of top [1, 10, 50] = [0.761  0.9447 0.9825], mr = 9.076, mrr = 0.827, Loss = 30.7270
INFO - 12/17/25 16:27:34 - 0:21:27 - Ep 200 | r2l: acc of top [1, 10, 50] = [0.7645 0.9451 0.9837], mr = 9.776, mrr = 0.829, Loss = 30.7270
Train | Ep [200/250] Step [403/500] LR [0.00006] Loss 30.72696 :  80%|█████████████████████████████████████████████████            | 201/250 [21:05<05:10,  6.34s/it]Train | Ep [201/250] Step [405/500] LR [0.00006] Loss 30.64980 :  80%|█████████████████████████████████████████████████            | 201/250 [21:07<05:10,  6.34s/it]INFO - 12/17/25 16:27:40 - 0:21:33 - Ep 201 | l2r: acc of top [1, 10, 50] = [0.7611 0.9447 0.9822], mr = 9.136, mrr = 0.827, Loss = 30.6498
INFO - 12/17/25 16:27:40 - 0:21:33 - Ep 201 | r2l: acc of top [1, 10, 50] = [0.7648 0.9451 0.9835], mr = 9.846, mrr = 0.829, Loss = 30.6498
Train | Ep [201/250] Step [405/500] LR [0.00006] Loss 30.64980 :  81%|█████████████████████████████████████████████████▎           | 202/250 [21:11<05:00,  6.26s/it]Train | Ep [202/250] Step [407/500] LR [0.00006] Loss 30.78517 :  81%|█████████████████████████████████████████████████▎           | 202/250 [21:14<05:00,  6.26s/it]INFO - 12/17/25 16:27:46 - 0:21:40 - Ep 202 | l2r: acc of top [1, 10, 50] = [0.7612 0.9442 0.982 ], mr = 9.219, mrr = 0.827, Loss = 30.7852
INFO - 12/17/25 16:27:46 - 0:21:40 - Ep 202 | r2l: acc of top [1, 10, 50] = [0.7646 0.9447 0.9833], mr = 9.904, mrr = 0.829, Loss = 30.7852
Train | Ep [202/250] Step [407/500] LR [0.00006] Loss 30.78517 :  81%|█████████████████████████████████████████████████▌           | 203/250 [21:18<04:54,  6.27s/it]Train | Ep [203/250] Step [409/500] LR [0.00006] Loss 30.63056 :  81%|█████████████████████████████████████████████████▌           | 203/250 [21:20<04:54,  6.27s/it]INFO - 12/17/25 16:27:52 - 0:21:46 - Ep 203 | l2r: acc of top [1, 10, 50] = [0.7616 0.9445 0.9821], mr = 9.224, mrr = 0.827, Loss = 30.6306
INFO - 12/17/25 16:27:52 - 0:21:46 - Ep 203 | r2l: acc of top [1, 10, 50] = [0.7648 0.945  0.9834], mr = 9.886, mrr = 0.829, Loss = 30.6306
Train | Ep [203/250] Step [409/500] LR [0.00006] Loss 30.63056 :  82%|█████████████████████████████████████████████████▊           | 204/250 [21:24<04:47,  6.25s/it]Train | Ep [204/250] Step [411/500] LR [0.00005] Loss 30.59426 :  82%|█████████████████████████████████████████████████▊           | 204/250 [21:26<04:47,  6.25s/it]INFO - 12/17/25 16:27:58 - 0:21:52 - Ep 204 | l2r: acc of top [1, 10, 50] = [0.7616 0.9448 0.9824], mr = 9.252, mrr = 0.827, Loss = 30.5943
INFO - 12/17/25 16:27:58 - 0:21:52 - Ep 204 | r2l: acc of top [1, 10, 50] = [0.7649 0.9451 0.9834], mr = 9.866, mrr = 0.829, Loss = 30.5943
Train | Ep [204/250] Step [411/500] LR [0.00005] Loss 30.59426 :  82%|██████████████████████████████████████████████████           | 205/250 [21:30<04:41,  6.25s/it]Train | Ep [205/250] Step [413/500] LR [0.00005] Loss 30.70792 :  82%|██████████████████████████████████████████████████           | 205/250 [21:32<04:41,  6.25s/it]INFO - 12/17/25 16:28:05 - 0:21:59 - Ep 205 | l2r: acc of top [1, 10, 50] = [0.7608 0.9447 0.9823], mr = 9.339, mrr = 0.827, Loss = 30.7079
INFO - 12/17/25 16:28:05 - 0:21:59 - Ep 205 | r2l: acc of top [1, 10, 50] = [0.765  0.9449 0.983 ], mr = 9.878, mrr = 0.830, Loss = 30.7079
Train | Ep [205/250] Step [413/500] LR [0.00005] Loss 30.70792 :  82%|██████████████████████████████████████████████████▎          | 206/250 [21:37<04:36,  6.28s/it]Train | Ep [206/250] Step [415/500] LR [0.00005] Loss 30.68623 :  82%|██████████████████████████████████████████████████▎          | 206/250 [21:39<04:36,  6.28s/it]INFO - 12/17/25 16:28:11 - 0:22:05 - Ep 206 | l2r: acc of top [1, 10, 50] = [0.761  0.9447 0.9821], mr = 9.424, mrr = 0.827, Loss = 30.6862
INFO - 12/17/25 16:28:11 - 0:22:05 - Ep 206 | r2l: acc of top [1, 10, 50] = [0.7648 0.9448 0.9832], mr = 9.906, mrr = 0.829, Loss = 30.6862
Train | Ep [206/250] Step [415/500] LR [0.00005] Loss 30.68623 :  83%|██████████████████████████████████████████████████▌          | 207/250 [21:43<04:30,  6.29s/it]Train | Ep [207/250] Step [417/500] LR [0.00005] Loss 30.58354 :  83%|██████████████████████████████████████████████████▌          | 207/250 [21:45<04:30,  6.29s/it]INFO - 12/17/25 16:28:17 - 0:22:11 - Ep 207 | l2r: acc of top [1, 10, 50] = [0.7614 0.9448 0.982 ], mr = 9.358, mrr = 0.827, Loss = 30.5835
INFO - 12/17/25 16:28:17 - 0:22:11 - Ep 207 | r2l: acc of top [1, 10, 50] = [0.7643 0.9448 0.9834], mr = 9.905, mrr = 0.829, Loss = 30.5835
Train | Ep [207/250] Step [417/500] LR [0.00005] Loss 30.58354 :  83%|██████████████████████████████████████████████████▊          | 208/250 [21:49<04:24,  6.30s/it]Train | Ep [208/250] Step [419/500] LR [0.00004] Loss 30.64260 :  83%|██████████████████████████████████████████████████▊          | 208/250 [21:51<04:24,  6.30s/it]INFO - 12/17/25 16:28:24 - 0:22:17 - Ep 208 | l2r: acc of top [1, 10, 50] = [0.7613 0.9444 0.9822], mr = 9.344, mrr = 0.827, Loss = 30.6426
INFO - 12/17/25 16:28:24 - 0:22:17 - Ep 208 | r2l: acc of top [1, 10, 50] = [0.7644 0.9446 0.9833], mr = 9.912, mrr = 0.829, Loss = 30.6426
Train | Ep [208/250] Step [419/500] LR [0.00004] Loss 30.64260 :  84%|██████████████████████████████████████████████████▉          | 209/250 [21:56<04:18,  6.30s/it]Train | Ep [209/250] Step [421/500] LR [0.00004] Loss 30.75271 :  84%|██████████████████████████████████████████████████▉          | 209/250 [21:58<04:18,  6.30s/it]INFO - 12/17/25 16:28:30 - 0:22:24 - Ep 209 | l2r: acc of top [1, 10, 50] = [0.7602 0.9441 0.982 ], mr = 9.429, mrr = 0.826, Loss = 30.7527
INFO - 12/17/25 16:28:30 - 0:22:24 - Ep 209 | r2l: acc of top [1, 10, 50] = [0.7644 0.9438 0.9832], mr = 9.972, mrr = 0.829, Loss = 30.7527
Train | Ep [209/250] Step [421/500] LR [0.00004] Loss 30.75271 :  84%|███████████████████████████████████████████████████▏         | 210/250 [22:02<04:11,  6.29s/it]Train | Ep [210/250] Step [423/500] LR [0.00004] Loss 30.45608 :  84%|███████████████████████████████████████████████████▏         | 210/250 [22:04<04:11,  6.29s/it]INFO - 12/17/25 16:28:36 - 0:22:30 - Ep 210 | l2r: acc of top [1, 10, 50] = [0.7597 0.9443 0.982 ], mr = 9.454, mrr = 0.826, Loss = 30.4561
INFO - 12/17/25 16:28:36 - 0:22:30 - Ep 210 | r2l: acc of top [1, 10, 50] = [0.7647 0.944  0.9833], mr = 10.005, mrr = 0.829, Loss = 30.4561
Train | Ep [210/250] Step [423/500] LR [0.00004] Loss 30.45608 :  84%|███████████████████████████████████████████████████▍         | 211/250 [22:08<04:06,  6.31s/it]Train | Ep [211/250] Step [425/500] LR [0.00004] Loss 30.63410 :  84%|███████████████████████████████████████████████████▍         | 211/250 [22:10<04:06,  6.31s/it]INFO - 12/17/25 16:28:43 - 0:22:36 - Ep 211 | l2r: acc of top [1, 10, 50] = [0.7604 0.9442 0.9821], mr = 9.459, mrr = 0.826, Loss = 30.6341
INFO - 12/17/25 16:28:43 - 0:22:36 - Ep 211 | r2l: acc of top [1, 10, 50] = [0.7639 0.9441 0.9834], mr = 10.009, mrr = 0.829, Loss = 30.6341
Train | Ep [211/250] Step [425/500] LR [0.00004] Loss 30.63410 :  85%|███████████████████████████████████████████████████▋         | 212/250 [22:14<03:58,  6.28s/it]Train | Ep [212/250] Step [427/500] LR [0.00004] Loss 30.56483 :  85%|███████████████████████████████████████████████████▋         | 212/250 [22:16<03:58,  6.28s/it]INFO - 12/17/25 16:28:49 - 0:22:42 - Ep 212 | l2r: acc of top [1, 10, 50] = [0.7601 0.9441 0.9821], mr = 9.466, mrr = 0.826, Loss = 30.5648
INFO - 12/17/25 16:28:49 - 0:22:42 - Ep 212 | r2l: acc of top [1, 10, 50] = [0.7638 0.944  0.9834], mr = 9.990, mrr = 0.829, Loss = 30.5648
Train | Ep [212/250] Step [427/500] LR [0.00004] Loss 30.56483 :  85%|███████████████████████████████████████████████████▉         | 213/250 [22:21<03:51,  6.25s/it]Train | Ep [213/250] Step [429/500] LR [0.00003] Loss 30.62703 :  85%|███████████████████████████████████████████████████▉         | 213/250 [22:23<03:51,  6.25s/it]INFO - 12/17/25 16:28:55 - 0:22:49 - Ep 213 | l2r: acc of top [1, 10, 50] = [0.7598 0.9438 0.982 ], mr = 9.488, mrr = 0.826, Loss = 30.6270
INFO - 12/17/25 16:28:55 - 0:22:49 - Ep 213 | r2l: acc of top [1, 10, 50] = [0.7635 0.9438 0.9832], mr = 9.993, mrr = 0.829, Loss = 30.6270
Train | Ep [213/250] Step [429/500] LR [0.00003] Loss 30.62703 :  86%|████████████████████████████████████████████████████▏        | 214/250 [22:27<03:43,  6.20s/it]Train | Ep [214/250] Step [431/500] LR [0.00003] Loss 30.45978 :  86%|████████████████████████████████████████████████████▏        | 214/250 [22:29<03:43,  6.20s/it]INFO - 12/17/25 16:29:01 - 0:22:55 - Ep 214 | l2r: acc of top [1, 10, 50] = [0.7597 0.944  0.9821], mr = 9.508, mrr = 0.826, Loss = 30.4598
INFO - 12/17/25 16:29:01 - 0:22:55 - Ep 214 | r2l: acc of top [1, 10, 50] = [0.7637 0.9439 0.983 ], mr = 10.022, mrr = 0.829, Loss = 30.4598
Train | Ep [214/250] Step [431/500] LR [0.00003] Loss 30.45978 :  86%|████████████████████████████████████████████████████▍        | 215/250 [22:33<03:34,  6.14s/it]Train | Ep [215/250] Step [433/500] LR [0.00003] Loss 30.73399 :  86%|████████████████████████████████████████████████████▍        | 215/250 [22:35<03:34,  6.14s/it]INFO - 12/17/25 16:29:07 - 0:23:01 - Ep 215 | l2r: acc of top [1, 10, 50] = [0.7603 0.9441 0.982 ], mr = 9.514, mrr = 0.826, Loss = 30.7340
INFO - 12/17/25 16:29:07 - 0:23:01 - Ep 215 | r2l: acc of top [1, 10, 50] = [0.7636 0.9439 0.983 ], mr = 10.049, mrr = 0.829, Loss = 30.7340
Train | Ep [215/250] Step [433/500] LR [0.00003] Loss 30.73399 :  86%|████████████████████████████████████████████████████▋        | 216/250 [22:39<03:27,  6.10s/it]Train | Ep [216/250] Step [435/500] LR [0.00003] Loss 30.43844 :  86%|████████████████████████████████████████████████████▋        | 216/250 [22:41<03:27,  6.10s/it]INFO - 12/17/25 16:29:13 - 0:23:07 - Ep 216 | l2r: acc of top [1, 10, 50] = [0.7598 0.9442 0.982 ], mr = 9.479, mrr = 0.826, Loss = 30.4384
INFO - 12/17/25 16:29:13 - 0:23:07 - Ep 216 | r2l: acc of top [1, 10, 50] = [0.7639 0.944  0.9831], mr = 10.053, mrr = 0.829, Loss = 30.4384
Train | Ep [216/250] Step [435/500] LR [0.00003] Loss 30.43844 :  87%|████████████████████████████████████████████████████▉        | 217/250 [22:45<03:22,  6.13s/it]Train | Ep [217/250] Step [437/500] LR [0.00003] Loss 30.26738 :  87%|████████████████████████████████████████████████████▉        | 217/250 [22:47<03:22,  6.13s/it]INFO - 12/17/25 16:29:19 - 0:23:13 - Ep 217 | l2r: acc of top [1, 10, 50] = [0.7603 0.9442 0.9819], mr = 9.473, mrr = 0.826, Loss = 30.2674
INFO - 12/17/25 16:29:19 - 0:23:13 - Ep 217 | r2l: acc of top [1, 10, 50] = [0.7635 0.944  0.9831], mr = 10.053, mrr = 0.829, Loss = 30.2674
Train | Ep [217/250] Step [437/500] LR [0.00003] Loss 30.26738 :  87%|█████████████████████████████████████████████████████▏       | 218/250 [22:51<03:16,  6.15s/it]Train | Ep [218/250] Step [439/500] LR [0.00003] Loss 30.62448 :  87%|█████████████████████████████████████████████████████▏       | 218/250 [22:53<03:16,  6.15s/it]INFO - 12/17/25 16:29:26 - 0:23:19 - Ep 218 | l2r: acc of top [1, 10, 50] = [0.7597 0.9442 0.9819], mr = 9.492, mrr = 0.826, Loss = 30.6245
INFO - 12/17/25 16:29:26 - 0:23:19 - Ep 218 | r2l: acc of top [1, 10, 50] = [0.7635 0.9441 0.983 ], mr = 10.064, mrr = 0.828, Loss = 30.6245
Train | Ep [218/250] Step [439/500] LR [0.00003] Loss 30.62448 :  88%|█████████████████████████████████████████████████████▍       | 219/250 [22:57<03:12,  6.22s/it]Train | Ep [219/250] Step [441/500] LR [0.00002] Loss 30.61636 :  88%|█████████████████████████████████████████████████████▍       | 219/250 [23:00<03:12,  6.22s/it]INFO - 12/17/25 16:29:32 - 0:23:26 - Ep 219 | l2r: acc of top [1, 10, 50] = [0.7598 0.944  0.9819], mr = 9.534, mrr = 0.826, Loss = 30.6164
INFO - 12/17/25 16:29:32 - 0:23:26 - Ep 219 | r2l: acc of top [1, 10, 50] = [0.7634 0.9443 0.983 ], mr = 10.082, mrr = 0.828, Loss = 30.6164
Train | Ep [219/250] Step [441/500] LR [0.00002] Loss 30.61636 :  88%|█████████████████████████████████████████████████████▋       | 220/250 [23:04<03:07,  6.24s/it]Train | Ep [220/250] Step [443/500] LR [0.00002] Loss 30.35032 :  88%|█████████████████████████████████████████████████████▋       | 220/250 [23:06<03:07,  6.24s/it]INFO - 12/17/25 16:29:38 - 0:23:32 - Ep 220 | l2r: acc of top [1, 10, 50] = [0.76   0.9439 0.9818], mr = 9.579, mrr = 0.826, Loss = 30.3503
INFO - 12/17/25 16:29:38 - 0:23:32 - Ep 220 | r2l: acc of top [1, 10, 50] = [0.763  0.9444 0.983 ], mr = 10.101, mrr = 0.828, Loss = 30.3503
Train | Ep [220/250] Step [443/500] LR [0.00002] Loss 30.35032 :  88%|█████████████████████████████████████████████████████▉       | 221/250 [23:10<03:01,  6.25s/it]Train | Ep [221/250] Step [445/500] LR [0.00002] Loss 30.53687 :  88%|█████████████████████████████████████████████████████▉       | 221/250 [23:12<03:01,  6.25s/it]INFO - 12/17/25 16:29:45 - 0:23:38 - Ep 221 | l2r: acc of top [1, 10, 50] = [0.7601 0.9438 0.9818], mr = 9.595, mrr = 0.826, Loss = 30.5369
INFO - 12/17/25 16:29:45 - 0:23:38 - Ep 221 | r2l: acc of top [1, 10, 50] = [0.763 0.944 0.983], mr = 10.106, mrr = 0.828, Loss = 30.5369
Train | Ep [221/250] Step [445/500] LR [0.00002] Loss 30.53687 :  89%|██████████████████████████████████████████████████████▏      | 222/250 [23:16<02:55,  6.28s/it]Train | Ep [222/250] Step [447/500] LR [0.00002] Loss 30.48748 :  89%|██████████████████████████████████████████████████████▏      | 222/250 [23:18<02:55,  6.28s/it]INFO - 12/17/25 16:29:51 - 0:23:45 - Ep 222 | l2r: acc of top [1, 10, 50] = [0.7601 0.9439 0.9818], mr = 9.605, mrr = 0.826, Loss = 30.4875
INFO - 12/17/25 16:29:51 - 0:23:45 - Ep 222 | r2l: acc of top [1, 10, 50] = [0.763  0.9439 0.983 ], mr = 10.114, mrr = 0.828, Loss = 30.4875
Train | Ep [222/250] Step [447/500] LR [0.00002] Loss 30.48748 :  89%|██████████████████████████████████████████████████████▍      | 223/250 [23:23<02:49,  6.29s/it]Train | Ep [223/250] Step [449/500] LR [0.00002] Loss 30.36162 :  89%|██████████████████████████████████████████████████████▍      | 223/250 [23:25<02:49,  6.29s/it]INFO - 12/17/25 16:29:57 - 0:23:51 - Ep 223 | l2r: acc of top [1, 10, 50] = [0.7595 0.9439 0.9818], mr = 9.631, mrr = 0.825, Loss = 30.3616
INFO - 12/17/25 16:29:57 - 0:23:51 - Ep 223 | r2l: acc of top [1, 10, 50] = [0.7631 0.944  0.983 ], mr = 10.130, mrr = 0.828, Loss = 30.3616
Train | Ep [223/250] Step [449/500] LR [0.00002] Loss 30.36162 :  90%|██████████████████████████████████████████████████████▋      | 224/250 [23:29<02:44,  6.33s/it]Train | Ep [224/250] Step [451/500] LR [0.00002] Loss 30.35883 :  90%|██████████████████████████████████████████████████████▋      | 224/250 [23:31<02:44,  6.33s/it]INFO - 12/17/25 16:30:03 - 0:23:57 - Ep 224 | l2r: acc of top [1, 10, 50] = [0.7598 0.9439 0.9818], mr = 9.649, mrr = 0.826, Loss = 30.3588
INFO - 12/17/25 16:30:03 - 0:23:57 - Ep 224 | r2l: acc of top [1, 10, 50] = [0.7629 0.944  0.983 ], mr = 10.150, mrr = 0.828, Loss = 30.3588
Train | Ep [224/250] Step [451/500] LR [0.00002] Loss 30.35883 :  90%|██████████████████████████████████████████████████████▉      | 225/250 [23:35<02:36,  6.24s/it]Train | Ep [225/250] Step [453/500] LR [0.00002] Loss 30.28739 :  90%|██████████████████████████████████████████████████████▉      | 225/250 [23:37<02:36,  6.24s/it]INFO - 12/17/25 16:30:09 - 0:24:03 - Ep 225 | l2r: acc of top [1, 10, 50] = [0.7596 0.9439 0.9818], mr = 9.664, mrr = 0.825, Loss = 30.2874
INFO - 12/17/25 16:30:09 - 0:24:03 - Ep 225 | r2l: acc of top [1, 10, 50] = [0.763  0.9441 0.983 ], mr = 10.161, mrr = 0.828, Loss = 30.2874
Train | Ep [225/250] Step [453/500] LR [0.00002] Loss 30.28739 :  90%|███████████████████████████████████████████████████████▏     | 226/250 [23:41<02:29,  6.21s/it]Train | Ep [226/250] Step [455/500] LR [0.00001] Loss 30.45599 :  90%|███████████████████████████████████████████████████████▏     | 226/250 [23:43<02:29,  6.21s/it]INFO - 12/17/25 16:30:16 - 0:24:09 - Ep 226 | l2r: acc of top [1, 10, 50] = [0.7595 0.9439 0.9817], mr = 9.681, mrr = 0.825, Loss = 30.4560
INFO - 12/17/25 16:30:16 - 0:24:09 - Ep 226 | r2l: acc of top [1, 10, 50] = [0.7634 0.944  0.983 ], mr = 10.169, mrr = 0.828, Loss = 30.4560
Train | Ep [226/250] Step [455/500] LR [0.00001] Loss 30.45599 :  91%|███████████████████████████████████████████████████████▍     | 227/250 [23:47<02:21,  6.17s/it]Train | Ep [227/250] Step [457/500] LR [0.00001] Loss 30.55629 :  91%|███████████████████████████████████████████████████████▍     | 227/250 [23:49<02:21,  6.17s/it]INFO - 12/17/25 16:30:22 - 0:24:15 - Ep 227 | l2r: acc of top [1, 10, 50] = [0.7594 0.9439 0.9817], mr = 9.680, mrr = 0.825, Loss = 30.5563
INFO - 12/17/25 16:30:22 - 0:24:15 - Ep 227 | r2l: acc of top [1, 10, 50] = [0.7634 0.9441 0.983 ], mr = 10.173, mrr = 0.828, Loss = 30.5563
Train | Ep [227/250] Step [457/500] LR [0.00001] Loss 30.55629 :  91%|███████████████████████████████████████████████████████▋     | 228/250 [23:54<02:16,  6.19s/it]Train | Ep [228/250] Step [459/500] LR [0.00001] Loss 30.42459 :  91%|███████████████████████████████████████████████████████▋     | 228/250 [23:56<02:16,  6.19s/it]INFO - 12/17/25 16:30:28 - 0:24:22 - Ep 228 | l2r: acc of top [1, 10, 50] = [0.7596 0.9439 0.9818], mr = 9.683, mrr = 0.825, Loss = 30.4246
INFO - 12/17/25 16:30:28 - 0:24:22 - Ep 228 | r2l: acc of top [1, 10, 50] = [0.7635 0.9442 0.983 ], mr = 10.172, mrr = 0.828, Loss = 30.4246
Train | Ep [228/250] Step [459/500] LR [0.00001] Loss 30.42459 :  92%|███████████████████████████████████████████████████████▉     | 229/250 [24:00<02:10,  6.19s/it]Train | Ep [229/250] Step [461/500] LR [0.00001] Loss 30.41490 :  92%|███████████████████████████████████████████████████████▉     | 229/250 [24:02<02:10,  6.19s/it]INFO - 12/17/25 16:30:34 - 0:24:28 - Ep 229 | l2r: acc of top [1, 10, 50] = [0.7595 0.9442 0.9818], mr = 9.689, mrr = 0.825, Loss = 30.4149
INFO - 12/17/25 16:30:34 - 0:24:28 - Ep 229 | r2l: acc of top [1, 10, 50] = [0.7635 0.9436 0.983 ], mr = 10.168, mrr = 0.828, Loss = 30.4149
Train | Ep [229/250] Step [461/500] LR [0.00001] Loss 30.41490 :  92%|████████████████████████████████████████████████████████     | 230/250 [24:06<02:04,  6.22s/it]Train | Ep [230/250] Step [463/500] LR [0.00001] Loss 30.48027 :  92%|████████████████████████████████████████████████████████     | 230/250 [24:08<02:04,  6.22s/it]INFO - 12/17/25 16:30:41 - 0:24:34 - Ep 230 | l2r: acc of top [1, 10, 50] = [0.7595 0.9442 0.9818], mr = 9.692, mrr = 0.825, Loss = 30.4803
INFO - 12/17/25 16:30:41 - 0:24:34 - Ep 230 | r2l: acc of top [1, 10, 50] = [0.7632 0.9436 0.983 ], mr = 10.166, mrr = 0.828, Loss = 30.4803
Train | Ep [230/250] Step [463/500] LR [0.00001] Loss 30.48027 :  92%|████████████████████████████████████████████████████████▎    | 231/250 [24:12<01:58,  6.23s/it]Train | Ep [231/250] Step [465/500] LR [0.00001] Loss 30.41644 :  92%|████████████████████████████████████████████████████████▎    | 231/250 [24:14<01:58,  6.23s/it]INFO - 12/17/25 16:30:47 - 0:24:41 - Ep 231 | l2r: acc of top [1, 10, 50] = [0.7594 0.9441 0.9818], mr = 9.708, mrr = 0.825, Loss = 30.4164
INFO - 12/17/25 16:30:47 - 0:24:41 - Ep 231 | r2l: acc of top [1, 10, 50] = [0.7633 0.9436 0.983 ], mr = 10.173, mrr = 0.828, Loss = 30.4164
Train | Ep [231/250] Step [465/500] LR [0.00001] Loss 30.41644 :  93%|████████████████████████████████████████████████████████▌    | 232/250 [24:19<01:52,  6.25s/it]Train | Ep [232/250] Step [467/500] LR [0.00001] Loss 30.31685 :  93%|████████████████████████████████████████████████████████▌    | 232/250 [24:21<01:52,  6.25s/it]INFO - 12/17/25 16:30:53 - 0:24:47 - Ep 232 | l2r: acc of top [1, 10, 50] = [0.7592 0.9441 0.9818], mr = 9.713, mrr = 0.825, Loss = 30.3168
INFO - 12/17/25 16:30:53 - 0:24:47 - Ep 232 | r2l: acc of top [1, 10, 50] = [0.7634 0.9435 0.983 ], mr = 10.175, mrr = 0.828, Loss = 30.3168
Train | Ep [232/250] Step [467/500] LR [0.00001] Loss 30.31685 :  93%|████████████████████████████████████████████████████████▊    | 233/250 [24:25<01:46,  6.26s/it]Train | Ep [233/250] Step [469/500] LR [0.00001] Loss 30.45131 :  93%|████████████████████████████████████████████████████████▊    | 233/250 [24:27<01:46,  6.26s/it]INFO - 12/17/25 16:30:59 - 0:24:53 - Ep 233 | l2r: acc of top [1, 10, 50] = [0.7592 0.9441 0.9818], mr = 9.713, mrr = 0.825, Loss = 30.4513
INFO - 12/17/25 16:30:59 - 0:24:53 - Ep 233 | r2l: acc of top [1, 10, 50] = [0.7633 0.9438 0.983 ], mr = 10.178, mrr = 0.828, Loss = 30.4513
Train | Ep [233/250] Step [469/500] LR [0.00001] Loss 30.45131 :  94%|█████████████████████████████████████████████████████████    | 234/250 [24:31<01:40,  6.25s/it]Train | Ep [234/250] Step [471/500] LR [0.00001] Loss 30.29694 :  94%|█████████████████████████████████████████████████████████    | 234/250 [24:33<01:40,  6.25s/it]INFO - 12/17/25 16:31:06 - 0:24:59 - Ep 234 | l2r: acc of top [1, 10, 50] = [0.7594 0.944  0.9818], mr = 9.707, mrr = 0.825, Loss = 30.2969
INFO - 12/17/25 16:31:06 - 0:24:59 - Ep 234 | r2l: acc of top [1, 10, 50] = [0.7634 0.9438 0.9829], mr = 10.178, mrr = 0.828, Loss = 30.2969
Train | Ep [234/250] Step [471/500] LR [0.00001] Loss 30.29694 :  94%|█████████████████████████████████████████████████████████▎   | 235/250 [24:37<01:33,  6.25s/it]Train | Ep [235/250] Step [473/500] LR [0.00001] Loss 30.34448 :  94%|█████████████████████████████████████████████████████████▎   | 235/250 [24:39<01:33,  6.25s/it]INFO - 12/17/25 16:31:12 - 0:25:05 - Ep 235 | l2r: acc of top [1, 10, 50] = [0.7594 0.9439 0.9818], mr = 9.701, mrr = 0.825, Loss = 30.3445
INFO - 12/17/25 16:31:12 - 0:25:05 - Ep 235 | r2l: acc of top [1, 10, 50] = [0.7634 0.9438 0.9829], mr = 10.180, mrr = 0.828, Loss = 30.3445
Train | Ep [235/250] Step [473/500] LR [0.00001] Loss 30.34448 :  94%|█████████████████████████████████████████████████████████▌   | 236/250 [24:44<01:27,  6.24s/it]Train | Ep [236/250] Step [475/500] LR [0.00000] Loss 30.32479 :  94%|█████████████████████████████████████████████████████████▌   | 236/250 [24:46<01:27,  6.24s/it]INFO - 12/17/25 16:31:18 - 0:25:12 - Ep 236 | l2r: acc of top [1, 10, 50] = [0.7591 0.9439 0.9818], mr = 9.699, mrr = 0.825, Loss = 30.3248
INFO - 12/17/25 16:31:18 - 0:25:12 - Ep 236 | r2l: acc of top [1, 10, 50] = [0.7632 0.9439 0.9829], mr = 10.183, mrr = 0.828, Loss = 30.3248
Train | Ep [236/250] Step [475/500] LR [0.00000] Loss 30.32479 :  95%|█████████████████████████████████████████████████████████▊   | 237/250 [24:50<01:21,  6.28s/it]Train | Ep [237/250] Step [477/500] LR [0.00000] Loss 30.34668 :  95%|█████████████████████████████████████████████████████████▊   | 237/250 [24:52<01:21,  6.28s/it]INFO - 12/17/25 16:31:24 - 0:25:18 - Ep 237 | l2r: acc of top [1, 10, 50] = [0.7591 0.9439 0.9818], mr = 9.700, mrr = 0.825, Loss = 30.3467
INFO - 12/17/25 16:31:24 - 0:25:18 - Ep 237 | r2l: acc of top [1, 10, 50] = [0.7631 0.9439 0.9829], mr = 10.185, mrr = 0.828, Loss = 30.3467
Train | Ep [237/250] Step [477/500] LR [0.00000] Loss 30.34668 :  95%|██████████████████████████████████████████████████████████   | 238/250 [24:56<01:14,  6.25s/it]Train | Ep [238/250] Step [479/500] LR [0.00000] Loss 30.44129 :  95%|██████████████████████████████████████████████████████████   | 238/250 [24:58<01:14,  6.25s/it]INFO - 12/17/25 16:31:31 - 0:25:24 - Ep 238 | l2r: acc of top [1, 10, 50] = [0.7592 0.944  0.9818], mr = 9.701, mrr = 0.825, Loss = 30.4413
INFO - 12/17/25 16:31:31 - 0:25:24 - Ep 238 | r2l: acc of top [1, 10, 50] = [0.7632 0.9438 0.9829], mr = 10.183, mrr = 0.828, Loss = 30.4413
Train | Ep [238/250] Step [479/500] LR [0.00000] Loss 30.44129 :  96%|██████████████████████████████████████████████████████████▎  | 239/250 [25:02<01:08,  6.26s/it]Train | Ep [239/250] Step [481/500] LR [0.00000] Loss 30.22332 :  96%|██████████████████████████████████████████████████████████▎  | 239/250 [25:04<01:08,  6.26s/it]INFO - 12/17/25 16:31:37 - 0:25:31 - Ep 239 | l2r: acc of top [1, 10, 50] = [0.7594 0.944  0.9818], mr = 9.704, mrr = 0.825, Loss = 30.2233
INFO - 12/17/25 16:31:37 - 0:25:31 - Ep 239 | r2l: acc of top [1, 10, 50] = [0.7631 0.9437 0.9829], mr = 10.184, mrr = 0.828, Loss = 30.2233
Train | Ep [239/250] Step [481/500] LR [0.00000] Loss 30.22332 :  96%|██████████████████████████████████████████████████████████▌  | 240/250 [25:09<01:02,  6.27s/it]Train | Ep [240/250] Step [483/500] LR [0.00000] Loss 30.23432 :  96%|██████████████████████████████████████████████████████████▌  | 240/250 [25:11<01:02,  6.27s/it]INFO - 12/17/25 16:31:43 - 0:25:37 - Ep 240 | l2r: acc of top [1, 10, 50] = [0.7592 0.944  0.9818], mr = 9.707, mrr = 0.825, Loss = 30.2343
INFO - 12/17/25 16:31:43 - 0:25:37 - Ep 240 | r2l: acc of top [1, 10, 50] = [0.7631 0.9437 0.983 ], mr = 10.185, mrr = 0.828, Loss = 30.2343
Train | Ep [240/250] Step [483/500] LR [0.00000] Loss 30.23432 :  96%|██████████████████████████████████████████████████████████▊  | 241/250 [25:15<00:56,  6.28s/it]Train | Ep [241/250] Step [485/500] LR [0.00000] Loss 30.28250 :  96%|██████████████████████████████████████████████████████████▊  | 241/250 [25:17<00:56,  6.28s/it]INFO - 12/17/25 16:31:50 - 0:25:43 - Ep 241 | l2r: acc of top [1, 10, 50] = [0.7592 0.944  0.9818], mr = 9.709, mrr = 0.825, Loss = 30.2825
INFO - 12/17/25 16:31:50 - 0:25:43 - Ep 241 | r2l: acc of top [1, 10, 50] = [0.7631 0.9438 0.983 ], mr = 10.186, mrr = 0.828, Loss = 30.2825
Train | Ep [241/250] Step [485/500] LR [0.00000] Loss 30.28250 :  97%|███████████████████████████████████████████████████████████  | 242/250 [25:21<00:50,  6.30s/it]Train | Ep [242/250] Step [487/500] LR [0.00000] Loss 30.40193 :  97%|███████████████████████████████████████████████████████████  | 242/250 [25:23<00:50,  6.30s/it]INFO - 12/17/25 16:31:56 - 0:25:49 - Ep 242 | l2r: acc of top [1, 10, 50] = [0.759  0.944  0.9818], mr = 9.710, mrr = 0.825, Loss = 30.4019
INFO - 12/17/25 16:31:56 - 0:25:49 - Ep 242 | r2l: acc of top [1, 10, 50] = [0.7631 0.9437 0.983 ], mr = 10.187, mrr = 0.828, Loss = 30.4019
Train | Ep [242/250] Step [487/500] LR [0.00000] Loss 30.40193 :  97%|███████████████████████████████████████████████████████████▎ | 243/250 [25:28<00:43,  6.28s/it]Train | Ep [243/250] Step [489/500] LR [0.00000] Loss 30.19064 :  97%|███████████████████████████████████████████████████████████▎ | 243/250 [25:30<00:43,  6.28s/it]INFO - 12/17/25 16:32:02 - 0:25:56 - Ep 243 | l2r: acc of top [1, 10, 50] = [0.7591 0.944  0.9818], mr = 9.709, mrr = 0.825, Loss = 30.1906
INFO - 12/17/25 16:32:02 - 0:25:56 - Ep 243 | r2l: acc of top [1, 10, 50] = [0.7631 0.9437 0.9829], mr = 10.188, mrr = 0.828, Loss = 30.1906
Train | Ep [243/250] Step [489/500] LR [0.00000] Loss 30.19064 :  98%|███████████████████████████████████████████████████████████▌ | 244/250 [25:34<00:37,  6.25s/it]Train | Ep [244/250] Step [491/500] LR [0.00000] Loss 30.34509 :  98%|███████████████████████████████████████████████████████████▌ | 244/250 [25:36<00:37,  6.25s/it]INFO - 12/17/25 16:32:08 - 0:26:02 - Ep 244 | l2r: acc of top [1, 10, 50] = [0.759  0.944  0.9818], mr = 9.709, mrr = 0.825, Loss = 30.3451
INFO - 12/17/25 16:32:08 - 0:26:02 - Ep 244 | r2l: acc of top [1, 10, 50] = [0.7631 0.9437 0.9829], mr = 10.187, mrr = 0.828, Loss = 30.3451
Train | Ep [244/250] Step [491/500] LR [0.00000] Loss 30.34509 :  98%|███████████████████████████████████████████████████████████▊ | 245/250 [25:40<00:31,  6.24s/it]Train | Ep [245/250] Step [493/500] LR [0.00000] Loss 30.21613 :  98%|███████████████████████████████████████████████████████████▊ | 245/250 [25:42<00:31,  6.24s/it]INFO - 12/17/25 16:32:14 - 0:26:08 - Ep 245 | l2r: acc of top [1, 10, 50] = [0.759  0.944  0.9818], mr = 9.710, mrr = 0.825, Loss = 30.2161
INFO - 12/17/25 16:32:14 - 0:26:08 - Ep 245 | r2l: acc of top [1, 10, 50] = [0.7631 0.9437 0.9829], mr = 10.188, mrr = 0.828, Loss = 30.2161
Train | Ep [245/250] Step [493/500] LR [0.00000] Loss 30.21613 :  98%|████████████████████████████████████████████████████████████ | 246/250 [25:46<00:24,  6.20s/it]Train | Ep [246/250] Step [495/500] LR [0.00000] Loss 30.31832 :  98%|████████████████████████████████████████████████████████████ | 246/250 [25:48<00:24,  6.20s/it]INFO - 12/17/25 16:32:20 - 0:26:14 - Ep 246 | l2r: acc of top [1, 10, 50] = [0.759  0.944  0.9818], mr = 9.709, mrr = 0.825, Loss = 30.3183
INFO - 12/17/25 16:32:20 - 0:26:14 - Ep 246 | r2l: acc of top [1, 10, 50] = [0.7631 0.9437 0.9829], mr = 10.188, mrr = 0.828, Loss = 30.3183
Train | Ep [246/250] Step [495/500] LR [0.00000] Loss 30.31832 :  99%|████████████████████████████████████████████████████████████▎| 247/250 [25:52<00:18,  6.20s/it]Train | Ep [247/250] Step [497/500] LR [0.00000] Loss 30.25502 :  99%|████████████████████████████████████████████████████████████▎| 247/250 [25:54<00:18,  6.20s/it]INFO - 12/17/25 16:32:27 - 0:26:20 - Ep 247 | l2r: acc of top [1, 10, 50] = [0.759  0.944  0.9818], mr = 9.709, mrr = 0.825, Loss = 30.2550
INFO - 12/17/25 16:32:27 - 0:26:20 - Ep 247 | r2l: acc of top [1, 10, 50] = [0.7632 0.9437 0.9829], mr = 10.188, mrr = 0.828, Loss = 30.2550
Train | Ep [247/250] Step [497/500] LR [0.00000] Loss 30.25502 :  99%|████████████████████████████████████████████████████████████▌| 248/250 [25:58<00:12,  6.16s/it]Train | Ep [248/250] Step [499/500] LR [0.00000] Loss 30.42820 :  99%|████████████████████████████████████████████████████████████▌| 248/250 [26:00<00:12,  6.16s/it]INFO - 12/17/25 16:32:33 - 0:26:26 - Ep 248 | l2r: acc of top [1, 10, 50] = [0.759  0.944  0.9818], mr = 9.710, mrr = 0.825, Loss = 30.4282
INFO - 12/17/25 16:32:33 - 0:26:26 - Ep 248 | r2l: acc of top [1, 10, 50] = [0.7632 0.9437 0.9829], mr = 10.188, mrr = 0.828, Loss = 30.4282
Train | Ep [248/250] Step [499/500] LR [0.00000] Loss 30.42820 : 100%|████████████████████████████████████████████████████████████▊| 249/250 [26:04<00:06,  6.13s/it]Train | Ep [249/250] Step [501/500] LR [0.00000] Loss 30.38059 : 100%|████████████████████████████████████████████████████████████▊| 249/250 [26:06<00:06,  6.13s/it]INFO - 12/17/25 16:32:39 - 0:26:32 - Ep 249 | l2r: acc of top [1, 10, 50] = [0.759  0.944  0.9818], mr = 9.710, mrr = 0.825, Loss = 30.3806
INFO - 12/17/25 16:32:39 - 0:26:32 - Ep 249 | r2l: acc of top [1, 10, 50] = [0.7632 0.9437 0.9829], mr = 10.188, mrr = 0.828, Loss = 30.3806
Train | Ep [249/250] Step [501/500] LR [0.00000] Loss 30.38059 : 100%|█████████████████████████████████████████████████████████████| 250/250 [26:11<00:00,  6.15s/it]Train | Ep [249/250] Step [501/500] LR [0.00000] Loss 30.38059 : 100%|█████████████████████████████████████████████████████████████| 250/250 [26:11<00:00,  6.28s/it]
INFO - 12/17/25 16:32:39 - 0:26:32 - load from the best model before final testing ... 
INFO - 12/17/25 16:32:39 - 0:26:32 -  --------------------- Test result --------------------- 
INFO - 12/17/25 16:32:44 - 0:26:38 - Ep 249 | l2r: acc of top [1, 10, 50] = [0.783  0.9587 0.9884], mr = 4.195, mrr = 0.845, Loss = 30.3806
INFO - 12/17/25 16:32:44 - 0:26:38 - Ep 249 | r2l: acc of top [1, 10, 50] = [0.7813 0.9582 0.9889], mr = 4.694, mrr = 0.845, Loss = 30.3806
INFO - 12/17/25 16:32:44 - 0:26:38 - min loss 30.380587577819824
INFO - 12/17/25 16:32:44 - 0:26:38 - done!

Script done on 2025-12-17 16:32:46+08:00 [COMMAND_EXIT_CODE="0"]
